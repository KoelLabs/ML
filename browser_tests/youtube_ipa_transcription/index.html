<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Test</title>
</head>
<body>
<h1>Browser Based YouTube IPA Transcription</h1>
<input type="text" id="url" value="https://www.youtube.com/watch?v=PUjvaMWKeBI" style="width: 80ch">
<button onclick="load()">Load</button>
<p id="info"></p>
<video id="player" style="width: 600px;" controls></video>
<audio id="audio" controls></audio>
<br>
<button onclick="transcribe()">Transcribe</button>
<p id="transcription"></p>
<script type="module">
    const video = document.getElementById("player");
    const audio = document.getElementById("audio");

    window.load = async () => {
        const url = document.getElementById("url").value;

        const buffer = await fetch("/best-video?url=" + url).then(res => res.arrayBuffer());
        video.src = URL.createObjectURL(new Blob([buffer], {type: "video/mp4"}));

        const audioBuffer = await fetch("/best-audio?url=" + url).then(res => res.arrayBuffer());
        audio.src = URL.createObjectURL(new Blob([audioBuffer], {type: "audio/mp4"}));
        console.log(new Uint8Array(audioBuffer).slice(0, 10));

        const info = await fetch("/info?url=" + url).then(res => res.json());
        const details = info.videoDetails;
        document.getElementById("info").innerHTML = `
            <p>Title: ${details.title}</p>
            <p>Author: ${details.author}</p>
            <p>View_count: ${details.viewCount}</p>
            <p>Duration: ${details.lengthSeconds} seconds</p>
            <p>Thumbnail: <img style="width: 100px" src="${details.thumbnail.thumbnails.at(-1).url}"></p>
        `;
        console.log(info.captions)
        console.log(audioBuffer.byteLength / details.lengthSeconds);
    }

    // Regular transcription without timestamps:
    // import { env, pipeline } from 'https://cdn.jsdelivr.net/npm/@xenova/transformers@2.17.2';
    // env.allowRemoteModels = false;
    // const pipe = await pipeline('automatic-speech-recognition', "facebook/wav2vec2-lv-60-espeak-cv-ft");
    
    // window.transcribe = async () => {
    //     console.log("Transcribing...");
    //     // const transcription = await pipe(new Float32Array(audioBuffer));
    //     // console.log(transcription.text);

    //     const transcription = await pipe(audio.src);
    //     console.log(transcription);
    // };

    // Transcription with timestamps:
    import { env, AutoProcessor, AutoModelForCTC, read_audio } from 'https://cdn.jsdelivr.net/npm/@xenova/transformers@2.17.2';
    env.allowRemoteModels = false;

    const processor = await AutoProcessor.from_pretrained("facebook/wav2vec2-lv-60-espeak-cv-ft");
    const model = await AutoModelForCTC.from_pretrained("facebook/wav2vec2-lv-60-espeak-cv-ft");

    function indexOfMax(arr) {
        if (arr.length === 0) {
            return -1;
        }

        var max = arr[0];
        var maxIndex = 0;

        for (var i = 1; i < arr.length; i++) {
            if (arr[i] > max) {
                maxIndex = i;
                max = arr[i];
            }
        }

        return maxIndex;
    }

    const vocab = {"<s>": 1, "<pad>": 0, "</s>": 2, "<unk>": 3, "n": 4, "s": 5, "t": 6, "ə": 7, "l": 8, "a": 9, "i": 10, "k": 11, "d": 12, "m": 13, "ɛ": 14, "ɾ": 15, "e": 16, "ɪ": 17, "p": 18, "o": 19, "ɐ": 20, "z": 21, "ð": 22, "f": 23, "j": 24, "v": 25, "b": 26, "ɹ": 27, "ʁ": 28, "ʊ": 29, "iː": 30, "r": 31, "w": 32, "ʌ": 33, "u": 34, "ɡ": 35, "æ": 36, "aɪ": 37, "ʃ": 38, "h": 39, "ɔ": 40, "ɑː": 41, "ŋ": 42, "ɚ": 43, "eɪ": 44, "β": 45, "uː": 46, "y": 47, "ɑ̃": 48, "oʊ": 49, "ᵻ": 50, "eː": 51, "θ": 52, "aʊ": 53, "ts": 54, "oː": 55, "ɔ̃": 56, "ɣ": 57, "ɜ": 58, "ɑ": 59, "dʒ": 60, "əl": 61, "x": 62, "ɜː": 63, "ç": 64, "ʒ": 65, "tʃ": 66, "ɔː": 67, "ɑːɹ": 68, "ɛ̃": 69, "ʎ": 70, "ɔːɹ": 71, "ʋ": 72, "aː": 73, "ɕ": 74, "œ": 75, "ø": 76, "oːɹ": 77, "ɲ": 78, "yː": 79, "ʔ": 80, "iə": 81, "i5": 82, "s.": 83, "tɕ": 84, "??": 85, "nʲ": 86, "ɛː": 87, "œ̃": 88, "ɭ": 89, "ɔø": 90, "ʑ": 91, "tʲ": 92, "ɨ": 93, "ɛɹ": 94, "ts.": 95, "rʲ": 96, "ɪɹ": 97, "ɭʲ": 98, "i.5": 99, "ɔɪ": 100, "q": 101, "sʲ": 102, "u5": 103, "ʊɹ": 104, "iɜ": 105, "a5": 106, "iɛ5": 107, "øː": 108, "ʕ": 109, "ja": 110, "əɜ": 111, "th": 112, "ɑ5": 113, "oɪ": 114, "dʲ": 115, "ə5": 116, "tɕh": 117, "ts.h": 118, "mʲ": 119, "ɯ": 120, "dʑ": 121, "vʲ": 122, "e̞": 123, "tʃʲ": 124, "ei5": 125, "o5": 126, "onɡ5": 127, "ɑu5": 128, "iɑ5": 129, "ai5": 130, "aɪɚ": 131, "kh": 132, "ə1": 133, "ʐ": 134, "i2": 135, "ʉ": 136, "ħ": 137, "t[": 138, "aɪə": 139, "ʲ": 140, "ju": 141, "ə2": 142, "u2": 143, "oɜ": 144, "pː": 145, "iɛɜ": 146, "ou5": 147, "y5": 148, "uɜ": 149, "tː": 150, "uo5": 151, "d[": 152, "uoɜ": 153, "tsh": 154, "ɑɜ": 155, "ɵ": 156, "i̪5": 157, "uei5": 158, "ɟ": 159, "aɜ": 160, "ɑɨ": 161, "i.ɜ": 162, "eʊ": 163, "o2": 164, "ɐ̃": 165, "ä": 166, "pʲ": 167, "kʲ": 168, "n̩": 169, "ɒ": 170, "ph": 171, "ɑu2": 172, "uɨ": 173, "əɪ": 174, "ɫ": 175, "ɬ": 176, "yɜ": 177, "bʲ": 178, "ɑ2": 179, "s̪": 180, "aiɜ": 181, "χ": 182, "ɐ̃ʊ̃": 183, "1": 184, "ə4": 185, "yæɜ": 186, "a2": 187, "ɨː": 188, "t̪": 189, "iouɜ": 190, "ũ": 191, "onɡɜ": 192, "aɨ": 193, "iɛ2": 194, "ɔɨ": 195, "ɑuɜ": 196, "o̞": 197, "ei2": 198, "iou2": 199, "c": 200, "kː": 201, "y2": 202, "ɖ": 203, "oe": 204, "dˤ": 205, "yɛɜ": 206, "əʊ": 207, "S": 208, "ɡʲ": 209, "onɡ2": 210, "u\"": 211, "eiɜ": 212, "ʈ": 213, "ɯᵝ": 214, "iou5": 215, "dZ": 216, "r̝̊": 217, "i.2": 218, "tS": 219, "s^": 220, "ʝ": 221, "yə5": 222, "iɑɜ": 223, "uə5": 224, "pf": 225, "ɨu": 226, "iɑ2": 227, "ou2": 228, "ər2": 229, "fʲ": 230, "ai2": 231, "r̝": 232, "uəɜ": 233, "ɳ": 234, "əɨ": 235, "ua5": 236, "uɪ": 237, "ɽ": 238, "bː": 239, "yu5": 240, "uo2": 241, "yɛ5": 242, "l̩": 243, "ɻ": 244, "ərɜ": 245, "ʂ": 246, "i̪2": 247, "ouɜ": 248, "uaɜ": 249, "a.": 250, "a.ː": 251, "yæ5": 252, "dː": 253, "r̩": 254, "ee": 255, "ɪu": 256, "ər5": 257, "i̪ɜ": 258, "æi": 259, "u:": 260, "i.ː": 261, "t^": 262, "o1": 263, "ɪ^": 264, "ai": 265, "ueiɜ": 266, "æː": 267, "ɛɪ": 268, "eə": 269, "i.": 270, "ɴ": 271, "ie": 272, "ua2": 273, "ɑ1": 274, "o4": 275, "tʃː": 276, "o:": 277, "ɑ:": 278, "u1": 279, "N": 280, "i̪1": 281, "au": 282, "yæ2": 283, "u.": 284, "qː": 285, "yəɜ": 286, "y:": 287, "kʰ": 288, "tʃʰ": 289, "iʊ": 290, "sx": 291, "õ": 292, "uo": 293, "tʰ": 294, "uai5": 295, "bʰ": 296, "u.ː": 297, "uə2": 298, "ʊə": 299, "d^": 300, "s̪ː": 301, "yiɜ": 302, "dʰ": 303, "r.": 304, "oe:": 305, "i1": 306, "ɟː": 307, "yu2": 308, "nʲʲ": 309, "i̪4": 310, "uei2": 311, "tsʲ": 312, "ɸ": 313, "ĩ": 314, "ɑ4": 315, "t̪ː": 316, "eɑ": 317, "u4": 318, "e:": 319, "tsː": 320, "ʈʰ": 321, "ɡʰ": 322, "ɯɯ": 323, "dʒʲ": 324, "ʂʲ": 325, "X": 326, "ɵː": 327, "uaiɜ": 328, "tɕʲ": 329, "ã": 330, "t^ː": 331, "ẽː": 332, "yɛ2": 333, "cː": 334, "i.1": 335, "ɛʊ": 336, "dˤdˤ": 337, "dʒː": 338, "i4": 339, "ɡː": 340, "yi": 341, "ɕʲ": 342, "ɟʰ": 343, "pʰ": 344, "dʑʲ": 345, "yuɜ": 346, "ua1": 347, "ua4": 348, "æiː": 349, "ɐɐ": 350, "ui": 351, "iou1": 352, "ʊː": 353, "a1": 354, "iou4": 355, "cʰ": 356, "iɛ1": 357, "yə2": 358, "ɖʰ": 359, "ẽ": 360, "ʒʲ": 361, "ää": 362, "ər4": 363, "iːː": 364, "ɪː": 365, "iɑ1": 366, "ər1": 367, "œː": 368, "øi": 369, "ɪuː": 370, "cʰcʰ": 371, "əː1": 372, "iː1": 373, "ũ": 374, "kʰː": 375, "o̞o̞": 376, "xʲ": 377, "ou1": 378, "iɛ4": 379, "e̞e̞": 380, "y1": 381, "dzː": 382, "dʲʲ": 383, "dʰː": 384, "ɯᵝɯᵝ": 385, "lː": 386, "uo1": 387, "i.4": 388, "i:": 389, "yɛ5ʲ": 390, "a4": 391};
    const reverse_vocab = Object.fromEntries(Object.entries(vocab).map(([k, v]) => [v, k]));
    const sample_rate = 16000;

    window.transcribe = async () => {
        console.log("Transcribing...");
        const start = performance.now();

        const input = await processor(await read_audio(audio.src, sample_rate))
        const { logits } = await model(input);
        window.logits = logits;
        const predicted_ids = [];
        for (const a of logits) {
            for (const b of a) {
                predicted_ids.push(indexOfMax(b.tolist()));
            }
        }
        const duration_sec = input.input_values.dims[1] / sample_rate;
        console.log(duration_sec);
        let current_phoneme_id = predicted_ids[0]
        let current_start_time = 0
        const phonemes_with_time = []
        for (let i = 1; i < predicted_ids.length; i++) {
            const phoneme_id = predicted_ids[i];
            const time = i * duration_sec / predicted_ids.length;
            if (current_phoneme_id != phoneme_id) {
                phonemes_with_time.push(
                    [reverse_vocab[current_phoneme_id], current_start_time, time]
                )
                current_start_time = time
                current_phoneme_id = phoneme_id
            }
        }
        const transcription_element = document.getElementById("transcription");
        for (const [phoneme, start, end] of phonemes_with_time) {
            transcription_element.innerHTML += `${phoneme} (${start.toFixed(2)} - ${end.toFixed(2)}) <button onclick="playAt(${start})">Play</button><br>`;
        }

        console.log("Transcription took", performance.now() - start, "ms");
    };

    window.playAt = (second, stop=undefined) => {
        video.currentTime = second;
        audio.currentTime = second;
        video.play();
        if (stop) {
            setTimeout(() => {
                video.pause();
            }, (stop - second) * 1000);
        }
    }
</script>
</body>
</html>
