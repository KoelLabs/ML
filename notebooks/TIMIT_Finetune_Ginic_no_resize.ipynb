{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import zipfile\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "# run as much as possible accelerated by apple silicon, fall back to cpu if not possible\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from scripts.audio import audio_file_to_array\n",
    "from scripts.ipa import timit2ipa\n",
    "from scripts.ipa import filter_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append('..')\n",
    "from scripts.eval_tests.panphon_model_eval import panphon_model_eval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set espeak library path for macOS\n",
    "if sys.platform == \"darwin\":\n",
    "    from phonemizer.backend.espeak.wrapper import EspeakWrapper\n",
    "\n",
    "    _ESPEAK_LIBRARY = \"/opt/homebrew/Cellar/espeak/1.48.04_1/lib/libespeak.1.1.48.dylib\"\n",
    "    EspeakWrapper.set_library(_ESPEAK_LIBRARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, AutoModelForCTC, AutoTokenizer, AutoFeatureExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = os.path.join('..', 'models', 'timit-xlsr-finetune-B')\n",
    "PRE_TRAINED_ID = \"ginic/gender_split_70_female_4_wav2vec2-large-xlsr-53-buckeye-ipa\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "timit = zipfile.ZipFile('../.data/TIMIT.zip', 'r')\n",
    "timit_files = timit.namelist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_files = list(set(map(lambda x: x.split('.')[0], filter(lambda x: x.startswith('data/TRAIN'), timit_files))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "WAV_HEADER_SIZE = 44\n",
    "def zipped_wav_to_array(filename):\n",
    "    with timit.open(filename) as wav_file:\n",
    "        return np.frombuffer(wav_file.read(), dtype=np.int16)[WAV_HEADER_SIZE//2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up Dataset Vocab \n",
    "You will see that the initial vocab of most multilingual phoneme transcription models is quite big (300-400 phonemes) we will reduce this in the dataset to improve overall performance for English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio</th>\n",
       "      <th>ipa</th>\n",
       "      <th>phoneme_starts</th>\n",
       "      <th>phoneme_ends</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[25971, 30303, 29285, 26995, 28271, 11552, 131...</td>\n",
       "      <td>sʌmθiŋpʊldmaɪlɛɡ</td>\n",
       "      <td>[0, 2190, 3300, 4400, 5235, 6620, 7326, 8040, ...</td>\n",
       "      <td>[2190, 3300, 4400, 5235, 6620, 7326, 8040, 922...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[25971, 30303, 29285, 26995, 28271, 11552, 131...</td>\n",
       "      <td>oʊnʔæskmitikɪɹiʔɛnʔɔɪliɹæɡlaɪkðæt</td>\n",
       "      <td>[0, 2040, 2440, 4428, 4840, 5973, 8600, 9608, ...</td>\n",
       "      <td>[2040, 2440, 4428, 4840, 5973, 8600, 9608, 101...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[25971, 30303, 29285, 26995, 28271, 11552, 131...</td>\n",
       "      <td>wɛlnaʊwihævtubɪɡθiiɾɹz</td>\n",
       "      <td>[0, 3000, 4386, 7506, 8981, 10109, 10750, 1320...</td>\n",
       "      <td>[3000, 4386, 7506, 8981, 10109, 10750, 13201, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[25971, 30303, 29285, 26995, 28271, 11552, 131...</td>\n",
       "      <td>vɛɹɪpikjujɹɹɛttʃɹbjuʃnindidsimztuoʊvɹteɪksʌttʃ...</td>\n",
       "      <td>[0, 2200, 2880, 4052, 4804, 6080, 7210, 7850, ...</td>\n",
       "      <td>[2200, 2880, 4052, 4804, 6080, 7210, 7850, 832...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[25971, 30303, 29285, 26995, 28271, 11552, 131...</td>\n",
       "      <td>wiɡɑtdɹɛnttʃtfɹəmðɪʔʌɾiɾiɹʌpidɹeɪn</td>\n",
       "      <td>[0, 4971, 5560, 6266, 6791, 6976, 8440, 8939, ...</td>\n",
       "      <td>[4971, 5560, 6266, 6791, 6976, 8440, 8939, 107...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               audio  \\\n",
       "0  [25971, 30303, 29285, 26995, 28271, 11552, 131...   \n",
       "1  [25971, 30303, 29285, 26995, 28271, 11552, 131...   \n",
       "2  [25971, 30303, 29285, 26995, 28271, 11552, 131...   \n",
       "3  [25971, 30303, 29285, 26995, 28271, 11552, 131...   \n",
       "4  [25971, 30303, 29285, 26995, 28271, 11552, 131...   \n",
       "\n",
       "                                                 ipa  \\\n",
       "0                                   sʌmθiŋpʊldmaɪlɛɡ   \n",
       "1                  oʊnʔæskmitikɪɹiʔɛnʔɔɪliɹæɡlaɪkðæt   \n",
       "2                             wɛlnaʊwihævtubɪɡθiiɾɹz   \n",
       "3  vɛɹɪpikjujɹɹɛttʃɹbjuʃnindidsimztuoʊvɹteɪksʌttʃ...   \n",
       "4                 wiɡɑtdɹɛnttʃtfɹəmðɪʔʌɾiɾiɹʌpidɹeɪn   \n",
       "\n",
       "                                      phoneme_starts  \\\n",
       "0  [0, 2190, 3300, 4400, 5235, 6620, 7326, 8040, ...   \n",
       "1  [0, 2040, 2440, 4428, 4840, 5973, 8600, 9608, ...   \n",
       "2  [0, 3000, 4386, 7506, 8981, 10109, 10750, 1320...   \n",
       "3  [0, 2200, 2880, 4052, 4804, 6080, 7210, 7850, ...   \n",
       "4  [0, 4971, 5560, 6266, 6791, 6976, 8440, 8939, ...   \n",
       "\n",
       "                                        phoneme_ends  \n",
       "0  [2190, 3300, 4400, 5235, 6620, 7326, 8040, 922...  \n",
       "1  [2040, 2440, 4428, 4840, 5973, 8600, 9608, 101...  \n",
       "2  [3000, 4386, 7506, 8981, 10109, 10750, 13201, ...  \n",
       "3  [2200, 2880, 4052, 4804, 6080, 7210, 7850, 832...  \n",
       "4  [4971, 5560, 6266, 6791, 6976, 8440, 8939, 107...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, ensure that the simplify_timit function is available and works\n",
    "def simplify_timit(phoneme):\n",
    "    # Substitute the phoneme based on the dictionary\n",
    "    substitution_dict = {\n",
    "        'ɾ̃': 'ɾ',  # Replace nasalized flap with plain flap\n",
    "        'ŋ̍': 'ŋ',  # Remove syllabic marker from 'ŋ̍'\n",
    "        'ə̥': 'ə',  # Remove voiceless marker from 'ə̥'\n",
    "        'ɝ': 'ɹ',   # Simplify rhotacized schwa to 'ɹ'\n",
    "        'ɚ': 'ɹ',   # Simplify rhotacized schwa to 'ɹ'\n",
    "        'l̩': 'l',   # Remove syllabic marker from 'l̩'\n",
    "        'm̩': 'm',   # Remove syllabic marker from 'm̩'\n",
    "        'n̩': 'n',   # Remove syllabic marker from 'n̩'\n",
    "        '̩': '',     # Remove syllabic marker\n",
    "        'ʉ': 'u',    # Replace high central rounded vowel with high back rounded vowel\n",
    "        'ɨ': 'i',    # Replace high central unrounded vowel with high front unrounded vowel\n",
    "        ' ': '',     # Remove nasalization marker\n",
    "        'ɦ': 'h',    # Replace voiceless glottal fricative with voiceless glottal fricative\n",
    "        # Add other necessary substitutions if needed\n",
    "    }\n",
    "    # Apply the substitution for the phoneme\n",
    "    return substitution_dict.get(phoneme, phoneme)  # Return simplified phoneme or the original if no replacement\n",
    "\n",
    "def remove_stress_mark(text):\n",
    "    \"\"\"\n",
    "    Removes the combining double inverted breve (͡) from text.\n",
    "    \n",
    "    Args:\n",
    "        text: String or iterable containing IPA symbols\n",
    "        \n",
    "    Returns:\n",
    "        Text with stress marks removed\n",
    "    \"\"\"\n",
    "    if isinstance(text, str):\n",
    "        return text.replace('͡', '')\n",
    "    else:\n",
    "        raise TypeError(\"Input must be string, set, or list\")\n",
    "    \n",
    "# Updated timit_file_to_dict to use the simplified IPA phonemes\n",
    "def timit_file_to_dict(filename):\n",
    "    with timit.open(filename + '.PHN') as phn_file:\n",
    "        timestamped_phonemes = []\n",
    "        for line in phn_file.read().decode('utf-8').split('\\n'):\n",
    "            if line == '':\n",
    "                continue\n",
    "            start, end, phoneme = line.split()\n",
    "            \n",
    "            # Convert to IPA first and then simplify the phoneme\n",
    "            ipa_phonemes = timit2ipa(phoneme, \"eng\")\n",
    "            \n",
    "            # Now filter only the necessary characters (this simplifies the phoneme to the basic form)\n",
    "            cleaned_ipa = filter_chars(simplify_timit(ipa_phonemes), filter_type=\"letters\")\n",
    "            cleaned_ipa = remove_stress_mark(cleaned_ipa)\n",
    "            timestamped_phonemes.append((cleaned_ipa, int(start), int(end)))\n",
    "\n",
    "    return {'timestamped_phonemes': timestamped_phonemes, 'wav_filename': filename + '.WAV'}\n",
    "\n",
    "# Updated files_to_df to create DataFrame with cleaned-up phonemes\n",
    "def files_to_df(files):\n",
    "    records = []\n",
    "    for filename in files:\n",
    "        parsed = timit_file_to_dict(filename)\n",
    "        parsed['audio'] = zipped_wav_to_array(parsed['wav_filename'])\n",
    "        del parsed['wav_filename']\n",
    "        parsed['ipa'] = \"\".join(phoneme for phoneme, _, _ in parsed['timestamped_phonemes'])\n",
    "        parsed['phoneme_starts'] = [start for _, start, _ in parsed['timestamped_phonemes']]\n",
    "        parsed['phoneme_ends'] = [end for _, _, end in parsed['timestamped_phonemes']]\n",
    "        del parsed['timestamped_phonemes']\n",
    "        records.append(parsed)\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "# Call files_to_df for your test files\n",
    "train_df = files_to_df(training_files)\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Up Audio\n",
    "We will just crop out the start signal :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_audio(row):\n",
    "    # Access the phoneme_starts column and get the last value of the list\n",
    "    end = row['phoneme_starts'][-1]\n",
    "    # Access the phoneme_ends column and get the first value of the list\n",
    "    start = row['phoneme_ends'][0]\n",
    "    # Crop the audio from start to end\n",
    "    # note that start and end are in samples, not seconds\n",
    "    cropped_audio = row['audio'][start:end]\n",
    "    \n",
    "    return cropped_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# graph one audio to see start signal that we will remove\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_df['audio'][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio</th>\n",
       "      <th>ipa</th>\n",
       "      <th>phoneme_starts</th>\n",
       "      <th>phoneme_ends</th>\n",
       "      <th>cropped_audio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[25971, 30303, 29285, 26995, 28271, 11552, 131...</td>\n",
       "      <td>sʌmθiŋpʊldmaɪlɛɡ</td>\n",
       "      <td>[0, 2190, 3300, 4400, 5235, 6620, 7326, 8040, ...</td>\n",
       "      <td>[2190, 3300, 4400, 5235, 6620, 7326, 8040, 922...</td>\n",
       "      <td>[2, -1, 0, 2, 1, 2, 3, 1, 0, 3, 1, -1, -1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[25971, 30303, 29285, 26995, 28271, 11552, 131...</td>\n",
       "      <td>oʊnʔæskmitikɪɹiʔɛnʔɔɪliɹæɡlaɪkðæt</td>\n",
       "      <td>[0, 2040, 2440, 4428, 4840, 5973, 8600, 9608, ...</td>\n",
       "      <td>[2040, 2440, 4428, 4840, 5973, 8600, 9608, 101...</td>\n",
       "      <td>[-1, -2, 0, 1, 0, 0, -1, -1, -1, -1, -2, 3, 3,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[25971, 30303, 29285, 26995, 28271, 11552, 131...</td>\n",
       "      <td>wɛlnaʊwihævtubɪɡθiiɾɹz</td>\n",
       "      <td>[0, 3000, 4386, 7506, 8981, 10109, 10750, 1320...</td>\n",
       "      <td>[3000, 4386, 7506, 8981, 10109, 10750, 13201, ...</td>\n",
       "      <td>[3, 0, -1, -3, -3, -2, -1, 1, -1, -1, -1, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[25971, 30303, 29285, 26995, 28271, 11552, 131...</td>\n",
       "      <td>vɛɹɪpikjujɹɹɛttʃɹbjuʃnindidsimztuoʊvɹteɪksʌttʃ...</td>\n",
       "      <td>[0, 2200, 2880, 4052, 4804, 6080, 7210, 7850, ...</td>\n",
       "      <td>[2200, 2880, 4052, 4804, 6080, 7210, 7850, 832...</td>\n",
       "      <td>[3, 2, 2, 1, 4, 5, 4, 8, 1, 4, 6, 0, 7, 5, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[25971, 30303, 29285, 26995, 28271, 11552, 131...</td>\n",
       "      <td>wiɡɑtdɹɛnttʃtfɹəmðɪʔʌɾiɾiɹʌpidɹeɪn</td>\n",
       "      <td>[0, 4971, 5560, 6266, 6791, 6976, 8440, 8939, ...</td>\n",
       "      <td>[4971, 5560, 6266, 6791, 6976, 8440, 8939, 107...</td>\n",
       "      <td>[9, 8, 9, 13, 9, 14, 8, 11, 4, 4, 4, 4, 4, 4, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               audio  \\\n",
       "0  [25971, 30303, 29285, 26995, 28271, 11552, 131...   \n",
       "1  [25971, 30303, 29285, 26995, 28271, 11552, 131...   \n",
       "2  [25971, 30303, 29285, 26995, 28271, 11552, 131...   \n",
       "3  [25971, 30303, 29285, 26995, 28271, 11552, 131...   \n",
       "4  [25971, 30303, 29285, 26995, 28271, 11552, 131...   \n",
       "\n",
       "                                                 ipa  \\\n",
       "0                                   sʌmθiŋpʊldmaɪlɛɡ   \n",
       "1                  oʊnʔæskmitikɪɹiʔɛnʔɔɪliɹæɡlaɪkðæt   \n",
       "2                             wɛlnaʊwihævtubɪɡθiiɾɹz   \n",
       "3  vɛɹɪpikjujɹɹɛttʃɹbjuʃnindidsimztuoʊvɹteɪksʌttʃ...   \n",
       "4                 wiɡɑtdɹɛnttʃtfɹəmðɪʔʌɾiɾiɹʌpidɹeɪn   \n",
       "\n",
       "                                      phoneme_starts  \\\n",
       "0  [0, 2190, 3300, 4400, 5235, 6620, 7326, 8040, ...   \n",
       "1  [0, 2040, 2440, 4428, 4840, 5973, 8600, 9608, ...   \n",
       "2  [0, 3000, 4386, 7506, 8981, 10109, 10750, 1320...   \n",
       "3  [0, 2200, 2880, 4052, 4804, 6080, 7210, 7850, ...   \n",
       "4  [0, 4971, 5560, 6266, 6791, 6976, 8440, 8939, ...   \n",
       "\n",
       "                                        phoneme_ends  \\\n",
       "0  [2190, 3300, 4400, 5235, 6620, 7326, 8040, 922...   \n",
       "1  [2040, 2440, 4428, 4840, 5973, 8600, 9608, 101...   \n",
       "2  [3000, 4386, 7506, 8981, 10109, 10750, 13201, ...   \n",
       "3  [2200, 2880, 4052, 4804, 6080, 7210, 7850, 832...   \n",
       "4  [4971, 5560, 6266, 6791, 6976, 8440, 8939, 107...   \n",
       "\n",
       "                                       cropped_audio  \n",
       "0  [2, -1, 0, 2, 1, 2, 3, 1, 0, 3, 1, -1, -1, 1, ...  \n",
       "1  [-1, -2, 0, 1, 0, 0, -1, -1, -1, -1, -2, 3, 3,...  \n",
       "2  [3, 0, -1, -3, -3, -2, -1, 1, -1, -1, -1, 0, 0...  \n",
       "3  [3, 2, 2, 1, 4, 5, 4, 8, 1, 4, 6, 0, 7, 5, 4, ...  \n",
       "4  [9, 8, 9, 13, 9, 14, 8, 11, 4, 4, 4, 4, 4, 4, ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the process_row function to each row in the DataFrame\n",
    "train_df['cropped_audio'] = train_df.apply(crop_audio, axis=1) \n",
    "train_df.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f20c11532b0>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize again, much better!\n",
    "plt.plot(train_df['cropped_audio'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ipa</th>\n",
       "      <th>audio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sʌmθiŋpʊldmaɪlɛɡ</td>\n",
       "      <td>[2, -1, 0, 2, 1, 2, 3, 1, 0, 3, 1, -1, -1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oʊnʔæskmitikɪɹiʔɛnʔɔɪliɹæɡlaɪkðæt</td>\n",
       "      <td>[-1, -2, 0, 1, 0, 0, -1, -1, -1, -1, -2, 3, 3,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wɛlnaʊwihævtubɪɡθiiɾɹz</td>\n",
       "      <td>[3, 0, -1, -3, -3, -2, -1, 1, -1, -1, -1, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vɛɹɪpikjujɹɹɛttʃɹbjuʃnindidsimztuoʊvɹteɪksʌttʃ...</td>\n",
       "      <td>[3, 2, 2, 1, 4, 5, 4, 8, 1, 4, 6, 0, 7, 5, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wiɡɑtdɹɛnttʃtfɹəmðɪʔʌɾiɾiɹʌpidɹeɪn</td>\n",
       "      <td>[9, 8, 9, 13, 9, 14, 8, 11, 4, 4, 4, 4, 4, 4, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 ipa  \\\n",
       "0                                   sʌmθiŋpʊldmaɪlɛɡ   \n",
       "1                  oʊnʔæskmitikɪɹiʔɛnʔɔɪliɹæɡlaɪkðæt   \n",
       "2                             wɛlnaʊwihævtubɪɡθiiɾɹz   \n",
       "3  vɛɹɪpikjujɹɹɛttʃɹbjuʃnindidsimztuoʊvɹteɪksʌttʃ...   \n",
       "4                 wiɡɑtdɹɛnttʃtfɹəmðɪʔʌɾiɾiɹʌpidɹeɪn   \n",
       "\n",
       "                                               audio  \n",
       "0  [2, -1, 0, 2, 1, 2, 3, 1, 0, 3, 1, -1, -1, 1, ...  \n",
       "1  [-1, -2, 0, 1, 0, 0, -1, -1, -1, -1, -2, 3, 3,...  \n",
       "2  [3, 0, -1, -3, -3, -2, -1, 1, -1, -1, -1, 0, 0...  \n",
       "3  [3, 2, 2, 1, 4, 5, 4, 8, 1, 4, 6, 0, 7, 5, 4, ...  \n",
       "4  [9, 8, 9, 13, 9, 14, 8, 11, 4, 4, 4, 4, 4, 4, ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_df comprised of just cropped_audio and phonemes\n",
    "train_df = train_df.drop(columns=['phoneme_starts', 'phoneme_ends', 'audio'])\n",
    "# rename cropped audio to audio\n",
    "train_df = train_df.rename(columns={'cropped_audio': 'audio'})\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset.from_pandas(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extend Phoneme Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "timit_vocab = set(\"\".join(train_df['ipa']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ʊ', 'ɪ', 'ð', 'u', 'ŋ', 'o', 'n', 'i', 'j', 'ɡ', 's', 'f', 'a', 'p', 'e', 'k', 'ɾ', 'b', 'ʌ', 'æ', 'ʃ', 'ʔ', 'θ', 'l', 'ɹ', 'm', 'd', 'ɛ', 'ə', 'ʒ', 'h', 't', 'z', 'w', 'ɑ', 'v', 'ɔ'}\n"
     ]
    }
   ],
   "source": [
    "print(timit_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 267, 'E': 45, 'H': 72, 'I': 20, 'O': 305, 'U': 292, '[PAD]': 310, '[UNK]': 309, '_': 182, 'a': 53, 'ã': 125, 'b': 113, 'b̪': 177, 'b̪͡v': 289, 'b͡ꞵ': 287, 'c': 25, 'cʼ': 229, 'c͡ç': 66, 'd': 176, 'd̼': 118, 'd͡z': 263, 'd͡ð': 244, 'd͡ɮ': 18, 'd͡ʑ': 94, 'd͡ʒ': 280, 'e': 175, 'ẽ': 211, 'e̞': 114, 'ẽ̞': 265, 'f': 139, 'fʼ': 249, 'h': 179, 'i': 245, 'j': 215, 'k': 282, 'kxʼ': 281, 'kǀ': 41, 'kǁ': 61, 'kǂ': 21, 'kǃ': 70, 'kʘ': 79, 'kʼ': 39, 'k̚': 89, 'k͡p': 48, 'k͡x': 198, 'l': 303, 'm': 75, 'm̥': 172, 'n': 102, 'n̥': 28, 'n̼': 169, 'o': 117, 'õ': 119, 'o̞': 62, 'õ̞': 234, 'p': 259, 'pʼ': 286, 'p̚': 149, 'p̪': 273, 'p̪͡f': 105, 'p͡f': 225, 'p͡ɸ': 103, 'q': 130, 'qǀ': 302, 'qǁ': 126, 'qǂ': 299, 'qǃ': 37, 'qʘ': 261, 'qʼ': 58, 'q͡ʡ': 127, 'q͡χʼ': 291, 'q͡ꭓ': 4, 'r': 82, 'r̥': 34, 's': 247, 'sʼ': 200, 't': 307, 'tʼ': 183, 't̚': 241, 't̪͡θʼ': 216, 't̼': 87, 't͡s': 156, 't͡sʼ': 43, 't͡ɕ': 264, 't͡ɬ': 170, 't͡ɬʼ': 164, 't͡ʃ': 91, 't͡ʃʼ': 108, 't͡θ': 140, 'u': 154, 'ũ': 81, 'v': 243, 'w': 143, 'x': 133, 'xʼ': 129, 'y': 214, 'ỹ': 277, 'z': 271, '{': 251, '}': 74, 'ã': 99, 'ä': 165, 'ä̃': 115, 'æ': 191, 'æ̃': 217, 'ç': 71, 'ð': 69, 'ð̠': 192, 'ð̼': 9, 'õ': 157, 'ø': 47, 'ø̃': 46, 'ø̞': 112, 'ø̞̃': 12, 'ħ': 224, 'ĩ': 180, 'ŋ': 213, 'ŋǀ': 231, 'ŋǁ': 304, 'ŋǂ': 301, 'ŋǃ': 284, 'ŋʘ': 168, 'ŋ̊': 27, 'ŋ͡m': 296, 'œ': 29, 'œ̃': 153, 'ũ': 31, 'ɐ': 142, 'ɐ̃': 7, 'ɑ': 49, 'ɑ̃': 50, 'ɒ': 116, 'ɒ̃': 85, 'ɓ': 178, 'ɓ̥': 13, 'ɔ': 228, 'ɔ̃': 186, 'ɕ': 220, 'ɕʼ': 36, 'ɖ': 256, 'ɖ͡ʐ': 77, 'ɗ': 93, 'ɗ̥': 270, 'ɘ': 104, 'ɘ̃': 189, 'ə': 6, 'ə̃': 294, 'ɚ': 184, 'ɛ': 293, 'ɛ̃': 98, 'ɜ': 92, 'ɜ̃': 73, 'ɝ': 196, 'ɞ': 210, 'ɞ̃': 54, 'ɟ': 68, 'ɟ͡ʝ': 86, 'ɠ': 160, 'ɠ̊': 1, 'ɡ': 252, 'ɡǀ': 19, 'ɡǁ': 226, 'ɡǂ': 131, 'ɡǃ': 152, 'ɡʘ': 162, 'ɡ̆': 201, 'ɡ͡b': 185, 'ɡ͡ɣ': 78, 'ɢ': 195, 'ɢǀ': 88, 'ɢǁ': 258, 'ɢǂ': 64, 'ɢǃ': 308, 'ɢʘ': 107, 'ɢ̆': 123, 'ɢ͡ʁ': 111, 'ɣ': 219, 'ɤ': 194, 'ɤ̃': 17, 'ɤ̞': 187, 'ɤ̞̃': 60, 'ɥ': 24, 'ɥ̊': 135, 'ɧ': 246, 'ɨ': 40, 'ɨ̃': 109, 'ɪ': 8, 'ɪ̃': 97, 'ɬ': 121, 'ɬʼ': 3, 'ɭ': 290, 'ɭ˔': 279, 'ɭ̆': 236, 'ɭ̥̆': 240, 'ɮ': 266, 'ɯ': 275, 'ɯ̃': 300, 'ɰ': 208, 'ɱ': 295, 'ɲ': 128, 'ɲ̊': 197, 'ɳ': 63, 'ɳ̊': 144, 'ɴ': 136, 'ɴǀ': 101, 'ɴǁ': 14, 'ɴǂ': 238, 'ɴǃ': 147, 'ɴʘ': 221, 'ɵ': 95, 'ɵ̃': 51, 'ɶ': 145, 'ɶ̃': 146, 'ɸ': 166, 'ɸʼ': 306, 'ɹ': 223, 'ɹ̠˔': 202, 'ɹ̠̊˔': 173, 'ɺ': 76, 'ɺ̥': 181, 'ɻ': 163, 'ɻ˔': 30, 'ɻ̊˔': 42, 'ɽ': 254, 'ɽ̊': 218, 'ɾ': 232, 'ɾ̥': 120, 'ɾ̼': 32, 'ʀ': 52, 'ʀ̥': 148, 'ʁ': 239, 'ʂ': 242, 'ʂʼ': 110, 'ʃ': 253, 'ʃʼ': 230, 'ʄ': 132, 'ʄ̊': 155, 'ʈ': 199, 'ʈʼ': 44, 'ʈ͡ʂ': 190, 'ʈ͡ʂʼ': 67, 'ʉ': 80, 'ʉ̃': 250, 'ʊ': 83, 'ʊ̃': 205, 'ʋ': 106, 'ʌ': 272, 'ʌ̃': 158, 'ʍ': 141, 'ʎ': 276, 'ʎ̆': 84, 'ʎ̝': 262, 'ʎ̝̊': 59, 'ʏ': 23, 'ʏ̃': 237, 'ʐ': 209, 'ʑ': 137, 'ʒ': 171, 'ʔ': 10, 'ʔ̞': 257, 'ʔ͡h': 203, 'ʕ': 38, 'ʙ': 274, 'ʙ̥': 167, 'ʛ': 233, 'ʛ̥': 159, 'ʜ': 298, 'ʝ': 35, 'ʟ': 150, 'ʟ̆': 248, 'ʟ̝': 33, 'ʟ̝̊': 161, 'ʟ̠': 285, 'ʡ': 174, 'ʡʼ': 5, 'ʡ̆': 22, 'ʡ͡ʜ': 56, 'ʡ͡ʢ': 255, 'ʢ': 188, 'ʰ': 206, 'ʲ': 0, 'ʷ': 288, 'ː': 235, '˞': 90, 'ˠ': 122, 'ˡ': 16, 'ˣ': 96, 'ˤ': 15, '̃': 57, '̩': 204, 'β': 269, 'θ': 283, 'θʼ': 26, 'θ̠': 100, 'θ̼': 227, 'χ': 65, 'χʼ': 260, 'ᵐ': 124, 'ᵑ': 297, 'ᶑ': 212, 'ᶑ̊': 268, 'ᶬ': 151, 'ᶮ': 55, 'ᶯ': 207, 'ᶰ': 11, 'ᶿ': 138, 'ẽ': 2, 'ⁿ': 222, 'ⱱ': 134, 'ⱱ̟': 193, 'ꞎ': 278, '<s>': 311, '</s>': 312}\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(PRE_TRAINED_ID)\n",
    "vocab = tokenizer.get_vocab()\n",
    "# you will see how large the vocab is, we will resize our linear layer later to make it work for our smaller vocab\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens that are in timit but not in the pretrained model set()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "additional_vocab = timit_vocab.difference(set(vocab.keys()) | {' '})\n",
    "print(\"tokens that are in timit but not in the pretrained model\", additional_vocab)\n",
    "tokenizer.add_tokens(list(additional_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = AutoFeatureExtractor.from_pretrained(PRE_TRAINED_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't need to update the feature extractor since it has been pretrained on 16kHz audio which matches the TIMIT dataset.\n",
    "\n",
    "For datasets with different sampling rates, the feature extractor should be updated or the audio resampled (easier).\n",
    "\n",
    "This is also where code to add extra features (such as conditioning on speaker's native language etc.) would be added."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINE-TUNE!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Running experiment with linear layer resizing...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:ixpc45ut) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">linear_resize</strong> at: <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size/runs/ixpc45ut' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size/runs/ixpc45ut</a><br/> View project at: <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size</a><br/>Synced 4 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250113_072426-ixpc45ut/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:ixpc45ut). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/arunasrivastava/ML/notebooks/wandb/run-20250113_072746-o06ks8r4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size/runs/o06ks8r4' target=\"_blank\">linear_resize</a></strong> to <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size/runs/o06ks8r4' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size/runs/o06ks8r4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading pretrained model and processor...\n",
      "INFO:__main__:Initial vocabulary size: 313\n",
      "INFO:__main__:Linear layer output size: 41\n",
      "INFO:__main__:Splitting dataset into train and evaluation...\n",
      "Map (num_proc=4):   0%|          | 0/3696 [00:00<?, ? examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   2%|▏         | 82/3696 [00:04<01:31, 39.29 examples/s] /home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   8%|▊         | 284/3696 [00:07<00:39, 86.37 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):  18%|█▊        | 654/3696 [00:10<00:21, 140.33 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4): 100%|██████████| 3696/3696 [01:00<00:00, 60.70 examples/s] \n",
      "Map (num_proc=4):   0%|          | 0/924 [00:00<?, ? examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   2%|▏         | 18/924 [00:01<00:40, 22.29 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   8%|▊         | 75/924 [00:01<00:12, 68.64 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):  17%|█▋        | 158/924 [00:02<00:06, 122.40 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4): 100%|██████████| 924/924 [00:16<00:00, 57.53 examples/s] \n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 463\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m metrics_resize, metrics_no_resize\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 463\u001b[0m     \u001b[43mrun_experiments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimit_vocab\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[25], line 449\u001b[0m, in \u001b[0;36mrun_experiments\u001b[0;34m(train_df, timit_vocab)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# Experiment 1: With linear layer resizing\u001b[39;00m\n\u001b[1;32m    448\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning experiment with linear layer resizing...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 449\u001b[0m metrics_resize \u001b[38;5;241m=\u001b[39m \u001b[43mmain_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimit_vocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresize_linear\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;66;03m# Experiment 2: Without linear layer resizing\u001b[39;00m\n\u001b[1;32m    452\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning experiment without linear layer resizing...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[25], line 425\u001b[0m, in \u001b[0;36mmain_experiment\u001b[0;34m(train_df, timit_vocab, resize_linear)\u001b[0m\n\u001b[1;32m    415\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m    416\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    417\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    421\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[early_stopping]\n\u001b[1;32m    422\u001b[0m )\n\u001b[1;32m    424\u001b[0m \u001b[38;5;66;03m# Train and save metrics\u001b[39;00m\n\u001b[0;32m--> 425\u001b[0m train_result \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    426\u001b[0m metrics \u001b[38;5;241m=\u001b[39m train_result\u001b[38;5;241m.\u001b[39mmetrics\n\u001b[1;32m    428\u001b[0m \u001b[38;5;66;03m# Log final metrics\u001b[39;00m\n",
      "File \u001b[0;32m~/ML/venv/lib/python3.8/site-packages/transformers/trainer.py:2122\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2120\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2121\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2123\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2124\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2127\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ML/venv/lib/python3.8/site-packages/transformers/trainer.py:2474\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2471\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2473\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2474\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2477\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2478\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2479\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2480\u001b[0m ):\n\u001b[1;32m   2481\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2482\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/ML/venv/lib/python3.8/site-packages/transformers/trainer.py:3572\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3569\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3571\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3572\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3574\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3575\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3576\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3577\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3578\u001b[0m ):\n",
      "File \u001b[0;32m~/ML/venv/lib/python3.8/site-packages/transformers/trainer.py:3625\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3623\u001b[0m         loss_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_items_in_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_items_in_batch\n\u001b[1;32m   3624\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mloss_kwargs}\n\u001b[0;32m-> 3625\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3626\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/ML/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ML/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/ML/venv/lib/python3.8/site-packages/accelerate/utils/operations.py:820\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 820\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ML/venv/lib/python3.8/site-packages/accelerate/utils/operations.py:808\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 808\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/ML/venv/lib/python3.8/site-packages/torch/amp/autocast_mode.py:43\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:2229\u001b[0m, in \u001b[0;36mWav2Vec2ForCTC.forward\u001b[0;34m(self, input_values, attention_mask, output_attentions, output_hidden_states, return_dict, labels)\u001b[0m\n\u001b[1;32m   2226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m labels\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mvocab_size:\n\u001b[1;32m   2227\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabel values must be <= vocab_size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mvocab_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2229\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwav2vec2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2230\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2231\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2232\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2233\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2235\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2237\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   2238\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n",
      "File \u001b[0;32m~/ML/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ML/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1815\u001b[0m, in \u001b[0;36mWav2Vec2Model.forward\u001b[0;34m(self, input_values, attention_mask, mask_time_indices, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1811\u001b[0m extract_features \u001b[38;5;241m=\u001b[39m extract_features\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m   1813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1814\u001b[0m     \u001b[38;5;66;03m# compute reduced attention_mask corresponding to feature vectors\u001b[39;00m\n\u001b[0;32m-> 1815\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_feature_vector_attention_mask\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1816\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextract_features\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_adapter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m   1817\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1819\u001b[0m hidden_states, extract_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_projection(extract_features)\n\u001b[1;32m   1820\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mask_hidden_states(\n\u001b[1;32m   1821\u001b[0m     hidden_states, mask_time_indices\u001b[38;5;241m=\u001b[39mmask_time_indices, attention_mask\u001b[38;5;241m=\u001b[39mattention_mask\n\u001b[1;32m   1822\u001b[0m )\n",
      "File \u001b[0;32m~/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1415\u001b[0m, in \u001b[0;36mWav2Vec2PreTrainedModel._get_feature_vector_attention_mask\u001b[0;34m(self, feature_vector_length, attention_mask, add_adapter)\u001b[0m\n\u001b[1;32m   1411\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\n\u001b[1;32m   1412\u001b[0m     (batch_size, feature_vector_length), dtype\u001b[38;5;241m=\u001b[39mattention_mask\u001b[38;5;241m.\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mattention_mask\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m   1413\u001b[0m )\n\u001b[1;32m   1414\u001b[0m \u001b[38;5;66;03m# these two operations makes sure that all values before the output lengths idxs are attended to\u001b[39;00m\n\u001b[0;32m-> 1415\u001b[0m \u001b[43mattention_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_lengths\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1416\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m attention_mask\u001b[38;5;241m.\u001b[39mflip([\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mcumsum(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mflip([\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mbool()\n\u001b[1;32m   1417\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m attention_mask\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import tempfile\n",
    "from transformers import AutoProcessor, AutoModelForCTC, Trainer, TrainingArguments, Wav2Vec2CTCTokenizer\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional, Union\n",
    "import logging\n",
    "from torch.utils.data import DataLoader\n",
    "import wandb\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchaudio\n",
    "import json\n",
    "from transformers.trainer_callback import EarlyStoppingCallback\n",
    "\n",
    "#B1- LESS TRAINING EPOCHS\n",
    "#B2- LENGTH PENALTY \n",
    "#B3- MORE TRAINING EPOCHS\n",
    "\n",
    "NEW_MODEL_ID = \"./notebooks/results-b0\"\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Constants\n",
    "SAMPLING_RATE = 16000\n",
    "MAX_AUDIO_LENGTH = 160000  # 10 seconds at 16kHz\n",
    "MAX_LABEL_LENGTH = 100\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorCTCWithPadding:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs received.\n",
    "    \"\"\"\n",
    "    processor: AutoProcessor\n",
    "    padding: Union[bool, str] = \"longest\"\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # Add max length check\n",
    "        max_length = min(\n",
    "            max(len(feature[\"input_values\"]) for feature in features),\n",
    "            MAX_AUDIO_LENGTH\n",
    "        )\n",
    "        # Pad input_values\n",
    "        padded_inputs = []\n",
    "        attention_mask = []\n",
    "        for feature in features:\n",
    "            input_length = len(feature[\"input_values\"])\n",
    "            padding_length = max_length - input_length\n",
    "            \n",
    "            # Convert to tensor and ensure correct shape\n",
    "            if isinstance(feature[\"input_values\"], list):\n",
    "                input_values = torch.tensor(feature[\"input_values\"])\n",
    "            else:\n",
    "                input_values = feature[\"input_values\"]\n",
    "            \n",
    "            # Remove any extra dimensions and ensure it's 1D\n",
    "            input_values = input_values.squeeze()\n",
    "            \n",
    "            # Pad with zeros\n",
    "            if padding_length > 0:\n",
    "                padded_input = torch.nn.functional.pad(input_values, (0, padding_length))\n",
    "                attention_mask.append(torch.cat([torch.ones(input_length), torch.zeros(padding_length)]))\n",
    "            else:\n",
    "                padded_input = input_values\n",
    "                attention_mask.append(torch.ones(input_length))\n",
    "            \n",
    "            padded_inputs.append(padded_input)\n",
    "\n",
    "        # Stack all padded inputs\n",
    "        batch = {\n",
    "            \"input_values\": torch.stack(padded_inputs),\n",
    "            \"attention_mask\": torch.stack(attention_mask)\n",
    "        }\n",
    "\n",
    "        # Process labels\n",
    "        with self.processor.as_target_processor():\n",
    "            label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "            labels_batch = self.processor.pad(\n",
    "                label_features,\n",
    "                padding=self.padding,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "\n",
    "        # Replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch\n",
    "\n",
    "def prepare_model_and_processor(timit_vocab):\n",
    "    \"\"\"\n",
    "    Original function that resizes the linear layer to match TIMIT vocab.\n",
    "    \"\"\"\n",
    "    logger.info(\"Loading pretrained model and processor...\")\n",
    "    \n",
    "    processor = AutoProcessor.from_pretrained(PRE_TRAINED_ID)\n",
    "    model = AutoModelForCTC.from_pretrained(PRE_TRAINED_ID)\n",
    "    \n",
    "    # Store the old vocabulary before making any changes\n",
    "    old_vocab = processor.tokenizer.get_vocab()\n",
    "    logger.info(f\"Initial vocabulary size: {len(old_vocab)}\")\n",
    "    \n",
    "    # Define fixed special token IDs - pad token first for CTC\n",
    "    special_tokens = {\n",
    "        \"<pad>\": 0,  # Changed to 0 for CTC blank token\n",
    "        \"<s>\": 1,    # Shifted up\n",
    "        \"</s>\": 2,   # Shifted up\n",
    "        \"<unk>\": 3   # Shifted up\n",
    "    }\n",
    "    \n",
    "    # Get regular tokens (excluding special tokens)\n",
    "    regular_tokens = sorted(list(timit_vocab - set(special_tokens.keys())))\n",
    "    \n",
    "    # Create combined vocabulary with fixed IDs\n",
    "    vocab = {**special_tokens}  # Start with special tokens\n",
    "    \n",
    "    # Add regular tokens after special tokens\n",
    "    for idx, token in enumerate(regular_tokens):\n",
    "        vocab[token] = idx + len(special_tokens)\n",
    "    \n",
    "    # Create tokenizer config\n",
    "    tokenizer_config = {\n",
    "        \"vocab\": vocab,\n",
    "        \"pad_token\": \"<pad>\",\n",
    "        \"bos_token\": \"<s>\",\n",
    "        \"eos_token\": \"</s>\",\n",
    "        \"unk_token\": \"<unk>\",\n",
    "    }\n",
    "    \n",
    "    # Save vocab to temporary file\n",
    "    with tempfile.NamedTemporaryFile(mode='w', delete=False) as f:\n",
    "        json.dump(vocab, f)\n",
    "        vocab_path = f.name\n",
    "    \n",
    "    # Create new tokenizer\n",
    "    new_tokenizer = Wav2Vec2CTCTokenizer(\n",
    "        vocab_path,\n",
    "        **{k: v for k, v in tokenizer_config.items() if k != \"vocab\"}\n",
    "    )\n",
    "    \n",
    "    # Update processor with new tokenizer\n",
    "    processor.tokenizer = new_tokenizer\n",
    "    os.remove(vocab_path)\n",
    "    \n",
    "    # Handle model weights\n",
    "    old_weights = model.lm_head.weight.data\n",
    "    old_bias = model.lm_head.bias.data\n",
    "    \n",
    "    # Create new layer with smaller size\n",
    "    new_layer = torch.nn.Linear(model.lm_head.in_features, len(processor.tokenizer))\n",
    "    new_layer.weight.data.zero_()\n",
    "    new_layer.bias.data.zero_()\n",
    "    \n",
    "    # Transfer weights and bias using the stored old_vocab\n",
    "    for token, new_idx in new_tokenizer.get_vocab().items():\n",
    "        if token in old_vocab:\n",
    "            old_idx = old_vocab[token]\n",
    "            new_layer.weight.data[new_idx, :] = old_weights[old_idx, :]\n",
    "            new_layer.bias.data[new_idx] = old_bias[old_idx]\n",
    "    \n",
    "    model.lm_head = new_layer\n",
    "    model.config.vocab_size = len(processor.tokenizer)\n",
    "    model.config.pad_token_id = 0\n",
    "    \n",
    "    return model, processor\n",
    "\n",
    "def prepare_model_and_processor_no_resize(timit_vocab):\n",
    "    \"\"\"\n",
    "    New function that keeps the original linear layer size.\n",
    "    \"\"\"\n",
    "    logger.info(\"Loading pretrained model and processor (no resize version)...\")\n",
    "    \n",
    "    processor = AutoProcessor.from_pretrained(PRE_TRAINED_ID)\n",
    "    model = AutoModelForCTC.from_pretrained(PRE_TRAINED_ID)\n",
    "    \n",
    "    # Store the old vocabulary\n",
    "    old_vocab = processor.tokenizer.get_vocab()\n",
    "    logger.info(f\"Initial vocabulary size: {len(old_vocab)}\")\n",
    "    original_vocab_size = len(old_vocab)\n",
    "    \n",
    "    # Define fixed special token IDs\n",
    "    special_tokens = {\n",
    "        \"<pad>\": 0,\n",
    "        \"<s>\": 1,\n",
    "        \"</s>\": 2,\n",
    "        \"<unk>\": 3\n",
    "    }\n",
    "    \n",
    "    # Create new vocabulary mapping while keeping original size\n",
    "    vocab = {**special_tokens}\n",
    "    \n",
    "    # Add TIMIT tokens after special tokens\n",
    "    regular_tokens = sorted(list(timit_vocab - set(special_tokens.keys())))\n",
    "    for idx, token in enumerate(regular_tokens):\n",
    "        vocab[token] = idx + len(special_tokens)\n",
    "        \n",
    "    # Fill remaining indices with unused tokens to maintain original size\n",
    "    current_size = len(vocab)\n",
    "    for i in range(current_size, original_vocab_size):\n",
    "        vocab[f\"<unused{i}>\"] = i\n",
    "        \n",
    "    # Save vocab to temporary file\n",
    "    with tempfile.NamedTemporaryFile(mode='w', delete=False) as f:\n",
    "        json.dump(vocab, f)\n",
    "        vocab_path = f.name\n",
    "    \n",
    "    # Create new tokenizer\n",
    "    tokenizer_config = {\n",
    "        \"pad_token\": \"<pad>\",\n",
    "        \"bos_token\": \"<s>\",\n",
    "        \"eos_token\": \"</s>\",\n",
    "        \"unk_token\": \"<unk>\",\n",
    "    }\n",
    "    \n",
    "    new_tokenizer = Wav2Vec2CTCTokenizer(\n",
    "        vocab_path,\n",
    "        **tokenizer_config\n",
    "    )\n",
    "    \n",
    "    # Update processor with new tokenizer\n",
    "    processor.tokenizer = new_tokenizer\n",
    "    os.remove(vocab_path)\n",
    "    \n",
    "    # Keep original linear layer - no resizing\n",
    "    logger.info(f\"Linear layer size maintained at: {model.lm_head.out_features}\")\n",
    "    \n",
    "    return model, processor\n",
    "\n",
    "def preprocess_audio(audio_input):\n",
    "    \"\"\"\n",
    "    Load and preprocess audio to match expected format.\n",
    "    \"\"\"\n",
    "    # Handle different input types\n",
    "    if isinstance(audio_input, str):  # File path\n",
    "        waveform, sample_rate = torchaudio.load(audio_input)\n",
    "        audio_numpy = waveform.squeeze().numpy()\n",
    "        \n",
    "    elif isinstance(audio_input, list):  # List input\n",
    "        audio_numpy = np.array(audio_input, dtype=np.float32)\n",
    "        \n",
    "    elif isinstance(audio_input, np.ndarray):  # Already numpy array\n",
    "        audio_numpy = audio_input\n",
    "        \n",
    "    elif isinstance(audio_input, torch.Tensor):  # Torch tensor\n",
    "        audio_numpy = audio_input.numpy()\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported audio type: {type(audio_input)}\")\n",
    "    \n",
    "    # Ensure float32 dtype\n",
    "    audio_numpy = audio_numpy.astype(np.float32)\n",
    "    \n",
    "    # Ensure 1D array\n",
    "    if len(audio_numpy.shape) > 1:\n",
    "        audio_numpy = np.mean(audio_numpy, axis=0)\n",
    "    \n",
    "    # Normalize audio\n",
    "    if np.abs(audio_numpy).max() > 1:\n",
    "        audio_numpy = audio_numpy / np.abs(audio_numpy).max()\n",
    "    \n",
    "    # Trim or pad to max length\n",
    "    if len(audio_numpy) > MAX_AUDIO_LENGTH:\n",
    "        audio_numpy = audio_numpy[:MAX_AUDIO_LENGTH]\n",
    "    elif len(audio_numpy) < MAX_AUDIO_LENGTH:\n",
    "        padding = np.zeros(MAX_AUDIO_LENGTH - len(audio_numpy), dtype=np.float32)\n",
    "        audio_numpy = np.concatenate([audio_numpy, padding])\n",
    "    \n",
    "    return audio_numpy\n",
    "\n",
    "def prepare_datasets(train_df, processor):\n",
    "    \"\"\"\n",
    "    Dataset preparation compatible with original data collator\n",
    "    \"\"\"\n",
    "    logger.info(\"Splitting dataset into train and evaluation...\")\n",
    "    \n",
    "    train_data, eval_data = train_test_split(train_df, test_size=0.2, random_state=42)\n",
    "    \n",
    "    def process_data(batch):\n",
    "        # Preprocess audio\n",
    "        audio = preprocess_audio(batch[\"audio\"])\n",
    "        audio = audio.squeeze()\n",
    "        \n",
    "        # Process audio without any padding or tensor conversion\n",
    "        inputs = processor(\n",
    "            audio, \n",
    "            sampling_rate=SAMPLING_RATE, \n",
    "            return_tensors=None\n",
    "        )\n",
    "        \n",
    "        input_values = np.squeeze(inputs[\"input_values\"])\n",
    "        \n",
    "        # Process labels without any padding or tensor conversion\n",
    "        with processor.as_target_processor():\n",
    "            labels = processor(batch[\"ipa\"]).input_ids\n",
    "        \n",
    "        return {\n",
    "            \"input_values\": input_values,\n",
    "            \"labels\": labels,\n",
    "            \"audio\": audio\n",
    "        }\n",
    "    \n",
    "    # Convert DataFrames to Datasets with optimized batch processing\n",
    "    train_dataset = Dataset.from_pandas(train_data)\n",
    "    eval_dataset = Dataset.from_pandas(eval_data)\n",
    "    \n",
    "    # Apply processing with larger batches\n",
    "    train_dataset = train_dataset.map(\n",
    "        process_data,\n",
    "        batch_size=32,\n",
    "        num_proc=4,\n",
    "        remove_columns=[col for col in train_dataset.column_names if col != \"audio\"]\n",
    "    )\n",
    "    eval_dataset = eval_dataset.map(\n",
    "        process_data,\n",
    "        batch_size=32,\n",
    "        num_proc=4,\n",
    "        remove_columns=[col for col in eval_dataset.column_names if col != \"audio\"]\n",
    "    )\n",
    "    \n",
    "    return train_dataset, eval_dataset\n",
    "\n",
    "def verify_dimensions(batch, logger):\n",
    "    \"\"\"Debug helper to verify tensor dimensions\"\"\"\n",
    "    logger.info(\"Batch dimensions:\")\n",
    "    for key, value in batch.items():\n",
    "        if isinstance(value, torch.Tensor):\n",
    "            logger.info(f\"{key}: {value.shape}\")\n",
    "\n",
    "def verify_token_ids(processor, stage=\"\"):\n",
    "    \"\"\"Simple token verification function\"\"\"\n",
    "    logger.info(f\"\\n=== Token ID Verification [{stage}] ===\")\n",
    "    vocab = processor.tokenizer.get_vocab()\n",
    "    logger.info(f\"Vocabulary size: {len(vocab)}\")\n",
    "    \n",
    "    # Check special tokens\n",
    "    special_tokens = [\"<pad>\", \"<s>\", \"</s>\", \"<unk>\"]\n",
    "    for token in special_tokens:\n",
    "        token_id = vocab.get(token)\n",
    "        logger.info(f\"Token {token}: ID {token_id}\")\n",
    "    \n",
    "    # Sample a few regular tokens\n",
    "    regular_tokens = [t for t in list(vocab.keys())[:5] if t not in special_tokens]\n",
    "    logger.info(\"Sample regular token IDs:\")\n",
    "    for token in regular_tokens:\n",
    "        logger.info(f\"Token {token}: ID {vocab[token]}\")\n",
    "    \n",
    "    return vocab\n",
    "\n",
    "def main_experiment(train_df, timit_vocab, resize_linear=False):\n",
    "    \"\"\"\n",
    "    Modified main function to run experiments with and without linear layer resizing\n",
    "    \"\"\"\n",
    "    experiment_name = \"linear_resize\" if resize_linear else \"linear_no_resize\"\n",
    "    wandb.init(project=\"xlsr-buckeye-phoneme-prediction-linear-size\", name=experiment_name)\n",
    "    \n",
    "    # Choose model preparation function based on experiment\n",
    "    if resize_linear:\n",
    "        model, processor = prepare_model_and_processor(timit_vocab)  # Original function\n",
    "    else:\n",
    "        model, processor = prepare_model_and_processor_no_resize(timit_vocab)  # New function\n",
    "    \n",
    "    # Log linear layer size\n",
    "    logger.info(f\"Linear layer output size: {model.lm_head.out_features}\")\n",
    "    wandb.log({\"linear_layer_size\": model.lm_head.out_features})\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.gradient_checkpointing_enable()\n",
    "    \n",
    "    train_dataset, eval_dataset = prepare_datasets(train_df, processor)\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"./results-{experiment_name}\",\n",
    "        learning_rate=8e-5,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        gradient_accumulation_steps=4,\n",
    "        max_grad_norm=0.907,\n",
    "        adam_beta1=0.93287,\n",
    "        adam_beta2=0.96748,\n",
    "        warmup_ratio=0.08253,\n",
    "        lr_scheduler_type=\"cosine_with_restarts\",\n",
    "        num_train_epochs=40,\n",
    "        logging_dir='./logs',\n",
    "        logging_steps=10,\n",
    "        save_steps=300,\n",
    "        eval_steps=50,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"eval_loss\",\n",
    "        greater_is_better=False,\n",
    "        save_safetensors=True,\n",
    "        save_strategy=\"steps\",\n",
    "        save_total_limit=3,\n",
    "        fp16=True,\n",
    "        dataloader_num_workers=4,\n",
    "        dataloader_pin_memory=True,\n",
    "        gradient_checkpointing=True,\n",
    "    )\n",
    "    \n",
    "    data_collator = DataCollatorCTCWithPadding(\n",
    "        processor=processor,\n",
    "        padding=\"longest\"\n",
    "    )\n",
    "    \n",
    "    # Add early stopping callback\n",
    "    early_stopping = EarlyStoppingCallback(\n",
    "        early_stopping_patience=5,\n",
    "        early_stopping_threshold=0.01\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        data_collator=data_collator,\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "    \n",
    "    # Train and save metrics\n",
    "    train_result = trainer.train()\n",
    "    metrics = train_result.metrics\n",
    "    \n",
    "    # Log final metrics\n",
    "    wandb.log({\n",
    "        \"final_train_loss\": metrics[\"train_loss\"],\n",
    "        \"vocab_size\": len(processor.tokenizer.get_vocab()),\n",
    "        \"linear_size\": model.lm_head.out_features\n",
    "    })\n",
    "    \n",
    "    # Save the final model and processor\n",
    "    model.save_pretrained(f\"./results-{experiment_name}\")\n",
    "    processor.save_pretrained(f\"./results-{experiment_name}\")\n",
    "    \n",
    "    wandb.finish()\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def run_experiments(train_df, timit_vocab):\n",
    "    \"\"\"\n",
    "    Run both experiments and compare results\n",
    "    \"\"\"\n",
    "    # Experiment 1: With linear layer resizing\n",
    "    logger.info(\"Running experiment with linear layer resizing...\")\n",
    "    metrics_resize = main_experiment(train_df, timit_vocab, resize_linear=True)\n",
    "    \n",
    "    # Experiment 2: Without linear layer resizing\n",
    "    logger.info(\"Running experiment without linear layer resizing...\")\n",
    "    metrics_no_resize = main_experiment(train_df, timit_vocab, resize_linear=False)\n",
    "    \n",
    "    # Compare results\n",
    "    logger.info(\"\\nExperiment Results Comparison:\")\n",
    "    logger.info(f\"With resizing - Final loss: {metrics_resize['train_loss']:.4f}\")\n",
    "    logger.info(f\"Without resizing - Final loss: {metrics_no_resize['train_loss']:.4f}\")\n",
    "    \n",
    "    return metrics_resize, metrics_no_resize\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_experiments(train_df, timit_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model on Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 1.26G/1.26G [00:27<00:00, 45.1MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForCTC, Wav2Vec2Processor\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Log in to Hugging Face (if not already logged in)\n",
    "# login(\"your-huggingface-api-token\")\n",
    "\n",
    "# Load the model and processor from your local directory\n",
    "model = AutoModelForCTC.from_pretrained(\"/home/arunasrivastava/ML/notebooks/results-b0\")\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"/home/arunasrivastava/ML/notebooks/results-b0\")\n",
    "\n",
    "# Specify the directory where you want to save the model\n",
    "save_directory = \"./xlsr-timit-b0\"\n",
    "\n",
    "# Save and upload to Hugging Face Model Hub under an organization\n",
    "model.save_pretrained(save_directory, push_to_hub=True, repo_id=\"KoelLabs/xlsr-timit-b0\")\n",
    "processor.save_pretrained(save_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions to Upload Model to Hugging Face\n",
    "\n",
    "1. **Login to Hugging Face**  \n",
    "   Run the following command to log in to your Hugging Face account:\n",
    "   ```bash\n",
    "   huggingface-cli login\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Create a Repository**  \n",
    "   Run the following command to log in to your Hugging Face account:\n",
    "   ```bash\n",
    "   huggingface-cli repo create your-model-name --organization your-org-name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Git clone**  \n",
    "   Run the following command to clone your repo:\n",
    "   ```bash \n",
    "   git clone https://huggingface.co/your-org-name/your-model-name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Upload Model**  (if you did not make it on Hugging Face already)\n",
    "   Run the following command to clone your repo:\n",
    "   ```bash \n",
    "   huggingface-cli repo upload --path ./<path here>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **Move Other Files**  \n",
    "   Run the following command to copy each file into the repo:\n",
    "   ```bash\n",
    "   cp -r ./<path here> <your-cloned-repo-folder> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. **Stage & Commit!**\n",
    "    Run the following git commands\n",
    "    ```bash\n",
    "    git add README.md\n",
    "    git commit -m \"Add model card\"\n",
    "    git push\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YAAAAY CONGRATULATIONS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Optional) Hyperparam search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Using cached optuna-4.1.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: joblib in /home/arunasrivastava/ML/venv/lib/python3.8/site-packages (1.4.2)\n",
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Using cached alembic-1.14.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: colorlog in /home/arunasrivastava/ML/venv/lib/python3.8/site-packages (from optuna) (6.8.2)\n",
      "Requirement already satisfied: numpy in /home/arunasrivastava/ML/venv/lib/python3.8/site-packages (from optuna) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/arunasrivastava/ML/venv/lib/python3.8/site-packages (from optuna) (24.1)\n",
      "Collecting sqlalchemy>=1.4.2 (from optuna)\n",
      "  Downloading SQLAlchemy-2.0.37-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: tqdm in /home/arunasrivastava/ML/venv/lib/python3.8/site-packages (from optuna) (4.66.5)\n",
      "Requirement already satisfied: PyYAML in /home/arunasrivastava/ML/venv/lib/python3.8/site-packages (from optuna) (5.4.1)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna)\n",
      "  Downloading Mako-1.3.8-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4 in /home/arunasrivastava/ML/venv/lib/python3.8/site-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
      "Requirement already satisfied: importlib-metadata in /home/arunasrivastava/ML/venv/lib/python3.8/site-packages (from alembic>=1.5.0->optuna) (8.5.0)\n",
      "Requirement already satisfied: importlib-resources in /home/arunasrivastava/ML/venv/lib/python3.8/site-packages (from alembic>=1.5.0->optuna) (6.4.5)\n",
      "Collecting greenlet!=0.4.17 (from sqlalchemy>=1.4.2->optuna)\n",
      "  Using cached greenlet-3.1.1-cp38-cp38-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/arunasrivastava/ML/venv/lib/python3.8/site-packages (from importlib-metadata->alembic>=1.5.0->optuna) (3.20.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /home/arunasrivastava/ML/venv/lib/python3.8/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
      "Using cached optuna-4.1.0-py3-none-any.whl (364 kB)\n",
      "Using cached alembic-1.14.0-py3-none-any.whl (233 kB)\n",
      "Downloading SQLAlchemy-2.0.37-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached greenlet-3.1.1-cp38-cp38-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (605 kB)\n",
      "Downloading Mako-1.3.8-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: Mako, greenlet, sqlalchemy, alembic, optuna\n",
      "Successfully installed Mako-1.3.8 alembic-1.14.0 greenlet-3.1.1 optuna-4.1.0 sqlalchemy-2.0.37\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install optuna joblib\n",
    "# you can use WADNB sweeps as well, whatever is easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-13 07:40:09,243] A new study created in memory with name: linear_size_study_resize\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running hyperparameter search for resize model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:o06ks8r4) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>linear_layer_size</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>linear_layer_size</td><td>41</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">linear_resize</strong> at: <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size/runs/o06ks8r4' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size/runs/o06ks8r4</a><br/> View project at: <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250113_072746-o06ks8r4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:o06ks8r4). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/arunasrivastava/ML/notebooks/wandb/run-20250113_074009-hsdbup90</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size/runs/hsdbup90' target=\"_blank\">trial_0_resize</a></strong> to <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size/runs/hsdbup90' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size/runs/hsdbup90</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading pretrained model and processor...\n",
      "INFO:__main__:Initial vocabulary size: 313\n",
      "INFO:__main__:Splitting dataset into train and evaluation...\n",
      "Map (num_proc=4):   0%|          | 0/3696 [00:00<?, ? examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   2%|▏         | 73/3696 [00:04<01:34, 38.24 examples/s] /home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   7%|▋         | 243/3696 [00:06<00:37, 91.53 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):  15%|█▌        | 567/3696 [00:09<00:25, 124.07 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4): 100%|██████████| 3696/3696 [01:02<00:00, 59.27 examples/s] \n",
      "Map (num_proc=4):   0%|          | 0/924 [00:00<?, ? examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   4%|▍         | 35/924 [00:01<00:25, 34.37 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):  11%|█▏        | 104/924 [00:02<00:09, 82.10 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):  25%|██▌       | 234/924 [00:03<00:05, 125.87 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4): 100%|██████████| 924/924 [00:15<00:00, 58.20 examples/s] \n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2000' max='2310' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2000/2310 21:16 < 03:18, 1.57 it/s, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>61.476600</td>\n",
       "      <td>29.202192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>36.989100</td>\n",
       "      <td>15.681354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>26.911000</td>\n",
       "      <td>13.207084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>27.132300</td>\n",
       "      <td>10.979404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>25.825100</td>\n",
       "      <td>9.804962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>17.334500</td>\n",
       "      <td>10.308441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>20.837100</td>\n",
       "      <td>9.279531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>19.357400</td>\n",
       "      <td>9.486718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>23.255700</td>\n",
       "      <td>9.092893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>21.617200</td>\n",
       "      <td>8.871961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>18.542700</td>\n",
       "      <td>9.427045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>19.358800</td>\n",
       "      <td>9.294700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>20.789000</td>\n",
       "      <td>8.671291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>18.973600</td>\n",
       "      <td>8.839470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>22.218900</td>\n",
       "      <td>9.043280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>21.720100</td>\n",
       "      <td>9.260453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>19.838300</td>\n",
       "      <td>8.809546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>20.423500</td>\n",
       "      <td>8.941749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>19.092000</td>\n",
       "      <td>9.024729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>16.642300</td>\n",
       "      <td>9.024844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='231' max='231' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [231/231 00:26]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_eval_loss</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▃▃▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▃▅▆▄▄█▆▄▂▅▅▂▅▆▃▁▄▃▆▂▃</td></tr><tr><td>eval/samples_per_second</td><td>▅▃▃▅▅▁▃▅▇▄▄▆▄▃▅█▅▆▂▇▆</td></tr><tr><td>eval/steps_per_second</td><td>▅▃▃▅▅▁▃▅▇▄▄▆▄▃▅█▅▆▂▇▆</td></tr><tr><td>final_train_loss</td><td>▁</td></tr><tr><td>hp_adam_beta1</td><td>▁</td></tr><tr><td>hp_adam_beta2</td><td>▁</td></tr><tr><td>hp_adam_epsilon</td><td>▁</td></tr><tr><td>hp_batch_size</td><td>▁</td></tr><tr><td>hp_gradient_accumulation_steps</td><td>▁</td></tr><tr><td>hp_learning_rate</td><td>▁</td></tr><tr><td>hp_max_grad_norm</td><td>▁</td></tr><tr><td>hp_warmup_ratio</td><td>▁</td></tr><tr><td>hp_weight_decay</td><td>▁</td></tr><tr><td>linear_layer_size</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>train/grad_norm</td><td>█▄▂▆▁▁▁▂▁▂▁▁▁▁▁▂▂▁▂▂▃▁▃▁▁▂▁▁▁▁▁▂▁▄▁▁▁▂▂▁</td></tr><tr><td>train/learning_rate</td><td>▁▃▄▅▆▇███████▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▇▅▄▃▃▃▃▂▂▂▁▁▂▂▂▂▂▂▂▁▁▂▂▂▂▁▂▂▂▁▂▂▂▁▂▁▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_eval_loss</td><td>8.87196</td></tr><tr><td>eval/loss</td><td>8.87196</td></tr><tr><td>eval/runtime</td><td>27.9448</td></tr><tr><td>eval/samples_per_second</td><td>33.065</td></tr><tr><td>eval/steps_per_second</td><td>8.266</td></tr><tr><td>final_train_loss</td><td>23.87516</td></tr><tr><td>hp_adam_beta1</td><td>0.85206</td></tr><tr><td>hp_adam_beta2</td><td>0.99753</td></tr><tr><td>hp_adam_epsilon</td><td>0.0</td></tr><tr><td>hp_batch_size</td><td>4</td></tr><tr><td>hp_gradient_accumulation_steps</td><td>2</td></tr><tr><td>hp_learning_rate</td><td>1e-05</td></tr><tr><td>hp_max_grad_norm</td><td>1.56211</td></tr><tr><td>hp_warmup_ratio</td><td>0.13662</td></tr><tr><td>hp_weight_decay</td><td>0.01593</td></tr><tr><td>linear_layer_size</td><td>41</td></tr><tr><td>total_flos</td><td>4.8457842432e+18</td></tr><tr><td>train/epoch</td><td>4.329</td></tr><tr><td>train/global_step</td><td>2000</td></tr><tr><td>train/grad_norm</td><td>37.65573</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>16.6423</td></tr><tr><td>train_loss</td><td>23.87516</td></tr><tr><td>train_runtime</td><td>1277.4337</td></tr><tr><td>train_samples_per_second</td><td>14.467</td></tr><tr><td>train_steps_per_second</td><td>1.808</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_0_resize</strong> at: <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size/runs/hsdbup90' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size/runs/hsdbup90</a><br/> View project at: <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size</a><br/>Synced 4 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250113_074009-hsdbup90/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-13 08:03:41,925] Trial 0 finished with value: 8.871959686279297 and parameters: {'learning_rate': 5.611516415334504e-06, 'batch_size': 4, 'gradient_accumulation_steps': 2, 'warmup_ratio': 0.1366176145774935, 'weight_decay': 0.015930522616241012, 'max_grad_norm': 1.5621088666940683, 'adam_beta1': 0.8520584494295802, 'adam_beta2': 0.9975255827559377, 'adam_epsilon': 4.622589001020826e-08}. Best is trial 0 with value: 8.871959686279297.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/arunasrivastava/ML/notebooks/wandb/run-20250113_080341-elpma1sz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size/runs/elpma1sz' target=\"_blank\">trial_1_resize</a></strong> to <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size/runs/elpma1sz' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size/runs/elpma1sz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading pretrained model and processor...\n",
      "INFO:__main__:Initial vocabulary size: 313\n",
      "INFO:__main__:Splitting dataset into train and evaluation...\n",
      "Map (num_proc=4):   0%|          | 0/3696 [00:00<?, ? examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   1%|          | 31/3696 [00:04<03:24, 17.90 examples/s] /home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   7%|▋         | 251/3696 [00:08<00:28, 122.24 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):  14%|█▍        | 514/3696 [00:10<00:25, 127.17 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4): 100%|██████████| 3696/3696 [01:07<00:00, 54.43 examples/s] \n",
      "Map (num_proc=4):   0%|          | 0/924 [00:00<?, ? examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   2%|▏         | 18/924 [00:01<00:41, 22.09 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   7%|▋         | 64/924 [00:01<00:12, 68.01 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):  15%|█▍        | 138/924 [00:02<00:06, 113.77 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4): 100%|██████████| 924/924 [00:16<00:00, 56.45 examples/s] \n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='575' max='575' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [575/575 10:30, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>50.030400</td>\n",
       "      <td>16.777199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>28.933800</td>\n",
       "      <td>14.117034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>27.036400</td>\n",
       "      <td>13.478450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>27.121100</td>\n",
       "      <td>13.101134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>25.779700</td>\n",
       "      <td>12.938252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:20]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_eval_loss</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▃▂▁▁▁</td></tr><tr><td>eval/runtime</td><td>█▃█▄▁▆</td></tr><tr><td>eval/samples_per_second</td><td>▁▆▁▅█▃</td></tr><tr><td>eval/steps_per_second</td><td>▁▆▁▅█▃</td></tr><tr><td>final_train_loss</td><td>▁</td></tr><tr><td>hp_adam_beta1</td><td>▁</td></tr><tr><td>hp_adam_beta2</td><td>▁</td></tr><tr><td>hp_adam_epsilon</td><td>▁</td></tr><tr><td>hp_batch_size</td><td>▁</td></tr><tr><td>hp_gradient_accumulation_steps</td><td>▁</td></tr><tr><td>hp_learning_rate</td><td>▁</td></tr><tr><td>hp_max_grad_norm</td><td>▁</td></tr><tr><td>hp_warmup_ratio</td><td>▁</td></tr><tr><td>hp_weight_decay</td><td>▁</td></tr><tr><td>linear_layer_size</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▂▂▂▃▃▄▄▄▅▆▆▆▇▇███</td></tr><tr><td>train/global_step</td><td>▁▂▂▂▃▃▄▄▄▅▆▆▆▇▇████</td></tr><tr><td>train/grad_norm</td><td>█▄▃▄▂▄▂▁▂▂▂</td></tr><tr><td>train/learning_rate</td><td>▅██▇▆▅▄▃▂▁▁</td></tr><tr><td>train/loss</td><td>█▅▂▂▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_eval_loss</td><td>12.94451</td></tr><tr><td>eval/loss</td><td>12.94451</td></tr><tr><td>eval/runtime</td><td>24.2839</td></tr><tr><td>eval/samples_per_second</td><td>38.05</td></tr><tr><td>eval/steps_per_second</td><td>2.388</td></tr><tr><td>final_train_loss</td><td>33.25582</td></tr><tr><td>hp_adam_beta1</td><td>0.88664</td></tr><tr><td>hp_adam_beta2</td><td>0.97235</td></tr><tr><td>hp_adam_epsilon</td><td>0.0</td></tr><tr><td>hp_batch_size</td><td>16</td></tr><tr><td>hp_gradient_accumulation_steps</td><td>2</td></tr><tr><td>hp_learning_rate</td><td>0.0</td></tr><tr><td>hp_max_grad_norm</td><td>0.93822</td></tr><tr><td>hp_warmup_ratio</td><td>0.11119</td></tr><tr><td>hp_weight_decay</td><td>0.0019</td></tr><tr><td>linear_layer_size</td><td>41</td></tr><tr><td>total_flos</td><td>5.57265187968e+18</td></tr><tr><td>train/epoch</td><td>4.97835</td></tr><tr><td>train/global_step</td><td>575</td></tr><tr><td>train/grad_norm</td><td>90.85894</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>26.8108</td></tr><tr><td>train_loss</td><td>33.25582</td></tr><tr><td>train_runtime</td><td>634.6476</td></tr><tr><td>train_samples_per_second</td><td>29.119</td></tr><tr><td>train_steps_per_second</td><td>0.906</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_1_resize</strong> at: <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size/runs/elpma1sz' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size/runs/elpma1sz</a><br/> View project at: <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250113_080341-elpma1sz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-13 08:16:12,608] Trial 1 finished with value: 12.944514274597168 and parameters: {'learning_rate': 2.6587543983272713e-06, 'batch_size': 16, 'gradient_accumulation_steps': 2, 'warmup_ratio': 0.11118528947223794, 'weight_decay': 0.0019010245319870357, 'max_grad_norm': 0.9382169728028272, 'adam_beta1': 0.8866361843293691, 'adam_beta2': 0.9723474292266348, 'adam_epsilon': 3.7183641805732076e-08}. Best is trial 0 with value: 8.871959686279297.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/arunasrivastava/ML/notebooks/wandb/run-20250113_081612-r8jzom36</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size/runs/r8jzom36' target=\"_blank\">trial_2_resize</a></strong> to <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size/runs/r8jzom36' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size/runs/r8jzom36</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading pretrained model and processor...\n",
      "INFO:__main__:Initial vocabulary size: 313\n",
      "INFO:__main__:Splitting dataset into train and evaluation...\n",
      "Map (num_proc=4):   0%|          | 0/3696 [00:00<?, ? examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   3%|▎         | 103/3696 [00:06<03:06, 19.30 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   8%|▊         | 312/3696 [00:08<00:42, 80.51 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):  20%|█▉        | 721/3696 [00:11<00:23, 128.67 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4): 100%|██████████| 3696/3696 [01:05<00:00, 56.83 examples/s] \n",
      "Map (num_proc=4):   0%|          | 0/924 [00:00<?, ? examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   3%|▎         | 24/924 [00:01<00:33, 26.65 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):  10%|▉         | 89/924 [00:02<00:10, 79.83 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):  22%|██▏       | 200/924 [00:03<00:05, 125.72 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4): 100%|██████████| 924/924 [00:17<00:00, 52.11 examples/s] \n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 13:30, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>64.383600</td>\n",
       "      <td>29.795015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>35.801400</td>\n",
       "      <td>14.905666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>26.158800</td>\n",
       "      <td>14.607113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>27.613300</td>\n",
       "      <td>13.430224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>27.589100</td>\n",
       "      <td>12.829280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>25.606700</td>\n",
       "      <td>12.540054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>24.772800</td>\n",
       "      <td>12.227273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>23.913500</td>\n",
       "      <td>12.071071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>24.275000</td>\n",
       "      <td>11.820246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>22.619800</td>\n",
       "      <td>11.732581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>24.066100</td>\n",
       "      <td>11.691442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='116' max='116' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [116/116 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_eval_loss</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▆▃▆▅▆█▅▅▅▆▅▁</td></tr><tr><td>eval/samples_per_second</td><td>▃▆▃▄▃▁▄▃▃▃▄█</td></tr><tr><td>eval/steps_per_second</td><td>▃▆▃▄▃▁▄▃▃▃▄█</td></tr><tr><td>final_train_loss</td><td>▁</td></tr><tr><td>hp_adam_beta1</td><td>▁</td></tr><tr><td>hp_adam_beta2</td><td>▁</td></tr><tr><td>hp_adam_epsilon</td><td>▁</td></tr><tr><td>hp_batch_size</td><td>▁</td></tr><tr><td>hp_gradient_accumulation_steps</td><td>▁</td></tr><tr><td>hp_learning_rate</td><td>▁</td></tr><tr><td>hp_max_grad_norm</td><td>▁</td></tr><tr><td>hp_warmup_ratio</td><td>▁</td></tr><tr><td>hp_weight_decay</td><td>▁</td></tr><tr><td>linear_layer_size</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇██████</td></tr><tr><td>train/grad_norm</td><td>▄▄█▄▄▃▃▂▂▂▁▄▂▂▄▁▅▁▂▂▂▂▁</td></tr><tr><td>train/learning_rate</td><td>▃▅▇███▇▇▇▆▆▅▅▄▄▃▃▂▂▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▇▅▃▂▂▂▂▂▂▁▁▂▁▂▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_eval_loss</td><td>11.73881</td></tr><tr><td>eval/loss</td><td>11.73881</td></tr><tr><td>eval/runtime</td><td>23.4267</td></tr><tr><td>eval/samples_per_second</td><td>39.442</td></tr><tr><td>eval/steps_per_second</td><td>4.952</td></tr><tr><td>final_train_loss</td><td>30.76046</td></tr><tr><td>hp_adam_beta1</td><td>0.88046</td></tr><tr><td>hp_adam_beta2</td><td>0.95479</td></tr><tr><td>hp_adam_epsilon</td><td>0.0</td></tr><tr><td>hp_batch_size</td><td>8</td></tr><tr><td>hp_gradient_accumulation_steps</td><td>2</td></tr><tr><td>hp_learning_rate</td><td>0.0</td></tr><tr><td>hp_max_grad_norm</td><td>1.7126</td></tr><tr><td>hp_warmup_ratio</td><td>0.14489</td></tr><tr><td>hp_weight_decay</td><td>0.08536</td></tr><tr><td>linear_layer_size</td><td>41</td></tr><tr><td>total_flos</td><td>5.596880800896e+18</td></tr><tr><td>train/epoch</td><td>5</td></tr><tr><td>train/global_step</td><td>1155</td></tr><tr><td>train/grad_norm</td><td>80.07467</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>24.9831</td></tr><tr><td>train_loss</td><td>30.76046</td></tr><tr><td>train_runtime</td><td>812.8246</td></tr><tr><td>train_samples_per_second</td><td>22.736</td></tr><tr><td>train_steps_per_second</td><td>1.421</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_2_resize</strong> at: <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size/runs/r8jzom36' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size/runs/r8jzom36</a><br/> View project at: <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250113_081612-r8jzom36/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-13 08:31:38,716] Trial 2 finished with value: 11.738807678222656 and parameters: {'learning_rate': 2.5081156860452325e-06, 'batch_size': 8, 'gradient_accumulation_steps': 2, 'warmup_ratio': 0.14488855372533332, 'weight_decay': 0.08536189862866832, 'max_grad_norm': 1.7125960221746916, 'adam_beta1': 0.8804613769173371, 'adam_beta2': 0.9547859335863128, 'adam_epsilon': 2.335963502626154e-08}. Best is trial 0 with value: 8.871959686279297.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/arunasrivastava/ML/notebooks/wandb/run-20250113_083138-klum1lgv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size/runs/klum1lgv' target=\"_blank\">trial_3_resize</a></strong> to <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size/runs/klum1lgv' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size/runs/klum1lgv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading pretrained model and processor...\n",
      "INFO:__main__:Initial vocabulary size: 313\n",
      "INFO:__main__:Splitting dataset into train and evaluation...\n",
      "Map (num_proc=4):   0%|          | 0/3696 [00:00<?, ? examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   2%|▏         | 76/3696 [00:04<01:37, 37.30 examples/s] /home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   7%|▋         | 255/3696 [00:07<00:38, 90.43 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):  16%|█▌        | 592/3696 [00:09<00:23, 130.27 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4): 100%|██████████| 3696/3696 [01:04<00:00, 57.38 examples/s] \n",
      "Map (num_proc=4):   0%|          | 0/924 [00:00<?, ? examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   3%|▎         | 30/924 [00:01<00:32, 27.89 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   9%|▉         | 83/924 [00:02<00:11, 76.12 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):  21%|██        | 191/924 [00:03<00:05, 125.46 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4): 100%|██████████| 924/924 [00:17<00:00, 53.76 examples/s] \n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 13:29, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>38.835900</td>\n",
       "      <td>14.799637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>27.702300</td>\n",
       "      <td>11.994796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>19.262000</td>\n",
       "      <td>10.295615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>20.132900</td>\n",
       "      <td>9.385421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>20.956000</td>\n",
       "      <td>9.144909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>19.395200</td>\n",
       "      <td>8.928479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>18.407000</td>\n",
       "      <td>8.903134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>17.833700</td>\n",
       "      <td>8.922076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>18.563500</td>\n",
       "      <td>8.759708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>17.042200</td>\n",
       "      <td>8.752543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>18.342200</td>\n",
       "      <td>8.708118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='116' max='116' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [116/116 00:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_eval_loss</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▅▃▂▂▁▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▄▄▁▃▃▂▂▂█▅█▆</td></tr><tr><td>eval/samples_per_second</td><td>▅▄█▆▆▇▇▇▁▃▁▃</td></tr><tr><td>eval/steps_per_second</td><td>▅▄█▆▆▇▇▇▁▃▁▃</td></tr><tr><td>final_train_loss</td><td>▁</td></tr><tr><td>hp_adam_beta1</td><td>▁</td></tr><tr><td>hp_adam_beta2</td><td>▁</td></tr><tr><td>hp_adam_epsilon</td><td>▁</td></tr><tr><td>hp_batch_size</td><td>▁</td></tr><tr><td>hp_gradient_accumulation_steps</td><td>▁</td></tr><tr><td>hp_learning_rate</td><td>▁</td></tr><tr><td>hp_max_grad_norm</td><td>▁</td></tr><tr><td>hp_warmup_ratio</td><td>▁</td></tr><tr><td>hp_weight_decay</td><td>▁</td></tr><tr><td>linear_layer_size</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇██████</td></tr><tr><td>train/grad_norm</td><td>█▇▂▂▃▂▂▇▂▁▂▄▃▂▃▃▅▃▃▃▂▃▃</td></tr><tr><td>train/learning_rate</td><td>▄████▇▇▇▆▆▅▅▄▄▃▃▂▂▂▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▄▃▃▂▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_eval_loss</td><td>8.75202</td></tr><tr><td>eval/loss</td><td>8.75202</td></tr><tr><td>eval/runtime</td><td>25.131</td></tr><tr><td>eval/samples_per_second</td><td>36.767</td></tr><tr><td>eval/steps_per_second</td><td>4.616</td></tr><tr><td>final_train_loss</td><td>23.08969</td></tr><tr><td>hp_adam_beta1</td><td>0.86849</td></tr><tr><td>hp_adam_beta2</td><td>0.99751</td></tr><tr><td>hp_adam_epsilon</td><td>0.0</td></tr><tr><td>hp_batch_size</td><td>8</td></tr><tr><td>hp_gradient_accumulation_steps</td><td>2</td></tr><tr><td>hp_learning_rate</td><td>1e-05</td></tr><tr><td>hp_max_grad_norm</td><td>1.32007</td></tr><tr><td>hp_warmup_ratio</td><td>0.08117</td></tr><tr><td>hp_weight_decay</td><td>0.01097</td></tr><tr><td>linear_layer_size</td><td>41</td></tr><tr><td>total_flos</td><td>5.596880800896e+18</td></tr><tr><td>train/epoch</td><td>5</td></tr><tr><td>train/global_step</td><td>1155</td></tr><tr><td>train/grad_norm</td><td>146.57866</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>19.3718</td></tr><tr><td>train_loss</td><td>23.08969</td></tr><tr><td>train_runtime</td><td>811.3672</td></tr><tr><td>train_samples_per_second</td><td>22.776</td></tr><tr><td>train_steps_per_second</td><td>1.424</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_3_resize</strong> at: <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size/runs/klum1lgv' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size/runs/klum1lgv</a><br/> View project at: <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250113_083138-klum1lgv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-13 08:47:03,385] Trial 3 finished with value: 8.752020835876465 and parameters: {'learning_rate': 7.5911048052827045e-06, 'batch_size': 8, 'gradient_accumulation_steps': 2, 'warmup_ratio': 0.0811711076089411, 'weight_decay': 0.010968217207529524, 'max_grad_norm': 1.3200654190149195, 'adam_beta1': 0.8684854455525527, 'adam_beta2': 0.9975096467604634, 'adam_epsilon': 3.550304858128307e-08}. Best is trial 3 with value: 8.752020835876465.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/arunasrivastava/ML/notebooks/wandb/run-20250113_084703-fezbur4i</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size/runs/fezbur4i' target=\"_blank\">trial_4_resize</a></strong> to <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size/runs/fezbur4i' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size/runs/fezbur4i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading pretrained model and processor...\n",
      "INFO:__main__:Initial vocabulary size: 313\n",
      "INFO:__main__:Splitting dataset into train and evaluation...\n",
      "Map (num_proc=4):   0%|          | 0/3696 [00:00<?, ? examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   2%|▏         | 79/3696 [00:04<01:40, 35.84 examples/s] /home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   7%|▋         | 266/3696 [00:07<00:40, 84.74 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):  17%|█▋        | 638/3696 [00:10<00:22, 133.01 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4): 100%|██████████| 3696/3696 [01:04<00:00, 57.62 examples/s] \n",
      "Map (num_proc=4):   0%|          | 0/924 [00:00<?, ? examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   3%|▎         | 24/924 [00:01<00:34, 25.96 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):  10%|█         | 93/924 [00:02<00:12, 67.26 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):  22%|██▏       | 206/924 [00:03<00:05, 124.66 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4): 100%|██████████| 924/924 [00:17<00:00, 53.69 examples/s] \n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='285' max='285' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [285/285 08:36, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>38.834100</td>\n",
       "      <td>8.954326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>30.706900</td>\n",
       "      <td>6.460080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:20]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_eval_loss</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▂▁</td></tr><tr><td>eval/runtime</td><td>█▁█</td></tr><tr><td>eval/samples_per_second</td><td>▁█▁</td></tr><tr><td>eval/steps_per_second</td><td>▂█▁</td></tr><tr><td>final_train_loss</td><td>▁</td></tr><tr><td>hp_adam_beta1</td><td>▁</td></tr><tr><td>hp_adam_beta2</td><td>▁</td></tr><tr><td>hp_adam_epsilon</td><td>▁</td></tr><tr><td>hp_batch_size</td><td>▁</td></tr><tr><td>hp_gradient_accumulation_steps</td><td>▁</td></tr><tr><td>hp_learning_rate</td><td>▁</td></tr><tr><td>hp_max_grad_norm</td><td>▁</td></tr><tr><td>hp_warmup_ratio</td><td>▁</td></tr><tr><td>hp_weight_decay</td><td>▁</td></tr><tr><td>linear_layer_size</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▂▂▄▅▅▇██</td></tr><tr><td>train/global_step</td><td>▁▂▂▄▅▅▇███</td></tr><tr><td>train/grad_norm</td><td>▇▃▃▁█</td></tr><tr><td>train/learning_rate</td><td>█▇▅▃▁</td></tr><tr><td>train/loss</td><td>█▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_eval_loss</td><td>6.18729</td></tr><tr><td>eval/loss</td><td>6.18729</td></tr><tr><td>eval/runtime</td><td>24.368</td></tr><tr><td>eval/samples_per_second</td><td>37.919</td></tr><tr><td>eval/steps_per_second</td><td>2.38</td></tr><tr><td>final_train_loss</td><td>41.37569</td></tr><tr><td>hp_adam_beta1</td><td>0.93287</td></tr><tr><td>hp_adam_beta2</td><td>0.96748</td></tr><tr><td>hp_adam_epsilon</td><td>0.0</td></tr><tr><td>hp_batch_size</td><td>16</td></tr><tr><td>hp_gradient_accumulation_steps</td><td>4</td></tr><tr><td>hp_learning_rate</td><td>8e-05</td></tr><tr><td>hp_max_grad_norm</td><td>0.90702</td></tr><tr><td>hp_warmup_ratio</td><td>0.08253</td></tr><tr><td>hp_weight_decay</td><td>0.00599</td></tr><tr><td>linear_layer_size</td><td>41</td></tr><tr><td>total_flos</td><td>5.524194037248e+18</td></tr><tr><td>train/epoch</td><td>4.93506</td></tr><tr><td>train/global_step</td><td>285</td></tr><tr><td>train/grad_norm</td><td>145.66391</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>27.5972</td></tr><tr><td>train_loss</td><td>41.37569</td></tr><tr><td>train_runtime</td><td>523.3851</td></tr><tr><td>train_samples_per_second</td><td>35.309</td></tr><tr><td>train_steps_per_second</td><td>0.545</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_4_resize</strong> at: <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size/runs/fezbur4i' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size/runs/fezbur4i</a><br/> View project at: <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250113_084703-fezbur4i/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-13 08:57:38,989] Trial 4 finished with value: 6.187285900115967 and parameters: {'learning_rate': 7.568292060167621e-05, 'batch_size': 16, 'gradient_accumulation_steps': 4, 'warmup_ratio': 0.08253303307632644, 'weight_decay': 0.0059890036722543005, 'max_grad_norm': 0.9070235476608439, 'adam_beta1': 0.9328737509151929, 'adam_beta2': 0.9674809130079859, 'adam_epsilon': 3.6464395589807156e-09}. Best is trial 4 with value: 6.187285900115967.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/arunasrivastava/ML/notebooks/wandb/run-20250113_085739-4rvuabc1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size/runs/4rvuabc1' target=\"_blank\">trial_5_resize</a></strong> to <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size/runs/4rvuabc1' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size/runs/4rvuabc1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading pretrained model and processor...\n",
      "INFO:__main__:Initial vocabulary size: 313\n",
      "INFO:__main__:Splitting dataset into train and evaluation...\n",
      "Map (num_proc=4):   0%|          | 0/3696 [00:00<?, ? examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   2%|▏         | 86/3696 [00:05<01:31, 39.58 examples/s] /home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   8%|▊         | 281/3696 [00:07<00:39, 86.42 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):  17%|█▋        | 637/3696 [00:10<00:23, 128.14 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4): 100%|██████████| 3696/3696 [01:05<00:00, 56.29 examples/s] \n",
      "Map (num_proc=4):   0%|          | 0/924 [00:00<?, ? examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   3%|▎         | 30/924 [00:01<00:27, 32.30 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):  10%|▉         | 92/924 [00:02<00:11, 72.60 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):  22%|██▏       | 200/924 [00:03<00:05, 124.42 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4): 100%|██████████| 924/924 [00:17<00:00, 54.32 examples/s] \n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 13:30, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>29.669800</td>\n",
       "      <td>13.562604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>24.374100</td>\n",
       "      <td>9.994723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>17.488900</td>\n",
       "      <td>9.803380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>19.018000</td>\n",
       "      <td>8.913371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>19.762600</td>\n",
       "      <td>8.454498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>18.206300</td>\n",
       "      <td>8.290072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>17.147800</td>\n",
       "      <td>8.154704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>16.757700</td>\n",
       "      <td>8.433953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>17.409900</td>\n",
       "      <td>8.085526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>15.928800</td>\n",
       "      <td>8.063108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>17.012100</td>\n",
       "      <td>8.017988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='116' max='116' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [116/116 00:22]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_eval_loss</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▃▃▂▂▁▁▂▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▅▅▆▆▄█▁▇▅▇▃▃</td></tr><tr><td>eval/samples_per_second</td><td>▄▄▃▃▅▁█▂▄▂▆▆</td></tr><tr><td>eval/steps_per_second</td><td>▄▄▃▃▅▁█▂▄▂▆▆</td></tr><tr><td>final_train_loss</td><td>▁</td></tr><tr><td>hp_adam_beta1</td><td>▁</td></tr><tr><td>hp_adam_beta2</td><td>▁</td></tr><tr><td>hp_adam_epsilon</td><td>▁</td></tr><tr><td>hp_batch_size</td><td>▁</td></tr><tr><td>hp_gradient_accumulation_steps</td><td>▁</td></tr><tr><td>hp_learning_rate</td><td>▁</td></tr><tr><td>hp_max_grad_norm</td><td>▁</td></tr><tr><td>hp_warmup_ratio</td><td>▁</td></tr><tr><td>hp_weight_decay</td><td>▁</td></tr><tr><td>linear_layer_size</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇██████</td></tr><tr><td>train/grad_norm</td><td>█▂▂▁▃▂▁▄▁▁▁▆▂▂▄▃▄▂▃▄▃▃▃</td></tr><tr><td>train/learning_rate</td><td>▆████▇▇▇▆▆▅▅▄▄▃▃▂▂▂▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▃▃▂▂▁▁▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_eval_loss</td><td>8.0639</td></tr><tr><td>eval/loss</td><td>8.0639</td></tr><tr><td>eval/runtime</td><td>24.5948</td></tr><tr><td>eval/samples_per_second</td><td>37.569</td></tr><tr><td>eval/steps_per_second</td><td>4.716</td></tr><tr><td>final_train_loss</td><td>21.07534</td></tr><tr><td>hp_adam_beta1</td><td>0.9229</td></tr><tr><td>hp_adam_beta2</td><td>0.98779</td></tr><tr><td>hp_adam_epsilon</td><td>0.0</td></tr><tr><td>hp_batch_size</td><td>8</td></tr><tr><td>hp_gradient_accumulation_steps</td><td>2</td></tr><tr><td>hp_learning_rate</td><td>1e-05</td></tr><tr><td>hp_max_grad_norm</td><td>1.56029</td></tr><tr><td>hp_warmup_ratio</td><td>0.05055</td></tr><tr><td>hp_weight_decay</td><td>0.04275</td></tr><tr><td>linear_layer_size</td><td>41</td></tr><tr><td>total_flos</td><td>5.596880800896e+18</td></tr><tr><td>train/epoch</td><td>5</td></tr><tr><td>train/global_step</td><td>1155</td></tr><tr><td>train/grad_norm</td><td>167.39833</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>18.0447</td></tr><tr><td>train_loss</td><td>21.07534</td></tr><tr><td>train_runtime</td><td>812.8264</td></tr><tr><td>train_samples_per_second</td><td>22.735</td></tr><tr><td>train_steps_per_second</td><td>1.421</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_5_resize</strong> at: <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size/runs/4rvuabc1' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size/runs/4rvuabc1</a><br/> View project at: <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250113_085739-4rvuabc1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-13 09:13:06,482] Trial 5 finished with value: 8.063904762268066 and parameters: {'learning_rate': 1.2172847081122448e-05, 'batch_size': 8, 'gradient_accumulation_steps': 2, 'warmup_ratio': 0.05055221171236024, 'weight_decay': 0.04274869455295218, 'max_grad_norm': 1.5602860157714256, 'adam_beta1': 0.9229007168040987, 'adam_beta2': 0.9877922469876114, 'adam_epsilon': 1.4063366777718189e-09}. Best is trial 4 with value: 6.187285900115967.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/arunasrivastava/ML/notebooks/wandb/run-20250113_091306-pjui4os0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size/runs/pjui4os0' target=\"_blank\">trial_6_resize</a></strong> to <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size/runs/pjui4os0' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size/runs/pjui4os0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading pretrained model and processor...\n",
      "INFO:__main__:Initial vocabulary size: 313\n",
      "INFO:__main__:Splitting dataset into train and evaluation...\n",
      "Map (num_proc=4):   0%|          | 0/3696 [00:00<?, ? examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   2%|▏         | 76/3696 [00:04<01:33, 38.63 examples/s] /home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   7%|▋         | 253/3696 [00:07<00:39, 86.11 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):  17%|█▋        | 614/3696 [00:10<00:23, 130.80 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4): 100%|██████████| 3696/3696 [01:05<00:00, 56.50 examples/s] \n",
      "Map (num_proc=4):   0%|          | 0/924 [00:00<?, ? examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   3%|▎         | 30/924 [00:01<00:29, 30.81 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):  10%|█         | 93/924 [00:02<00:10, 75.95 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):  21%|██        | 190/924 [00:03<00:06, 121.90 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4): 100%|██████████| 924/924 [00:16<00:00, 54.49 examples/s] \n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 13:31, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>46.238900</td>\n",
       "      <td>15.619992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>29.778000</td>\n",
       "      <td>13.275213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>22.855600</td>\n",
       "      <td>12.818264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>23.549200</td>\n",
       "      <td>10.988846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>23.015800</td>\n",
       "      <td>9.992898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>20.998400</td>\n",
       "      <td>9.767344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>19.803400</td>\n",
       "      <td>9.554112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>19.197000</td>\n",
       "      <td>9.584857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>19.799500</td>\n",
       "      <td>9.416276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>18.256600</td>\n",
       "      <td>9.413230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>19.649400</td>\n",
       "      <td>9.380929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='116' max='116' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [116/116 00:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_eval_loss</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▅▅▃▂▁▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▇▁▂▆▄▆▃▃▄▇▅█</td></tr><tr><td>eval/samples_per_second</td><td>▂█▇▃▅▃▆▆▅▁▃▁</td></tr><tr><td>eval/steps_per_second</td><td>▂█▇▃▅▃▆▆▅▁▃▁</td></tr><tr><td>final_train_loss</td><td>▁</td></tr><tr><td>hp_adam_beta1</td><td>▁</td></tr><tr><td>hp_adam_beta2</td><td>▁</td></tr><tr><td>hp_adam_epsilon</td><td>▁</td></tr><tr><td>hp_batch_size</td><td>▁</td></tr><tr><td>hp_gradient_accumulation_steps</td><td>▁</td></tr><tr><td>hp_learning_rate</td><td>▁</td></tr><tr><td>hp_max_grad_norm</td><td>▁</td></tr><tr><td>hp_warmup_ratio</td><td>▁</td></tr><tr><td>hp_weight_decay</td><td>▁</td></tr><tr><td>linear_layer_size</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇██████</td></tr><tr><td>train/grad_norm</td><td>██▂▄▃▂▂▃▁▁▅▄▂▂▂▃▆▄▂▃▂▂▁</td></tr><tr><td>train/learning_rate</td><td>▄████▇▇▇▆▆▅▅▄▄▃▃▂▂▂▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▅▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_eval_loss</td><td>9.41258</td></tr><tr><td>eval/loss</td><td>9.41258</td></tr><tr><td>eval/runtime</td><td>26.0964</td></tr><tr><td>eval/samples_per_second</td><td>35.407</td></tr><tr><td>eval/steps_per_second</td><td>4.445</td></tr><tr><td>final_train_loss</td><td>25.2177</td></tr><tr><td>hp_adam_beta1</td><td>0.93872</td></tr><tr><td>hp_adam_beta2</td><td>0.97314</td></tr><tr><td>hp_adam_epsilon</td><td>0.0</td></tr><tr><td>hp_batch_size</td><td>8</td></tr><tr><td>hp_gradient_accumulation_steps</td><td>2</td></tr><tr><td>hp_learning_rate</td><td>1e-05</td></tr><tr><td>hp_max_grad_norm</td><td>1.45634</td></tr><tr><td>hp_warmup_ratio</td><td>0.08252</td></tr><tr><td>hp_weight_decay</td><td>0.02879</td></tr><tr><td>linear_layer_size</td><td>41</td></tr><tr><td>total_flos</td><td>5.596880800896e+18</td></tr><tr><td>train/epoch</td><td>5</td></tr><tr><td>train/global_step</td><td>1155</td></tr><tr><td>train/grad_norm</td><td>62.90198</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>20.6225</td></tr><tr><td>train_loss</td><td>25.2177</td></tr><tr><td>train_runtime</td><td>813.7279</td></tr><tr><td>train_samples_per_second</td><td>22.71</td></tr><tr><td>train_steps_per_second</td><td>1.419</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_6_resize</strong> at: <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size/runs/pjui4os0' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size/runs/pjui4os0</a><br/> View project at: <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250113_091306-pjui4os0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-13 09:28:41,875] Trial 6 finished with value: 9.412580490112305 and parameters: {'learning_rate': 5.211124595788262e-06, 'batch_size': 8, 'gradient_accumulation_steps': 2, 'warmup_ratio': 0.08251833220267471, 'weight_decay': 0.02878805718308924, 'max_grad_norm': 1.4563362070328196, 'adam_beta1': 0.9387212742576326, 'adam_beta2': 0.9731385313329355, 'adam_epsilon': 1.734556664236095e-09}. Best is trial 4 with value: 6.187285900115967.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/arunasrivastava/ML/notebooks/wandb/run-20250113_092841-10zbq0y6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size/runs/10zbq0y6' target=\"_blank\">trial_7_resize</a></strong> to <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size/runs/10zbq0y6' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size/runs/10zbq0y6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading pretrained model and processor...\n",
      "INFO:__main__:Initial vocabulary size: 313\n",
      "INFO:__main__:Splitting dataset into train and evaluation...\n",
      "Map (num_proc=4):   0%|          | 0/3696 [00:00<?, ? examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   2%|▏         | 81/3696 [00:05<02:36, 23.12 examples/s] /home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   7%|▋         | 264/3696 [00:07<00:39, 87.21 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):  16%|█▌        | 597/3696 [00:10<00:24, 123.99 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4): 100%|██████████| 3696/3696 [01:07<00:00, 55.10 examples/s] \n",
      "Map (num_proc=4):   0%|          | 0/924 [00:00<?, ? examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   3%|▎         | 30/924 [00:01<00:28, 31.06 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):  10%|█         | 94/924 [00:02<00:12, 69.09 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):  23%|██▎       | 211/924 [00:03<00:05, 125.51 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4): 100%|██████████| 924/924 [00:16<00:00, 54.84 examples/s] \n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='285' max='285' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [285/285 08:40, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>45.402800</td>\n",
       "      <td>9.867482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>39.008500</td>\n",
       "      <td>8.587796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:20]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_eval_loss</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▂▁</td></tr><tr><td>eval/runtime</td><td>▁█▄</td></tr><tr><td>eval/samples_per_second</td><td>█▁▅</td></tr><tr><td>eval/steps_per_second</td><td>█▁▅</td></tr><tr><td>final_train_loss</td><td>▁</td></tr><tr><td>hp_adam_beta1</td><td>▁</td></tr><tr><td>hp_adam_beta2</td><td>▁</td></tr><tr><td>hp_adam_epsilon</td><td>▁</td></tr><tr><td>hp_batch_size</td><td>▁</td></tr><tr><td>hp_gradient_accumulation_steps</td><td>▁</td></tr><tr><td>hp_learning_rate</td><td>▁</td></tr><tr><td>hp_max_grad_norm</td><td>▁</td></tr><tr><td>hp_warmup_ratio</td><td>▁</td></tr><tr><td>hp_weight_decay</td><td>▁</td></tr><tr><td>linear_layer_size</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▂▂▄▅▅▇██</td></tr><tr><td>train/global_step</td><td>▁▂▂▄▅▅▇███</td></tr><tr><td>train/grad_norm</td><td>█▃▁▃▁</td></tr><tr><td>train/learning_rate</td><td>█▇▅▃▁</td></tr><tr><td>train/loss</td><td>█▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_eval_loss</td><td>8.41108</td></tr><tr><td>eval/loss</td><td>8.41108</td></tr><tr><td>eval/runtime</td><td>24.7693</td></tr><tr><td>eval/samples_per_second</td><td>37.304</td></tr><tr><td>eval/steps_per_second</td><td>2.342</td></tr><tr><td>final_train_loss</td><td>49.2308</td></tr><tr><td>hp_adam_beta1</td><td>0.91364</td></tr><tr><td>hp_adam_beta2</td><td>0.9654</td></tr><tr><td>hp_adam_epsilon</td><td>0.0</td></tr><tr><td>hp_batch_size</td><td>16</td></tr><tr><td>hp_gradient_accumulation_steps</td><td>4</td></tr><tr><td>hp_learning_rate</td><td>3e-05</td></tr><tr><td>hp_max_grad_norm</td><td>0.54714</td></tr><tr><td>hp_warmup_ratio</td><td>0.05254</td></tr><tr><td>hp_weight_decay</td><td>0.00164</td></tr><tr><td>linear_layer_size</td><td>41</td></tr><tr><td>total_flos</td><td>5.524194037248e+18</td></tr><tr><td>train/epoch</td><td>4.93506</td></tr><tr><td>train/global_step</td><td>285</td></tr><tr><td>train/grad_norm</td><td>79.53757</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>36.9686</td></tr><tr><td>train_loss</td><td>49.2308</td></tr><tr><td>train_runtime</td><td>526.8404</td></tr><tr><td>train_samples_per_second</td><td>35.077</td></tr><tr><td>train_steps_per_second</td><td>0.541</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_7_resize</strong> at: <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size/runs/10zbq0y6' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size/runs/10zbq0y6</a><br/> View project at: <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250113_092841-10zbq0y6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-13 09:39:24,807] Trial 7 finished with value: 8.411081314086914 and parameters: {'learning_rate': 2.66986667427446e-05, 'batch_size': 16, 'gradient_accumulation_steps': 4, 'warmup_ratio': 0.052541912674409524, 'weight_decay': 0.001643549747511133, 'max_grad_norm': 0.5471437785301014, 'adam_beta1': 0.913641041126378, 'adam_beta2': 0.96540344307274, 'adam_epsilon': 1.040258761588384e-08}. Best is trial 4 with value: 6.187285900115967.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/arunasrivastava/ML/notebooks/wandb/run-20250113_093924-slii6ec8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size/runs/slii6ec8' target=\"_blank\">trial_8_resize</a></strong> to <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size/runs/slii6ec8' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-linear-size/runs/slii6ec8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading pretrained model and processor...\n",
      "INFO:__main__:Initial vocabulary size: 313\n",
      "INFO:__main__:Splitting dataset into train and evaluation...\n",
      "Map (num_proc=4):   0%|          | 0/3696 [00:00<?, ? examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   2%|▏         | 75/3696 [00:04<01:35, 37.90 examples/s] /home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   7%|▋         | 264/3696 [00:07<00:42, 80.69 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):  17%|█▋        | 612/3696 [00:10<00:22, 139.14 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4): 100%|██████████| 3696/3696 [03:38<00:00, 16.88 examples/s] \n",
      "Map (num_proc=4):   0%|          | 0/924 [00:00<?, ? examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   3%|▎         | 28/924 [00:01<00:37, 23.86 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):  10%|█         | 96/924 [00:02<00:12, 66.65 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):  22%|██▏       | 199/924 [00:03<00:06, 119.64 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4): 100%|██████████| 924/924 [00:17<00:00, 53.41 examples/s] \n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='118' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/140 08:07 < 01:32, 0.24 it/s, Epoch 4.05/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>79.337500</td>\n",
       "      <td>8.506593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from transformers import TrainingArguments, EarlyStoppingCallback\n",
    "from functools import partial\n",
    "import wandb\n",
    "\n",
    "def objective(trial, train_df, timit_vocab, resize_linear=True, base_output_dir=\"./results\"):\n",
    "    \"\"\"\n",
    "    Optuna objective function for hyperparameter optimization\n",
    "    \"\"\"\n",
    "    # Generate a unique run name\n",
    "    model_type = \"resize\" if resize_linear else \"no_resize\"\n",
    "    run_name = f\"trial_{trial.number}_{model_type}\"\n",
    "    output_dir = f\"{base_output_dir}/{run_name}\"\n",
    "    \n",
    "    # Initialize wandb for this trial\n",
    "    wandb.init(\n",
    "        project=\"xlsr-buckeye-phoneme-prediction-linear-size\",\n",
    "        name=run_name,\n",
    "        config={\n",
    "            \"trial_number\": trial.number,\n",
    "            \"model_type\": model_type,\n",
    "            \"resize_linear\": resize_linear\n",
    "        },\n",
    "        reinit=True\n",
    "    )\n",
    "    \n",
    "    # Sample hyperparameters (using your ranges)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-6, 1e-4, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [4, 8, 16])\n",
    "    grad_accum = trial.suggest_categorical(\"gradient_accumulation_steps\", [2, 4, 8])\n",
    "    warmup_ratio = trial.suggest_float(\"warmup_ratio\", 0.05, 0.15)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 0.001, 0.1, log=True)\n",
    "    max_grad_norm = trial.suggest_float(\"max_grad_norm\", 0.5, 2.0)\n",
    "    adam_beta1 = trial.suggest_float(\"adam_beta1\", 0.85, 0.95)\n",
    "    adam_beta2 = trial.suggest_float(\"adam_beta2\", 0.95, 0.999)\n",
    "    adam_epsilon = trial.suggest_float(\"adam_epsilon\", 1e-9, 1e-7, log=True)\n",
    "    \n",
    "    # Prepare model and data based on resize_linear flag\n",
    "    if resize_linear:\n",
    "        model, processor = prepare_model_and_processor(timit_vocab)\n",
    "    else:\n",
    "        model, processor = prepare_model_and_processor_no_resize(timit_vocab)\n",
    "        \n",
    "    train_dataset, eval_dataset = prepare_datasets(train_df, processor)\n",
    "    \n",
    "    # Log linear layer size\n",
    "    linear_size = model.lm_head.out_features\n",
    "    wandb.log({\"linear_layer_size\": linear_size})\n",
    "    \n",
    "    # Enable gradient checkpointing for memory efficiency\n",
    "    model.gradient_checkpointing_enable()\n",
    "    \n",
    "    # Create training arguments with sampled hyperparameters\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        learning_rate=learning_rate,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        gradient_accumulation_steps=grad_accum,\n",
    "        max_grad_norm=max_grad_norm,\n",
    "        warmup_ratio=warmup_ratio,\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "        weight_decay=weight_decay,\n",
    "        num_train_epochs=5,  # Reduced epochs for faster search\n",
    "        logging_dir=f'{output_dir}/logs',\n",
    "        logging_steps=50,\n",
    "        save_steps=500,\n",
    "        eval_steps=100,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"eval_loss\",\n",
    "        greater_is_better=False,\n",
    "        save_safetensors=True,\n",
    "        save_strategy=\"steps\",\n",
    "        save_total_limit=1,  # Keep only best model\n",
    "        fp16=True,\n",
    "        fp16_full_eval=True,\n",
    "        dataloader_num_workers=4,\n",
    "        dataloader_pin_memory=True,\n",
    "        gradient_checkpointing=True,\n",
    "        adam_beta1=adam_beta1,\n",
    "        adam_beta2=adam_beta2,\n",
    "        adam_epsilon=adam_epsilon,\n",
    "    )\n",
    "    \n",
    "    # Create early stopping callback\n",
    "    early_stopping_callback = EarlyStoppingCallback(\n",
    "        early_stopping_patience=3,\n",
    "        early_stopping_threshold=0.01\n",
    "    )\n",
    "    \n",
    "    # Create trainer with early stopping\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        data_collator=DataCollatorCTCWithPadding(processor=processor, padding=\"longest\"),\n",
    "        callbacks=[early_stopping_callback]\n",
    "    )\n",
    "    \n",
    "    # Train and get best eval loss\n",
    "    try:\n",
    "        train_result = trainer.train()\n",
    "        eval_result = trainer.evaluate()\n",
    "        \n",
    "        # Report to wandb\n",
    "        wandb.log({\n",
    "            \"best_eval_loss\": eval_result[\"eval_loss\"],\n",
    "            \"final_train_loss\": train_result.training_loss,\n",
    "            **{f\"hp_{k}\": v for k, v in trial.params.items()}\n",
    "        })\n",
    "        \n",
    "        wandb.finish()\n",
    "        \n",
    "        return eval_result[\"eval_loss\"]\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Trial {trial.number} failed with error: {str(e)}\")\n",
    "        wandb.finish()\n",
    "        return float('inf')\n",
    "\n",
    "def run_hyperparameter_search(train_df, timit_vocab, n_trials=20):\n",
    "    \"\"\"\n",
    "    Run the hyperparameter search for both model variants\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for resize_linear in [True, False]:\n",
    "        model_type = \"resize\" if resize_linear else \"no_resize\"\n",
    "        print(f\"\\nRunning hyperparameter search for {model_type} model\")\n",
    "        \n",
    "        study = optuna.create_study(\n",
    "            direction=\"minimize\",\n",
    "            study_name=f\"linear_size_study_{model_type}\",\n",
    "            sampler=optuna.samplers.TPESampler(seed=42),\n",
    "            pruner=optuna.pruners.MedianPruner(\n",
    "                n_startup_trials=5,\n",
    "                n_warmup_steps=5,\n",
    "                interval_steps=1\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        study.optimize(\n",
    "            partial(objective, train_df=train_df, timit_vocab=timit_vocab, resize_linear=resize_linear),\n",
    "            n_trials=n_trials,\n",
    "            timeout=3600 * 12  # 12 hour timeout\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nBest trial for {model_type} model:\")\n",
    "        trial = study.best_trial\n",
    "        print(f\"  Value: {trial.value}\")\n",
    "        print(\"  Params: \")\n",
    "        for key, value in trial.params.items():\n",
    "            print(f\"    {key}: {value}\")\n",
    "            \n",
    "        results[model_type] = {\n",
    "            \"study\": study,\n",
    "            \"best_params\": trial.params,\n",
    "            \"best_value\": trial.value\n",
    "        }\n",
    "        \n",
    "        # Save study results\n",
    "        import joblib\n",
    "        joblib.dump(study, f\"hyperparam_study_{model_type}.pkl\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run hyperparameter search for both model variants\n",
    "    results = run_hyperparameter_search(train_df, timit_vocab)\n",
    "    \n",
    "    # Print comparison\n",
    "    print(\"\\nFinal Comparison:\")\n",
    "    print(f\"Resize model best loss: {results['resize']['best_value']}\")\n",
    "    print(f\"No-resize model best loss: {results['no_resize']['best_value']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
