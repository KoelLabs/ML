{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import zipfile\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "# run as much as possible accelerated by apple silicon, fall back to cpu if not possible\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from scripts.audio import audio_file_to_array\n",
    "from scripts.ipa import timit2ipa\n",
    "from scripts.ipa import filter_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append('..')\n",
    "from scripts.eval_tests.panphon_model_eval import panphon_model_eval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set espeak library path for macOS\n",
    "if sys.platform == \"darwin\":\n",
    "    from phonemizer.backend.espeak.wrapper import EspeakWrapper\n",
    "\n",
    "    _ESPEAK_LIBRARY = \"/opt/homebrew/Cellar/espeak/1.48.04_1/lib/libespeak.1.1.48.dylib\"\n",
    "    EspeakWrapper.set_library(_ESPEAK_LIBRARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, AutoModelForCTC, AutoTokenizer, AutoFeatureExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = os.path.join('..', 'models', 'timit-xlsr-finetune-B')\n",
    "PRE_TRAINED_ID = \"ginic/data_seed_4_wav2vec2-large-xlsr-buckeye-ipa\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "timit = zipfile.ZipFile('../.data/TIMIT.zip', 'r')\n",
    "timit_files = timit.namelist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_files = list(set(map(lambda x: x.split('.')[0], filter(lambda x: x.startswith('data/TRAIN'), timit_files))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "WAV_HEADER_SIZE = 44\n",
    "def zipped_wav_to_array(filename):\n",
    "    with timit.open(filename) as wav_file:\n",
    "        return np.frombuffer(wav_file.read(), dtype=np.int16)[WAV_HEADER_SIZE//2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio</th>\n",
       "      <th>ipa</th>\n",
       "      <th>phoneme_starts</th>\n",
       "      <th>phoneme_ends</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[25971, 30303, 29285, 26995, 28271, 11552, 131...</td>\n",
       "      <td>ɹɛɡɹintɑmttʃʊztəwɑttʃkɑɹtunzniɛftɹnun</td>\n",
       "      <td>[0, 2346, 2709, 3467, 4646, 5101, 6558, 7394, ...</td>\n",
       "      <td>[2346, 2709, 3467, 4646, 5101, 6558, 7394, 836...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[25971, 30303, 29285, 26995, 28271, 11552, 131...</td>\n",
       "      <td>wɪttʃttʃɹttʃduðɪsmɪθswɹʃipɪn</td>\n",
       "      <td>[0, 2095, 2892, 3718, 4530, 5760, 6732, 8731, ...</td>\n",
       "      <td>[2095, 2892, 3718, 4530, 5760, 6732, 8731, 107...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[25971, 30303, 29285, 26995, 28271, 11552, 131...</td>\n",
       "      <td>ʃihæddʒɹdɑɹksuʔnɹisiwɔʃwɔɾɹʔɔljɪɹ</td>\n",
       "      <td>[0, 4760, 6520, 7561, 8280, 10193, 10920, 1156...</td>\n",
       "      <td>[4760, 6520, 7561, 8280, 10193, 10920, 11560, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[25971, 30303, 29285, 26995, 28271, 11552, 131...</td>\n",
       "      <td>əblɪsiɾihɛnoʊɾɹaɪiɾiɡoʊhændinhænd</td>\n",
       "      <td>[0, 2200, 3091, 3880, 5347, 5848, 6365, 7400, ...</td>\n",
       "      <td>[2200, 3091, 3880, 5347, 5848, 6365, 7400, 960...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[25971, 30303, 29285, 26995, 28271, 11552, 131...</td>\n",
       "      <td>hinivɛlfiŋfɪlmmɛɾitɑksikimiklzɹjuzd</td>\n",
       "      <td>[0, 2007, 2571, 3020, 4014, 4238, 4687, 5713, ...</td>\n",
       "      <td>[2007, 2571, 3020, 4014, 4238, 4687, 5713, 763...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               audio  \\\n",
       "0  [25971, 30303, 29285, 26995, 28271, 11552, 131...   \n",
       "1  [25971, 30303, 29285, 26995, 28271, 11552, 131...   \n",
       "2  [25971, 30303, 29285, 26995, 28271, 11552, 131...   \n",
       "3  [25971, 30303, 29285, 26995, 28271, 11552, 131...   \n",
       "4  [25971, 30303, 29285, 26995, 28271, 11552, 131...   \n",
       "\n",
       "                                     ipa  \\\n",
       "0  ɹɛɡɹintɑmttʃʊztəwɑttʃkɑɹtunzniɛftɹnun   \n",
       "1           wɪttʃttʃɹttʃduðɪsmɪθswɹʃipɪn   \n",
       "2      ʃihæddʒɹdɑɹksuʔnɹisiwɔʃwɔɾɹʔɔljɪɹ   \n",
       "3      əblɪsiɾihɛnoʊɾɹaɪiɾiɡoʊhændinhænd   \n",
       "4    hinivɛlfiŋfɪlmmɛɾitɑksikimiklzɹjuzd   \n",
       "\n",
       "                                      phoneme_starts  \\\n",
       "0  [0, 2346, 2709, 3467, 4646, 5101, 6558, 7394, ...   \n",
       "1  [0, 2095, 2892, 3718, 4530, 5760, 6732, 8731, ...   \n",
       "2  [0, 4760, 6520, 7561, 8280, 10193, 10920, 1156...   \n",
       "3  [0, 2200, 3091, 3880, 5347, 5848, 6365, 7400, ...   \n",
       "4  [0, 2007, 2571, 3020, 4014, 4238, 4687, 5713, ...   \n",
       "\n",
       "                                        phoneme_ends  \n",
       "0  [2346, 2709, 3467, 4646, 5101, 6558, 7394, 836...  \n",
       "1  [2095, 2892, 3718, 4530, 5760, 6732, 8731, 107...  \n",
       "2  [4760, 6520, 7561, 8280, 10193, 10920, 11560, ...  \n",
       "3  [2200, 3091, 3880, 5347, 5848, 6365, 7400, 960...  \n",
       "4  [2007, 2571, 3020, 4014, 4238, 4687, 5713, 763...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, ensure that the simplify_timit function is available and works\n",
    "def simplify_timit(phoneme):\n",
    "    # Substitute the phoneme based on the dictionary\n",
    "    substitution_dict = {\n",
    "        'ɾ̃': 'ɾ',  # Replace nasalized flap with plain flap\n",
    "        'ŋ̍': 'ŋ',  # Remove syllabic marker from 'ŋ̍'\n",
    "        'ə̥': 'ə',  # Remove voiceless marker from 'ə̥'\n",
    "        'ɝ': 'ɹ',   # Simplify rhotacized schwa to 'ɹ'\n",
    "        'ɚ': 'ɹ',   # Simplify rhotacized schwa to 'ɹ'\n",
    "        'l̩': 'l',   # Remove syllabic marker from 'l̩'\n",
    "        'm̩': 'm',   # Remove syllabic marker from 'm̩'\n",
    "        'n̩': 'n',   # Remove syllabic marker from 'n̩'\n",
    "        '̩': '',     # Remove syllabic marker\n",
    "        'ʉ': 'u',    # Replace high central rounded vowel with high back rounded vowel\n",
    "        'ɨ': 'i',    # Replace high central unrounded vowel with high front unrounded vowel\n",
    "        ' ': '',     # Remove nasalization marker\n",
    "        'ɦ': 'h',    # Replace voiceless glottal fricative with voiceless glottal fricative\n",
    "        # Add other necessary substitutions if needed\n",
    "    }\n",
    "    # Apply the substitution for the phoneme\n",
    "    return substitution_dict.get(phoneme, phoneme)  # Return simplified phoneme or the original if no replacement\n",
    "\n",
    "def remove_stress_mark(text):\n",
    "    \"\"\"\n",
    "    Removes the combining double inverted breve (͡) from text.\n",
    "    \n",
    "    Args:\n",
    "        text: String or iterable containing IPA symbols\n",
    "        \n",
    "    Returns:\n",
    "        Text with stress marks removed\n",
    "    \"\"\"\n",
    "    if isinstance(text, str):\n",
    "        return text.replace('͡', '')\n",
    "    else:\n",
    "        raise TypeError(\"Input must be string, set, or list\")\n",
    "    \n",
    "# Updated timit_file_to_dict to use the simplified IPA phonemes\n",
    "def timit_file_to_dict(filename):\n",
    "    with timit.open(filename + '.PHN') as phn_file:\n",
    "        timestamped_phonemes = []\n",
    "        for line in phn_file.read().decode('utf-8').split('\\n'):\n",
    "            if line == '':\n",
    "                continue\n",
    "            start, end, phoneme = line.split()\n",
    "            \n",
    "            # Convert to IPA first and then simplify the phoneme\n",
    "            ipa_phonemes = timit2ipa(phoneme, \"eng\")\n",
    "            \n",
    "            # Now filter only the necessary characters (this simplifies the phoneme to the basic form)\n",
    "            cleaned_ipa = filter_chars(simplify_timit(ipa_phonemes), filter_type=\"letters\")\n",
    "            cleaned_ipa = remove_stress_mark(cleaned_ipa)\n",
    "            timestamped_phonemes.append((cleaned_ipa, int(start), int(end)))\n",
    "\n",
    "    return {'timestamped_phonemes': timestamped_phonemes, 'wav_filename': filename + '.WAV'}\n",
    "\n",
    "# Updated files_to_df to create DataFrame with cleaned-up phonemes\n",
    "def files_to_df(files):\n",
    "    records = []\n",
    "    for filename in files:\n",
    "        parsed = timit_file_to_dict(filename)\n",
    "        parsed['audio'] = zipped_wav_to_array(parsed['wav_filename'])\n",
    "        del parsed['wav_filename']\n",
    "        parsed['ipa'] = \"\".join(phoneme for phoneme, _, _ in parsed['timestamped_phonemes'])\n",
    "        parsed['phoneme_starts'] = [start for _, start, _ in parsed['timestamped_phonemes']]\n",
    "        parsed['phoneme_ends'] = [end for _, _, end in parsed['timestamped_phonemes']]\n",
    "        del parsed['timestamped_phonemes']\n",
    "        records.append(parsed)\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "# Call files_to_df for your test files\n",
    "train_df = files_to_df(training_files)\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Up Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_audio(row):\n",
    "    # Access the phoneme_starts column and get the last value of the list\n",
    "    end = row['phoneme_starts'][-1]\n",
    "    # Access the phoneme_ends column and get the first value of the list\n",
    "    start = row['phoneme_ends'][0]\n",
    "    # Crop the audio from start to end\n",
    "    # note that start and end are in samples, not seconds\n",
    "    cropped_audio = row['audio'][start:end]\n",
    "    \n",
    "    return cropped_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# graph one audio to see start signal that we will remove\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_df['audio'][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio</th>\n",
       "      <th>ipa</th>\n",
       "      <th>phoneme_starts</th>\n",
       "      <th>phoneme_ends</th>\n",
       "      <th>cropped_audio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[25971, 30303, 29285, 26995, 28271, 11552, 131...</td>\n",
       "      <td>ɹɛɡɹintɑmttʃʊztəwɑttʃkɑɹtunzniɛftɹnun</td>\n",
       "      <td>[0, 2346, 2709, 3467, 4646, 5101, 6558, 7394, ...</td>\n",
       "      <td>[2346, 2709, 3467, 4646, 5101, 6558, 7394, 836...</td>\n",
       "      <td>[2, 0, 1, 1, 7, 2, 10, 2, -3, 0, 5, 3, 5, -1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[25971, 30303, 29285, 26995, 28271, 11552, 131...</td>\n",
       "      <td>wɪttʃttʃɹttʃduðɪsmɪθswɹʃipɪn</td>\n",
       "      <td>[0, 2095, 2892, 3718, 4530, 5760, 6732, 8731, ...</td>\n",
       "      <td>[2095, 2892, 3718, 4530, 5760, 6732, 8731, 107...</td>\n",
       "      <td>[1, 3, 2, 2, 1, 3, 1, -1, 1, 0, 4, 3, 2, 1, 2,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[25971, 30303, 29285, 26995, 28271, 11552, 131...</td>\n",
       "      <td>ʃihæddʒɹdɑɹksuʔnɹisiwɔʃwɔɾɹʔɔljɪɹ</td>\n",
       "      <td>[0, 4760, 6520, 7561, 8280, 10193, 10920, 1156...</td>\n",
       "      <td>[4760, 6520, 7561, 8280, 10193, 10920, 11560, ...</td>\n",
       "      <td>[3, -1, 1, -2, -1, 0, -1, 1, -1, 0, 2, 2, 0, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[25971, 30303, 29285, 26995, 28271, 11552, 131...</td>\n",
       "      <td>əblɪsiɾihɛnoʊɾɹaɪiɾiɡoʊhændinhænd</td>\n",
       "      <td>[0, 2200, 3091, 3880, 5347, 5848, 6365, 7400, ...</td>\n",
       "      <td>[2200, 3091, 3880, 5347, 5848, 6365, 7400, 960...</td>\n",
       "      <td>[-1, -4, 1, 0, -1, 2, 3, 0, 0, 1, 0, 1, 2, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[25971, 30303, 29285, 26995, 28271, 11552, 131...</td>\n",
       "      <td>hinivɛlfiŋfɪlmmɛɾitɑksikimiklzɹjuzd</td>\n",
       "      <td>[0, 2007, 2571, 3020, 4014, 4238, 4687, 5713, ...</td>\n",
       "      <td>[2007, 2571, 3020, 4014, 4238, 4687, 5713, 763...</td>\n",
       "      <td>[-4, 5, 13, 10, 6, 3, -6, -8, -1, 5, 2, -1, 2,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               audio  \\\n",
       "0  [25971, 30303, 29285, 26995, 28271, 11552, 131...   \n",
       "1  [25971, 30303, 29285, 26995, 28271, 11552, 131...   \n",
       "2  [25971, 30303, 29285, 26995, 28271, 11552, 131...   \n",
       "3  [25971, 30303, 29285, 26995, 28271, 11552, 131...   \n",
       "4  [25971, 30303, 29285, 26995, 28271, 11552, 131...   \n",
       "\n",
       "                                     ipa  \\\n",
       "0  ɹɛɡɹintɑmttʃʊztəwɑttʃkɑɹtunzniɛftɹnun   \n",
       "1           wɪttʃttʃɹttʃduðɪsmɪθswɹʃipɪn   \n",
       "2      ʃihæddʒɹdɑɹksuʔnɹisiwɔʃwɔɾɹʔɔljɪɹ   \n",
       "3      əblɪsiɾihɛnoʊɾɹaɪiɾiɡoʊhændinhænd   \n",
       "4    hinivɛlfiŋfɪlmmɛɾitɑksikimiklzɹjuzd   \n",
       "\n",
       "                                      phoneme_starts  \\\n",
       "0  [0, 2346, 2709, 3467, 4646, 5101, 6558, 7394, ...   \n",
       "1  [0, 2095, 2892, 3718, 4530, 5760, 6732, 8731, ...   \n",
       "2  [0, 4760, 6520, 7561, 8280, 10193, 10920, 1156...   \n",
       "3  [0, 2200, 3091, 3880, 5347, 5848, 6365, 7400, ...   \n",
       "4  [0, 2007, 2571, 3020, 4014, 4238, 4687, 5713, ...   \n",
       "\n",
       "                                        phoneme_ends  \\\n",
       "0  [2346, 2709, 3467, 4646, 5101, 6558, 7394, 836...   \n",
       "1  [2095, 2892, 3718, 4530, 5760, 6732, 8731, 107...   \n",
       "2  [4760, 6520, 7561, 8280, 10193, 10920, 11560, ...   \n",
       "3  [2200, 3091, 3880, 5347, 5848, 6365, 7400, 960...   \n",
       "4  [2007, 2571, 3020, 4014, 4238, 4687, 5713, 763...   \n",
       "\n",
       "                                       cropped_audio  \n",
       "0  [2, 0, 1, 1, 7, 2, 10, 2, -3, 0, 5, 3, 5, -1, ...  \n",
       "1  [1, 3, 2, 2, 1, 3, 1, -1, 1, 0, 4, 3, 2, 1, 2,...  \n",
       "2  [3, -1, 1, -2, -1, 0, -1, 1, -1, 0, 2, 2, 0, -...  \n",
       "3  [-1, -4, 1, 0, -1, 2, 3, 0, 0, 1, 0, 1, 2, 1, ...  \n",
       "4  [-4, 5, 13, 10, 6, 3, -6, -8, -1, 5, 2, -1, 2,...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the process_row function to each row in the DataFrame\n",
    "train_df['cropped_audio'] = train_df.apply(crop_audio, axis=1) \n",
    "train_df.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4a32302040>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize again, much better!\n",
    "plt.plot(train_df['cropped_audio'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ipa</th>\n",
       "      <th>audio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ɹɛɡɹintɑmttʃʊztəwɑttʃkɑɹtunzniɛftɹnun</td>\n",
       "      <td>[2, 0, 1, 1, 7, 2, 10, 2, -3, 0, 5, 3, 5, -1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wɪttʃttʃɹttʃduðɪsmɪθswɹʃipɪn</td>\n",
       "      <td>[1, 3, 2, 2, 1, 3, 1, -1, 1, 0, 4, 3, 2, 1, 2,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ʃihæddʒɹdɑɹksuʔnɹisiwɔʃwɔɾɹʔɔljɪɹ</td>\n",
       "      <td>[3, -1, 1, -2, -1, 0, -1, 1, -1, 0, 2, 2, 0, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>əblɪsiɾihɛnoʊɾɹaɪiɾiɡoʊhændinhænd</td>\n",
       "      <td>[-1, -4, 1, 0, -1, 2, 3, 0, 0, 1, 0, 1, 2, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hinivɛlfiŋfɪlmmɛɾitɑksikimiklzɹjuzd</td>\n",
       "      <td>[-4, 5, 13, 10, 6, 3, -6, -8, -1, 5, 2, -1, 2,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     ipa  \\\n",
       "0  ɹɛɡɹintɑmttʃʊztəwɑttʃkɑɹtunzniɛftɹnun   \n",
       "1           wɪttʃttʃɹttʃduðɪsmɪθswɹʃipɪn   \n",
       "2      ʃihæddʒɹdɑɹksuʔnɹisiwɔʃwɔɾɹʔɔljɪɹ   \n",
       "3      əblɪsiɾihɛnoʊɾɹaɪiɾiɡoʊhændinhænd   \n",
       "4    hinivɛlfiŋfɪlmmɛɾitɑksikimiklzɹjuzd   \n",
       "\n",
       "                                               audio  \n",
       "0  [2, 0, 1, 1, 7, 2, 10, 2, -3, 0, 5, 3, 5, -1, ...  \n",
       "1  [1, 3, 2, 2, 1, 3, 1, -1, 1, 0, 4, 3, 2, 1, 2,...  \n",
       "2  [3, -1, 1, -2, -1, 0, -1, 1, -1, 0, 2, 2, 0, -...  \n",
       "3  [-1, -4, 1, 0, -1, 2, 3, 0, 0, 1, 0, 1, 2, 1, ...  \n",
       "4  [-4, 5, 13, 10, 6, 3, -6, -8, -1, 5, 2, -1, 2,...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_df comprised of just cropped_audio and phonemes\n",
    "train_df = train_df.drop(columns=['phoneme_starts', 'phoneme_ends', 'audio'])\n",
    "# rename cropped audio to audio\n",
    "train_df = train_df.rename(columns={'cropped_audio': 'audio'})\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset.from_pandas(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extend Phoneme Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "timit_vocab = set(\"\".join(train_df['ipa']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'u', 'ɡ', 'w', 'ɾ', 'i', 'h', 'ʊ', 'ɔ', 'l', 'd', 'k', 'ʒ', 'n', 'ɹ', 'o', 'ð', 'v', 'ɛ', 'b', 'ŋ', 't', 's', 'm', 'ɑ', 'ə', 'f', 'æ', 'ʔ', 'e', 'a', 'ʌ', 'j', 'ʃ', 'θ', 'z', 'ɪ', 'p'}\n"
     ]
    }
   ],
   "source": [
    "print(timit_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 113, 'C': 20, 'E': 89, 'H': 148, 'I': 124, 'O': 28, 'U': 176, 'X': 224, '[PAD]': 312, '[UNK]': 311, '_': 259, 'a': 156, 'ã': 188, 'b': 286, 'b̪': 83, 'b̪͡v': 137, 'b͡ꞵ': 80, 'c': 186, 'cʼ': 277, 'c͡ç': 265, 'd': 229, 'd̼': 210, 'd͡z': 51, 'd͡ð': 110, 'd͡ɮ': 284, 'd͡ʑ': 112, 'd͡ʒ': 214, 'e': 22, 'ẽ': 233, 'e̞': 202, 'ẽ̞': 187, 'f': 34, 'fʼ': 181, 'h': 253, 'i': 160, 'j': 92, 'k': 135, 'kxʼ': 221, 'kǀ': 25, 'kǁ': 140, 'kǂ': 115, 'kǃ': 97, 'kʘ': 165, 'kʼ': 7, 'k̚': 118, 'k͡p': 102, 'k͡x': 287, 'l': 292, 'm': 85, 'm̥': 101, 'n': 141, 'n̥': 54, 'n̼': 61, 'o': 162, 'õ': 62, 'o̞': 203, 'õ̞': 60, 'p': 38, 'pʼ': 216, 'p̚': 11, 'p̪': 236, 'p̪͡f': 205, 'p͡f': 43, 'p͡ɸ': 154, 'q': 237, 'qǀ': 9, 'qǁ': 49, 'qǂ': 196, 'qǃ': 53, 'qʘ': 119, 'qʼ': 99, 'q͡ʡ': 169, 'q͡χʼ': 44, 'q͡ꭓ': 226, 'r': 254, 'r̥': 174, 's': 201, 'sʼ': 117, 't': 39, 'tʼ': 2, 't̚': 59, 't̪͡θʼ': 50, 't̼': 307, 't͡s': 264, 't͡sʼ': 68, 't͡ɕ': 281, 't͡ɬ': 158, 't͡ɬʼ': 172, 't͡ʃ': 246, 't͡ʃʼ': 192, 't͡θ': 161, 'u': 48, 'ũ': 159, 'v': 82, 'w': 127, 'x': 177, 'xʼ': 66, 'y': 261, 'ỹ': 189, 'z': 126, '{': 73, '}': 238, 'ã': 209, 'ä': 69, 'ä̃': 47, 'æ': 26, 'æ̃': 153, 'ç': 10, 'ð': 266, 'ð̠': 163, 'ð̼': 204, 'õ': 298, 'ø': 95, 'ø̃': 3, 'ø̞': 121, 'ø̞̃': 280, 'ħ': 19, 'ĩ': 42, 'ŋ': 222, 'ŋǀ': 109, 'ŋǁ': 310, 'ŋǂ': 301, 'ŋǃ': 232, 'ŋʘ': 58, 'ŋ̊': 146, 'ŋ͡m': 302, 'œ': 111, 'œ̃': 132, 'ũ': 248, 'ɐ': 197, 'ɐ̃': 234, 'ɑ': 208, 'ɑ̃': 37, 'ɒ': 18, 'ɒ̃': 4, 'ɓ': 303, 'ɓ̥': 157, 'ɔ': 106, 'ɔ̃': 183, 'ɕ': 308, 'ɕʼ': 185, 'ɖ': 239, 'ɖ͡ʐ': 215, 'ɗ': 180, 'ɗ̥': 300, 'ɘ': 91, 'ɘ̃': 41, 'ə': 155, 'ə̃': 289, 'ɚ': 131, 'ɛ': 282, 'ɛ̃': 65, 'ɜ': 297, 'ɜ̃': 14, 'ɝ': 151, 'ɞ': 198, 'ɞ̃': 120, 'ɟ': 166, 'ɟ͡ʝ': 150, 'ɠ': 164, 'ɠ̊': 247, 'ɡ': 103, 'ɡǀ': 79, 'ɡǁ': 269, 'ɡǂ': 98, 'ɡǃ': 133, 'ɡʘ': 134, 'ɡ̆': 228, 'ɡ͡b': 70, 'ɡ͡ɣ': 190, 'ɢ': 220, 'ɢǀ': 152, 'ɢǁ': 116, 'ɢǂ': 168, 'ɢǃ': 290, 'ɢʘ': 268, 'ɢ̆': 267, 'ɢ͡ʁ': 63, 'ɣ': 149, 'ɤ': 147, 'ɤ̃': 67, 'ɤ̞': 244, 'ɤ̞̃': 240, 'ɥ': 74, 'ɥ̊': 64, 'ɧ': 87, 'ɨ': 123, 'ɨ̃': 72, 'ɪ': 256, 'ɪ̃': 179, 'ɬ': 108, 'ɬʼ': 207, 'ɭ': 249, 'ɭ˔': 262, 'ɭ̆': 178, 'ɭ̥̆': 299, 'ɮ': 242, 'ɯ': 213, 'ɯ̃': 76, 'ɰ': 250, 'ɱ': 219, 'ɲ': 31, 'ɲ̊': 30, 'ɳ': 193, 'ɳ̊': 184, 'ɴ': 257, 'ɴǀ': 138, 'ɴǁ': 182, 'ɴǂ': 206, 'ɴǃ': 243, 'ɴʘ': 23, 'ɵ': 212, 'ɵ̃': 94, 'ɶ': 296, 'ɶ̃': 24, 'ɸ': 199, 'ɸʼ': 305, 'ɹ': 285, 'ɹ̠˔': 260, 'ɹ̠̊˔': 12, 'ɺ': 100, 'ɺ̥': 139, 'ɻ': 273, 'ɻ˔': 55, 'ɻ̊˔': 170, 'ɽ': 211, 'ɽ̊': 270, 'ɾ': 251, 'ɾ̥': 21, 'ɾ̼': 27, 'ʀ': 235, 'ʀ̥': 125, 'ʁ': 200, 'ʂ': 75, 'ʂʼ': 96, 'ʃ': 279, 'ʃʼ': 230, 'ʄ': 291, 'ʄ̊': 88, 'ʈ': 5, 'ʈʼ': 309, 'ʈ͡ʂ': 258, 'ʈ͡ʂʼ': 1, 'ʉ': 29, 'ʉ̃': 33, 'ʊ': 128, 'ʊ̃': 263, 'ʋ': 56, 'ʌ': 223, 'ʌ̃': 225, 'ʍ': 173, 'ʎ': 288, 'ʎ̆': 175, 'ʎ̝': 81, 'ʎ̝̊': 195, 'ʏ': 105, 'ʏ̃': 86, 'ʐ': 306, 'ʑ': 304, 'ʒ': 171, 'ʔ': 245, 'ʔ̞': 78, 'ʔ͡h': 276, 'ʕ': 107, 'ʙ': 104, 'ʙ̥': 6, 'ʛ': 15, 'ʛ̥': 294, 'ʜ': 16, 'ʝ': 84, 'ʟ': 52, 'ʟ̆': 275, 'ʟ̝': 8, 'ʟ̝̊': 57, 'ʟ̠': 40, 'ʡ': 194, 'ʡʼ': 231, 'ʡ̆': 32, 'ʡ͡ʜ': 114, 'ʡ͡ʢ': 122, 'ʢ': 36, 'ʰ': 45, 'ʲ': 191, 'ʷ': 144, 'ː': 295, '˞': 145, 'ˠ': 217, 'ˡ': 218, 'ˣ': 46, 'ˤ': 271, '̃': 283, '̩': 272, 'β': 0, 'θ': 278, 'θʼ': 71, 'θ̠': 13, 'θ̼': 136, 'χ': 129, 'χʼ': 241, 'ᵐ': 17, 'ᵑ': 274, 'ᶑ': 90, 'ᶑ̊': 293, 'ᶬ': 142, 'ᶮ': 130, 'ᶯ': 255, 'ᶰ': 252, 'ᶿ': 93, 'ẽ': 35, 'ⁿ': 143, 'ⱱ': 167, 'ⱱ̟': 227, 'ꞎ': 77, '<s>': 313, '</s>': 314}\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(PRE_TRAINED_ID)\n",
    "vocab = tokenizer.get_vocab()\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "additional_vocab = timit_vocab.difference(set(vocab.keys()) | {' '})\n",
    "tokenizer.add_tokens(list(additional_vocab))\n",
    "print(additional_vocab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = AutoFeatureExtractor.from_pretrained(PRE_TRAINED_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't need to update the feature extractor since it has been pretrained on 16kHz audio which matches the TIMIT dataset.\n",
    "\n",
    "For datasets with different sampling rates, the feature extractor should be updated or the audio resampled (easier).\n",
    "\n",
    "This is also where code to add extra features (such as conditioning on speaker's native language etc.) would be added."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NEW FINE-TUNE CODE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maruna-sri\u001b[0m (\u001b[33maruna-team\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/arunasrivastava/ML/notebooks/wandb/run-20241130_195758-mlqyema9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-overnight/runs/mlqyema9' target=\"_blank\">helpful-energy-11</a></strong> to <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-overnight' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-overnight' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-overnight</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-overnight/runs/mlqyema9' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-overnight/runs/mlqyema9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading pretrained model and processor...\n",
      "INFO:__main__:Initial vocabulary size: 315\n",
      "INFO:__main__:Initial special tokens setup:\n",
      "INFO:__main__:<pad>: 0\n",
      "INFO:__main__:<s>: 1\n",
      "INFO:__main__:</s>: 2\n",
      "INFO:__main__:<unk>: 3\n",
      "INFO:__main__:\n",
      "Verifying special token IDs in new tokenizer:\n",
      "INFO:__main__:<pad>: expected=0, actual=0\n",
      "INFO:__main__:<s>: expected=1, actual=1\n",
      "INFO:__main__:</s>: expected=2, actual=2\n",
      "INFO:__main__:<unk>: expected=3, actual=3\n",
      "INFO:__main__:\n",
      "Final vocabulary size: 41\n",
      "INFO:__main__:\n",
      "Final vocabulary check:\n",
      "INFO:__main__:<pad>: 0\n",
      "INFO:__main__:<s>: 1\n",
      "INFO:__main__:</s>: 2\n",
      "INFO:__main__:<unk>: 3\n",
      "INFO:__main__:\n",
      "=== Token ID Verification [After Model Preparation] ===\n",
      "INFO:__main__:Vocabulary size: 41\n",
      "INFO:__main__:Token <pad>: ID 0\n",
      "INFO:__main__:Token <s>: ID 1\n",
      "INFO:__main__:Token </s>: ID 2\n",
      "INFO:__main__:Token <unk>: ID 3\n",
      "INFO:__main__:Sample regular token IDs:\n",
      "INFO:__main__:Token a: ID 4\n",
      "INFO:__main__:Full vocabulary: {'<pad>': 0, '<s>': 1, '</s>': 2, '<unk>': 3, 'a': 4, 'b': 5, 'd': 6, 'e': 7, 'f': 8, 'h': 9, 'i': 10, 'j': 11, 'k': 12, 'l': 13, 'm': 14, 'n': 15, 'o': 16, 'p': 17, 's': 18, 't': 19, 'u': 20, 'v': 21, 'w': 22, 'z': 23, 'æ': 24, 'ð': 25, 'ŋ': 26, 'ɑ': 27, 'ɔ': 28, 'ə': 29, 'ɛ': 30, 'ɡ': 31, 'ɪ': 32, 'ɹ': 33, 'ɾ': 34, 'ʃ': 35, 'ʊ': 36, 'ʌ': 37, 'ʒ': 38, 'ʔ': 39, 'θ': 40}\n",
      "INFO:__main__:Splitting dataset into train and evaluation...\n",
      "Map (num_proc=4):   0%|          | 0/3696 [00:00<?, ? examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   3%|▎         | 93/3696 [00:05<01:35, 37.64 examples/s] /home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   9%|▉         | 330/3696 [00:08<00:39, 85.20 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):  20%|██        | 751/3696 [00:12<00:20, 140.72 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4): 100%|██████████| 3696/3696 [01:07<00:00, 54.42 examples/s] \n",
      "Map (num_proc=4):   0%|          | 0/924 [00:00<?, ? examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   2%|▏         | 16/924 [00:01<01:03, 14.27 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   5%|▍         | 45/924 [00:02<00:20, 43.11 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):  14%|█▍        | 132/924 [00:03<00:08, 94.87 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4): 100%|██████████| 924/924 [00:18<00:00, 51.04 examples/s] \n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/trainer.py:3347: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(os.path.join(checkpoint, OPTIMIZER_NAME), map_location=map_location)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/trainer.py:3026: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint_rng_state = torch.load(rng_file)\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2280' max='2280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2280/2280 29:41, Epoch 39/40]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>1.364000</td>\n",
       "      <td>0.271319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>1.423900</td>\n",
       "      <td>0.268392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>1.333900</td>\n",
       "      <td>0.268137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.374300</td>\n",
       "      <td>0.267506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>1.388700</td>\n",
       "      <td>0.266808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>1.203800</td>\n",
       "      <td>0.267281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>1.320900</td>\n",
       "      <td>0.267207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>1.312200</td>\n",
       "      <td>0.266943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>1.254300</td>\n",
       "      <td>0.267002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "INFO:__main__:\n",
      "=== Token ID Verification [After Training] ===\n",
      "INFO:__main__:Vocabulary size: 41\n",
      "INFO:__main__:Token <pad>: ID 0\n",
      "INFO:__main__:Token <s>: ID 1\n",
      "INFO:__main__:Token </s>: ID 2\n",
      "INFO:__main__:Token <unk>: ID 3\n",
      "INFO:__main__:Sample regular token IDs:\n",
      "INFO:__main__:Token a: ID 4\n",
      "INFO:__main__:Running inference on sample...\n",
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "INFO:__main__:Sample raw prediction: ['jɛtðəspɪɹɪʔwitʃlɪvzinkimuɾiɾiiznɑɾaɪdɛɾiklwɪθðikmjuɾiɾi']\n",
      "INFO:__main__:Sample cleaned prediction: jɛtðəspɪɹɪʔwitʃlɪvzinkimuɾiɾiiznɑɾaɪdɛɾiklwɪθðikmjuɾiɾi\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▃▃▂▁▂▂▁▁</td></tr><tr><td>eval/runtime</td><td>▅█▇▆▅▃▁▄▄</td></tr><tr><td>eval/samples_per_second</td><td>▄▁▂▂▃▆█▄▅</td></tr><tr><td>eval/steps_per_second</td><td>▄▁▂▂▃▆█▄▅</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>█▄▄▂▂▆▁▃▂▂▃▄▃▅▃▆▆▃▄▂▅▃▃▄▂▄▃▄▇▄▃▄▇▅▃▄▁▃▄▄</td></tr><tr><td>train/learning_rate</td><td>██▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/loss</td><td>▆▄▅▅▅▆▇▅▇▃▅▃▄▄▂▆▅▃▅▂▆▃▃▅▅▂▂▁▅▄▃▃▁▄▃▃▂▂▂█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.267</td></tr><tr><td>eval/runtime</td><td>35.0172</td></tr><tr><td>eval/samples_per_second</td><td>26.387</td></tr><tr><td>eval/steps_per_second</td><td>1.656</td></tr><tr><td>total_flos</td><td>4.4193552297984e+19</td></tr><tr><td>train/epoch</td><td>39.88312</td></tr><tr><td>train/global_step</td><td>2280</td></tr><tr><td>train/grad_norm</td><td>3.59556</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.4649</td></tr><tr><td>train_loss</td><td>0.27779</td></tr><tr><td>train_runtime</td><td>1795.0485</td></tr><tr><td>train_samples_per_second</td><td>82.36</td></tr><tr><td>train_steps_per_second</td><td>1.27</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">helpful-energy-11</strong> at: <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-overnight/runs/mlqyema9' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-overnight/runs/mlqyema9</a><br/> View project at: <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-overnight' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction-overnight</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241130_195758-mlqyema9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import tempfile\n",
    "from transformers import AutoProcessor, AutoModelForCTC, Trainer, TrainingArguments, Wav2Vec2CTCTokenizer\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional, Union\n",
    "import logging\n",
    "from torch.utils.data import DataLoader\n",
    "import wandb\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchaudio\n",
    "import json\n",
    "from transformers.trainer_callback import EarlyStoppingCallback\n",
    "\n",
    "#B1- LESS TRAINING EPOCHS\n",
    "#B2- LENGTH PENALTY \n",
    "#B3- MORE TRAINING EPOCHS\n",
    "\n",
    "NEW_MODEL_ID = \"./notebooks/results-b0\"\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Constants\n",
    "SAMPLING_RATE = 16000\n",
    "MAX_AUDIO_LENGTH = 160000  # 10 seconds at 16kHz\n",
    "MAX_LABEL_LENGTH = 100\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorCTCWithPadding:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs received.\n",
    "    \"\"\"\n",
    "    processor: AutoProcessor\n",
    "    padding: Union[bool, str] = \"longest\"\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # Add max length check\n",
    "        max_length = min(\n",
    "            max(len(feature[\"input_values\"]) for feature in features),\n",
    "            MAX_AUDIO_LENGTH  # Your existing constant\n",
    "        )\n",
    "        # Pad input_values\n",
    "        padded_inputs = []\n",
    "        attention_mask = []\n",
    "        for feature in features:\n",
    "            input_length = len(feature[\"input_values\"])\n",
    "            padding_length = max_length - input_length\n",
    "            \n",
    "            # Convert to tensor and ensure correct shape\n",
    "            if isinstance(feature[\"input_values\"], list):\n",
    "                input_values = torch.tensor(feature[\"input_values\"])\n",
    "            else:\n",
    "                input_values = feature[\"input_values\"]\n",
    "            \n",
    "            # Remove any extra dimensions and ensure it's 1D\n",
    "            input_values = input_values.squeeze()\n",
    "            \n",
    "            # Pad with zeros\n",
    "            if padding_length > 0:\n",
    "                padded_input = torch.nn.functional.pad(input_values, (0, padding_length))\n",
    "                attention_mask.append(torch.cat([torch.ones(input_length), torch.zeros(padding_length)]))\n",
    "            else:\n",
    "                padded_input = input_values\n",
    "                attention_mask.append(torch.ones(input_length))\n",
    "            \n",
    "            padded_inputs.append(padded_input)\n",
    "\n",
    "        # Stack all padded inputs ensuring correct dimensions [batch_size, sequence_length]\n",
    "        batch = {\n",
    "            \"input_values\": torch.stack(padded_inputs),\n",
    "            \"attention_mask\": torch.stack(attention_mask)\n",
    "        }\n",
    "\n",
    "        # Process labels\n",
    "        with self.processor.as_target_processor():\n",
    "            label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "            labels_batch = self.processor.pad(\n",
    "                label_features,\n",
    "                padding=self.padding,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "\n",
    "        # Replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch\n",
    "def prepare_model_and_processor(timit_vocab):\n",
    "    \"\"\"\n",
    "    Prepare the model and processor with reduced vocabulary and consistent special token IDs.\n",
    "    \"\"\"\n",
    "    logger.info(\"Loading pretrained model and processor...\")\n",
    "    \n",
    "    processor = AutoProcessor.from_pretrained(PRE_TRAINED_ID)\n",
    "    model = AutoModelForCTC.from_pretrained(PRE_TRAINED_ID)\n",
    "    \n",
    "    # Store the old vocabulary before making any changes\n",
    "    old_vocab = processor.tokenizer.get_vocab()\n",
    "    logger.info(f\"Initial vocabulary size: {len(old_vocab)}\")\n",
    "    \n",
    "    # Define fixed special token IDs - pad token first for CTC\n",
    "    special_tokens = {\n",
    "        \"<pad>\": 0,  # Changed to 0 for CTC blank token\n",
    "        \"<s>\": 1,    # Shifted up\n",
    "        \"</s>\": 2,   # Shifted up\n",
    "        \"<unk>\": 3   # Shifted up\n",
    "    }\n",
    "    logger.info(\"Initial special tokens setup:\")\n",
    "    for token, idx in special_tokens.items():\n",
    "        logger.info(f\"{token}: {idx}\")\n",
    "    \n",
    "    # Get regular tokens (excluding special tokens)\n",
    "    regular_tokens = sorted(list(timit_vocab - set(special_tokens.keys())))\n",
    "    \n",
    "    # Create combined vocabulary with fixed IDs\n",
    "    vocab = {**special_tokens}  # Start with special tokens\n",
    "    \n",
    "    # Add regular tokens after special tokens\n",
    "    for idx, token in enumerate(regular_tokens):\n",
    "        vocab[token] = idx + len(special_tokens)\n",
    "    \n",
    "    # Create tokenizer config with consistent token formats\n",
    "    tokenizer_config = {\n",
    "        \"vocab\": vocab,\n",
    "        \"pad_token\": \"<pad>\",\n",
    "        \"bos_token\": \"<s>\",\n",
    "        \"eos_token\": \"</s>\",\n",
    "        \"unk_token\": \"<unk>\",\n",
    "    }\n",
    "    \n",
    "    # Save vocab to temporary file\n",
    "    with tempfile.NamedTemporaryFile(mode='w', delete=False) as f:\n",
    "        json.dump(vocab, f)\n",
    "        vocab_path = f.name\n",
    "    \n",
    "    # Create new tokenizer\n",
    "    new_tokenizer = Wav2Vec2CTCTokenizer(\n",
    "        vocab_path,\n",
    "        **{k: v for k, v in tokenizer_config.items() if k != \"vocab\"}\n",
    "    )\n",
    "    \n",
    "    # Verify tokenizer loaded correctly before proceeding\n",
    "    loaded_vocab = new_tokenizer.get_vocab()\n",
    "    logger.info(\"\\nVerifying special token IDs in new tokenizer:\")\n",
    "    for token, expected_id in special_tokens.items():\n",
    "        actual_id = loaded_vocab.get(token)\n",
    "        logger.info(f\"{token}: expected={expected_id}, actual={actual_id}\")\n",
    "        assert actual_id == expected_id, f\"Token ID mismatch for {token}\"\n",
    "    \n",
    "    # Update processor with new tokenizer\n",
    "    processor.tokenizer = new_tokenizer\n",
    "    os.remove(vocab_path)\n",
    "    \n",
    "    # Verify vocab size\n",
    "    final_vocab_size = len(processor.tokenizer.get_vocab())\n",
    "    logger.info(f\"\\nFinal vocabulary size: {final_vocab_size}\")\n",
    "    assert final_vocab_size == len(vocab), \"Vocabulary size mismatch\"\n",
    "    \n",
    "    # Handle model weights\n",
    "    old_weights = model.lm_head.weight.data\n",
    "    old_bias = model.lm_head.bias.data\n",
    "    \n",
    "    # Create new layer\n",
    "    new_layer = torch.nn.Linear(model.lm_head.in_features, len(processor.tokenizer))\n",
    "    new_layer.weight.data.zero_()\n",
    "    new_layer.bias.data.zero_()\n",
    "    \n",
    "    # Transfer weights and bias using the stored old_vocab\n",
    "    for token, new_idx in loaded_vocab.items():\n",
    "        if token in old_vocab:\n",
    "            old_idx = old_vocab[token]\n",
    "            new_layer.weight.data[new_idx, :] = old_weights[old_idx, :]\n",
    "            new_layer.bias.data[new_idx] = old_bias[old_idx]\n",
    "    \n",
    "    model.lm_head = new_layer\n",
    "    model.config.vocab_size = final_vocab_size\n",
    "    model.config.pad_token_id = 0  # Explicitly set pad token as CTC blank token\n",
    "    \n",
    "    # Final verification\n",
    "    logger.info(\"\\nFinal vocabulary check:\")\n",
    "    final_vocab = processor.tokenizer.get_vocab()\n",
    "    for token, expected_id in special_tokens.items():\n",
    "        actual_id = final_vocab.get(token)\n",
    "        logger.info(f\"{token}: {actual_id}\")\n",
    "        assert actual_id == expected_id, f\"Final token ID mismatch for {token}\"\n",
    "    \n",
    "    return model, processor\n",
    "\n",
    "\n",
    "def preprocess_audio(audio_input):\n",
    "    \"\"\"\n",
    "    Load and preprocess audio to match expected format.\n",
    "    \n",
    "    Args:\n",
    "        audio_input: Can be a file path (str), numpy array, list, or tensor\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: Processed audio as float32 numpy array\n",
    "    \"\"\"\n",
    "    # Handle different input types\n",
    "    if isinstance(audio_input, str):  # File path\n",
    "        waveform, sample_rate = torchaudio.load(audio_input)\n",
    "        audio_numpy = waveform.squeeze().numpy()\n",
    "        \n",
    "    elif isinstance(audio_input, list):  # List input\n",
    "        audio_numpy = np.array(audio_input, dtype=np.float32)\n",
    "        \n",
    "    elif isinstance(audio_input, np.ndarray):  # Already numpy array\n",
    "        audio_numpy = audio_input\n",
    "        \n",
    "    elif isinstance(audio_input, torch.Tensor):  # Torch tensor\n",
    "        audio_numpy = audio_input.numpy()\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported audio type: {type(audio_input)}\")\n",
    "    \n",
    "    # Ensure float32 dtype\n",
    "    audio_numpy = audio_numpy.astype(np.float32)\n",
    "    \n",
    "    # Ensure 1D array\n",
    "    if len(audio_numpy.shape) > 1:\n",
    "        audio_numpy = np.mean(audio_numpy, axis=0)\n",
    "    \n",
    "    # Normalize audio\n",
    "    if np.abs(audio_numpy).max() > 1:\n",
    "        audio_numpy = audio_numpy / np.abs(audio_numpy).max()\n",
    "    \n",
    "    # Trim or pad to max length\n",
    "    if len(audio_numpy) > MAX_AUDIO_LENGTH:\n",
    "        audio_numpy = audio_numpy[:MAX_AUDIO_LENGTH]\n",
    "    elif len(audio_numpy) < MAX_AUDIO_LENGTH:\n",
    "        padding = np.zeros(MAX_AUDIO_LENGTH - len(audio_numpy), dtype=np.float32)\n",
    "        audio_numpy = np.concatenate([audio_numpy, padding])\n",
    "    \n",
    "    return audio_numpy\n",
    "\n",
    "def prepare_datasets(train_df, processor):\n",
    "    \"\"\"\n",
    "    Dataset preparation compatible with original data collator\n",
    "    \"\"\"\n",
    "    logger.info(\"Splitting dataset into train and evaluation...\")\n",
    "    \n",
    "    train_data, eval_data = train_test_split(train_df, test_size=0.2, random_state=42)\n",
    "    \n",
    "    def process_data(batch):\n",
    "        # Preprocess audio\n",
    "        audio = preprocess_audio(batch[\"audio\"])\n",
    "        audio = audio.squeeze()\n",
    "        \n",
    "        # Process audio without any padding or tensor conversion\n",
    "        inputs = processor(\n",
    "            audio, \n",
    "            sampling_rate=SAMPLING_RATE, \n",
    "            return_tensors=None\n",
    "        )\n",
    "        \n",
    "        input_values = np.squeeze(inputs[\"input_values\"])\n",
    "        \n",
    "        # Process labels without any padding or tensor conversion\n",
    "        with processor.as_target_processor():\n",
    "            labels = processor(batch[\"ipa\"]).input_ids\n",
    "        \n",
    "        return {\n",
    "            \"input_values\": input_values,\n",
    "            \"labels\": labels,\n",
    "            \"audio\": audio\n",
    "        }\n",
    "    \n",
    "    # Convert DataFrames to Datasets with optimized batch processing\n",
    "    train_dataset = Dataset.from_pandas(train_data)\n",
    "    eval_dataset = Dataset.from_pandas(eval_data)\n",
    "    \n",
    "    # Apply processing with larger batches\n",
    "    train_dataset = train_dataset.map(\n",
    "        process_data,\n",
    "        batch_size=32,\n",
    "        num_proc=4,\n",
    "        remove_columns=[col for col in train_dataset.column_names if col != \"audio\"]\n",
    "    )\n",
    "    eval_dataset = eval_dataset.map(\n",
    "        process_data,\n",
    "        batch_size=32,\n",
    "        num_proc=4,\n",
    "        remove_columns=[col for col in eval_dataset.column_names if col != \"audio\"]\n",
    "    )\n",
    "    \n",
    "    return train_dataset, eval_dataset\n",
    "\n",
    "def verify_dimensions(batch, logger):\n",
    "    \"\"\"\n",
    "    Debug helper to verify tensor dimensions\n",
    "    \"\"\"\n",
    "    logger.info(\"Batch dimensions:\")\n",
    "    for key, value in batch.items():\n",
    "        if isinstance(value, torch.Tensor):\n",
    "            logger.info(f\"{key}: {value.shape}\")\n",
    "\n",
    "\n",
    "def verify_token_ids(processor, stage=\"\"):\n",
    "    \"\"\"\n",
    "    Simple token verification function\n",
    "    \"\"\"\n",
    "    logger.info(f\"\\n=== Token ID Verification [{stage}] ===\")\n",
    "    vocab = processor.tokenizer.get_vocab()\n",
    "    logger.info(f\"Vocabulary size: {len(vocab)}\")\n",
    "    \n",
    "    # Check special tokens\n",
    "    special_tokens = [\"<pad>\", \"<s>\", \"</s>\", \"<unk>\"]\n",
    "    for token in special_tokens:\n",
    "        token_id = vocab.get(token)\n",
    "        logger.info(f\"Token {token}: ID {token_id}\")\n",
    "    \n",
    "    # Sample a few regular tokens\n",
    "    regular_tokens = [t for t in list(vocab.keys())[:5] if t not in special_tokens]\n",
    "    logger.info(\"Sample regular token IDs:\")\n",
    "    for token in regular_tokens:\n",
    "        logger.info(f\"Token {token}: ID {vocab[token]}\")\n",
    "    \n",
    "    return vocab\n",
    "\n",
    "def main(train_df, timit_vocab):\n",
    "    \"\"\"\n",
    "    Modified main training pipeline with optimized parameters based on hyperparameter search\n",
    "    \"\"\"\n",
    "    wandb.init(project=\"xlsr-buckeye-phoneme-prediction-overnight\")\n",
    "    \n",
    "    model, processor = prepare_model_and_processor(timit_vocab)\n",
    "    \n",
    "    vocab = verify_token_ids(processor, \"After Model Preparation\")\n",
    "    logger.info(f\"Full vocabulary: {vocab}\")\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Enable gradient checkpointing for memory efficiency\n",
    "    model.gradient_checkpointing_enable()\n",
    "    \n",
    "    # Prepare datasets with optimized batch processing\n",
    "    train_dataset, eval_dataset = prepare_datasets(train_df, processor)\n",
    "    \n",
    "    # Modified training arguments based on hyperparameter search results\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./results-b0\",\n",
    "        # Trial 4's best performing parameters\n",
    "        learning_rate=8e-5,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        gradient_accumulation_steps=4,\n",
    "        max_grad_norm=0.907,\n",
    "        \n",
    "        # Optimizer parameters from best trial\n",
    "        adam_beta1=0.93287,\n",
    "        adam_beta2=0.96748,\n",
    "        adam_epsilon=1e-8,\n",
    "        weight_decay=0.00599,\n",
    "        \n",
    "        # Learning rate schedule\n",
    "        warmup_ratio=0.08253,\n",
    "        lr_scheduler_type=\"cosine_with_restarts\",\n",
    "        \n",
    "        # Training duration and evaluation\n",
    "        num_train_epochs=40,\n",
    "        logging_dir='./logs',\n",
    "        logging_steps=10,\n",
    "        save_steps=300,\n",
    "        eval_steps=50,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"eval_loss\",\n",
    "        greater_is_better=False,\n",
    "        \n",
    "        # Model saving strategy\n",
    "        save_safetensors=True,\n",
    "        save_strategy=\"steps\",\n",
    "        save_total_limit=3,\n",
    "        \n",
    "        # Performance optimizations\n",
    "        fp16=True,\n",
    "        dataloader_num_workers=4,\n",
    "        dataloader_pin_memory=True,\n",
    "        gradient_checkpointing=True,\n",
    "    )\n",
    "    \n",
    "    # Modified data collator with efficient padding\n",
    "    data_collator = DataCollatorCTCWithPadding(\n",
    "        processor=processor,\n",
    "        padding=\"longest\"\n",
    "    )\n",
    "    \n",
    "    # Add early stopping callback\n",
    "    early_stopping = EarlyStoppingCallback(\n",
    "        early_stopping_patience=5,\n",
    "        early_stopping_threshold=0.01\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        data_collator=data_collator,\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "    \n",
    "    # Train model with optimized parameters\n",
    "    trainer.train(\"/home/arunasrivastava/ML/notebooks/results-b0/checkpoint-1800\")\n",
    "    \n",
    "    # Save the final model and processor\n",
    "    model.save_pretrained(\"./results-b0\")\n",
    "    processor.save_pretrained(\"./results-b0\")\n",
    "    \n",
    "    # Verify tokens after training\n",
    "    verify_token_ids(processor, \"After Training\")\n",
    "    \n",
    "    # Final inference verification\n",
    "    logger.info(\"Running inference on sample...\")\n",
    "    sample_audio = train_dataset[0][\"audio\"]\n",
    "    inputs = processor(sample_audio, return_tensors=\"pt\", padding=True)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "    \n",
    "    predicted_tokens = processor.batch_decode(predicted_ids)\n",
    "    cleaned_prediction = (predicted_tokens[0]\n",
    "                        .replace('<s>', '')\n",
    "                        .replace('</s>', '')\n",
    "                        .replace('<pad>', '')\n",
    "                        .replace('<unk>', '')\n",
    "                        .strip())\n",
    "    \n",
    "    logger.info(f\"Sample raw prediction: {predicted_tokens}\")\n",
    "    logger.info(f\"Sample cleaned prediction: {cleaned_prediction}\")\n",
    "    \n",
    "    wandb.finish()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(train_df, timit_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparam search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install optuna joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 06:53:56,968] A new study created in memory with name: no-name-9ce4d42f-34ac-4594-8543-501e58004d3a\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:42v96w1w) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_0</strong> at: <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction/runs/42v96w1w' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction/runs/42v96w1w</a><br/> View project at: <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction</a><br/>Synced 4 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241130_065036-42v96w1w/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:42v96w1w). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/arunasrivastava/ML/notebooks/wandb/run-20241130_065356-w8ezizpw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction/runs/w8ezizpw' target=\"_blank\">trial_0</a></strong> to <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction/runs/w8ezizpw' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction/runs/w8ezizpw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading pretrained model and processor...\n",
      "INFO:__main__:Initial vocabulary size: 315\n",
      "INFO:__main__:Initial special tokens setup:\n",
      "INFO:__main__:<pad>: 0\n",
      "INFO:__main__:<s>: 1\n",
      "INFO:__main__:</s>: 2\n",
      "INFO:__main__:<unk>: 3\n",
      "INFO:__main__:\n",
      "Verifying special token IDs in new tokenizer:\n",
      "INFO:__main__:<pad>: expected=0, actual=0\n",
      "INFO:__main__:<s>: expected=1, actual=1\n",
      "INFO:__main__:</s>: expected=2, actual=2\n",
      "INFO:__main__:<unk>: expected=3, actual=3\n",
      "INFO:__main__:\n",
      "Final vocabulary size: 41\n",
      "INFO:__main__:\n",
      "Final vocabulary check:\n",
      "INFO:__main__:<pad>: 0\n",
      "INFO:__main__:<s>: 1\n",
      "INFO:__main__:</s>: 2\n",
      "INFO:__main__:<unk>: 3\n",
      "INFO:__main__:Splitting dataset into train and evaluation...\n",
      "Map (num_proc=4):   0%|          | 0/3696 [00:00<?, ? examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   2%|▏         | 89/3696 [00:05<01:34, 38.14 examples/s] /home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   8%|▊         | 303/3696 [00:08<00:36, 92.94 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):  17%|█▋        | 643/3696 [00:11<00:41, 73.04 examples/s] /home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4): 100%|██████████| 3696/3696 [01:21<00:00, 45.29 examples/s] \n",
      "Map (num_proc=4):   0%|          | 0/924 [00:00<?, ? examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   4%|▍         | 36/924 [00:01<00:28, 30.96 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):  13%|█▎        | 117/924 [00:03<00:12, 64.29 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):  27%|██▋       | 245/924 [00:04<00:05, 115.97 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4): 100%|██████████| 924/924 [00:18<00:00, 49.19 examples/s] \n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1800' max='2310' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1800/2310 28:00 < 07:56, 1.07 it/s, Epoch 3/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>57.621400</td>\n",
       "      <td>23.017355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>32.598000</td>\n",
       "      <td>15.419108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>29.435000</td>\n",
       "      <td>14.028382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>24.639100</td>\n",
       "      <td>11.438320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>20.599200</td>\n",
       "      <td>10.538558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>18.128500</td>\n",
       "      <td>9.989381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>23.206100</td>\n",
       "      <td>10.199656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>21.120200</td>\n",
       "      <td>9.461869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>24.016500</td>\n",
       "      <td>9.173496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>17.510500</td>\n",
       "      <td>9.425522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>19.031300</td>\n",
       "      <td>8.878605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>22.679700</td>\n",
       "      <td>9.051204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>16.942100</td>\n",
       "      <td>9.020010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>18.190700</td>\n",
       "      <td>9.116051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>22.417900</td>\n",
       "      <td>8.847750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>19.655900</td>\n",
       "      <td>8.868653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>17.333400</td>\n",
       "      <td>8.954391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>22.269200</td>\n",
       "      <td>9.010047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='231' max='231' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [231/231 00:28]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_eval_loss</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▄▄▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▇▇▆██▅█▆█▇▇▆█▅▇▁▂▁▂</td></tr><tr><td>eval/samples_per_second</td><td>▂▁▂▁▁▃▁▂▁▂▂▂▁▃▂█▇█▆</td></tr><tr><td>eval/steps_per_second</td><td>▂▁▂▁▁▃▁▂▁▂▂▂▁▃▂█▇█▆</td></tr><tr><td>final_train_loss</td><td>▁</td></tr><tr><td>hp_adam_beta1</td><td>▁</td></tr><tr><td>hp_adam_beta2</td><td>▁</td></tr><tr><td>hp_adam_epsilon</td><td>▁</td></tr><tr><td>hp_batch_size</td><td>▁</td></tr><tr><td>hp_gradient_accumulation_steps</td><td>▁</td></tr><tr><td>hp_learning_rate</td><td>▁</td></tr><tr><td>hp_max_grad_norm</td><td>▁</td></tr><tr><td>hp_warmup_ratio</td><td>▁</td></tr><tr><td>hp_weight_decay</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>train/grad_norm</td><td>▄▇▃█▂▁▁▂▂▂▁▂▁▄▂▁▂▃▃▄▂▁▃▄▁▁▅▂▂▂▄▃▁▄▂▃</td></tr><tr><td>train/learning_rate</td><td>▁▂▄▅▆▇██████▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▂▂▂▂▁</td></tr><tr><td>train/loss</td><td>█▇▄▃▃▃▂▂▂▂▂▁▂▂▂▂▁▂▂▁▂▂▂▂▂▁▁▁▂▂▂▂▂▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_eval_loss</td><td>8.87849</td></tr><tr><td>eval/loss</td><td>8.87849</td></tr><tr><td>eval/runtime</td><td>30.069</td></tr><tr><td>eval/samples_per_second</td><td>30.729</td></tr><tr><td>eval/steps_per_second</td><td>7.682</td></tr><tr><td>final_train_loss</td><td>24.19879</td></tr><tr><td>hp_adam_beta1</td><td>0.85206</td></tr><tr><td>hp_adam_beta2</td><td>0.99753</td></tr><tr><td>hp_adam_epsilon</td><td>0.0</td></tr><tr><td>hp_batch_size</td><td>4</td></tr><tr><td>hp_gradient_accumulation_steps</td><td>2</td></tr><tr><td>hp_learning_rate</td><td>1e-05</td></tr><tr><td>hp_max_grad_norm</td><td>1.56211</td></tr><tr><td>hp_warmup_ratio</td><td>0.13662</td></tr><tr><td>hp_weight_decay</td><td>0.01593</td></tr><tr><td>total_flos</td><td>4.36120581888e+18</td></tr><tr><td>train/epoch</td><td>3.8961</td></tr><tr><td>train/global_step</td><td>1800</td></tr><tr><td>train/grad_norm</td><td>307.1636</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>22.2692</td></tr><tr><td>train_loss</td><td>24.19879</td></tr><tr><td>train_runtime</td><td>1683.045</td></tr><tr><td>train_samples_per_second</td><td>10.98</td></tr><tr><td>train_steps_per_second</td><td>1.373</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_0</strong> at: <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction/runs/w8ezizpw' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction/runs/w8ezizpw</a><br/> View project at: <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241130_065356-w8ezizpw/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 07:24:21,440] Trial 0 finished with value: 8.878494262695312 and parameters: {'learning_rate': 5.611516415334504e-06, 'batch_size': 4, 'gradient_accumulation_steps': 2, 'warmup_ratio': 0.1366176145774935, 'weight_decay': 0.015930522616241012, 'max_grad_norm': 1.5621088666940683, 'adam_beta1': 0.8520584494295802, 'adam_beta2': 0.9975255827559377, 'adam_epsilon': 4.622589001020826e-08}. Best is trial 0 with value: 8.878494262695312.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/arunasrivastava/ML/notebooks/wandb/run-20241130_072421-wo7ll5re</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction/runs/wo7ll5re' target=\"_blank\">trial_1</a></strong> to <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction/runs/wo7ll5re' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction/runs/wo7ll5re</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading pretrained model and processor...\n",
      "INFO:__main__:Initial vocabulary size: 315\n",
      "INFO:__main__:Initial special tokens setup:\n",
      "INFO:__main__:<pad>: 0\n",
      "INFO:__main__:<s>: 1\n",
      "INFO:__main__:</s>: 2\n",
      "INFO:__main__:<unk>: 3\n",
      "INFO:__main__:\n",
      "Verifying special token IDs in new tokenizer:\n",
      "INFO:__main__:<pad>: expected=0, actual=0\n",
      "INFO:__main__:<s>: expected=1, actual=1\n",
      "INFO:__main__:</s>: expected=2, actual=2\n",
      "INFO:__main__:<unk>: expected=3, actual=3\n",
      "INFO:__main__:\n",
      "Final vocabulary size: 41\n",
      "INFO:__main__:\n",
      "Final vocabulary check:\n",
      "INFO:__main__:<pad>: 0\n",
      "INFO:__main__:<s>: 1\n",
      "INFO:__main__:</s>: 2\n",
      "INFO:__main__:<unk>: 3\n",
      "INFO:__main__:Splitting dataset into train and evaluation...\n",
      "Map (num_proc=4):   0%|          | 0/3696 [00:00<?, ? examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   3%|▎         | 104/3696 [00:05<02:24, 24.86 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   9%|▊         | 322/3696 [00:08<01:08, 48.93 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):  19%|█▉        | 707/3696 [00:11<00:21, 141.18 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4): 100%|██████████| 3696/3696 [01:13<00:00, 50.62 examples/s] \n",
      "Map (num_proc=4):   0%|          | 0/924 [00:00<?, ? examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   4%|▎         | 34/924 [00:01<00:29, 30.25 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):  12%|█▏        | 109/924 [00:02<00:11, 72.20 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):  26%|██▌       | 242/924 [00:03<00:04, 137.81 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4): 100%|██████████| 924/924 [00:16<00:00, 56.36 examples/s] \n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='575' max='575' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [575/575 11:27, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>42.523600</td>\n",
       "      <td>16.219936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>30.568900</td>\n",
       "      <td>14.440888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>29.528700</td>\n",
       "      <td>13.757891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>28.050900</td>\n",
       "      <td>13.439654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>26.644200</td>\n",
       "      <td>13.300109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:26]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_eval_loss</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▄▂▁▁▁</td></tr><tr><td>eval/runtime</td><td>▁▂▁▂██</td></tr><tr><td>eval/samples_per_second</td><td>█▇█▇▁▁</td></tr><tr><td>eval/steps_per_second</td><td>█▇█▇▁▁</td></tr><tr><td>final_train_loss</td><td>▁</td></tr><tr><td>hp_adam_beta1</td><td>▁</td></tr><tr><td>hp_adam_beta2</td><td>▁</td></tr><tr><td>hp_adam_epsilon</td><td>▁</td></tr><tr><td>hp_batch_size</td><td>▁</td></tr><tr><td>hp_gradient_accumulation_steps</td><td>▁</td></tr><tr><td>hp_learning_rate</td><td>▁</td></tr><tr><td>hp_max_grad_norm</td><td>▁</td></tr><tr><td>hp_warmup_ratio</td><td>▁</td></tr><tr><td>hp_weight_decay</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▂▂▂▃▃▄▄▄▅▆▆▆▇▇███</td></tr><tr><td>train/global_step</td><td>▁▂▂▂▃▃▄▄▄▅▆▆▆▇▇████</td></tr><tr><td>train/grad_norm</td><td>▅▂▂▁▁▂▁▁▁█▃</td></tr><tr><td>train/learning_rate</td><td>▅██▇▆▅▄▃▂▁▁</td></tr><tr><td>train/loss</td><td>█▄▂▂▁▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_eval_loss</td><td>13.30926</td></tr><tr><td>eval/loss</td><td>13.30926</td></tr><tr><td>eval/runtime</td><td>31.1916</td></tr><tr><td>eval/samples_per_second</td><td>29.623</td></tr><tr><td>eval/steps_per_second</td><td>1.859</td></tr><tr><td>final_train_loss</td><td>32.47763</td></tr><tr><td>hp_adam_beta1</td><td>0.88664</td></tr><tr><td>hp_adam_beta2</td><td>0.97235</td></tr><tr><td>hp_adam_epsilon</td><td>0.0</td></tr><tr><td>hp_batch_size</td><td>16</td></tr><tr><td>hp_gradient_accumulation_steps</td><td>2</td></tr><tr><td>hp_learning_rate</td><td>0.0</td></tr><tr><td>hp_max_grad_norm</td><td>0.93822</td></tr><tr><td>hp_warmup_ratio</td><td>0.11119</td></tr><tr><td>hp_weight_decay</td><td>0.0019</td></tr><tr><td>total_flos</td><td>5.57265187968e+18</td></tr><tr><td>train/epoch</td><td>4.97835</td></tr><tr><td>train/global_step</td><td>575</td></tr><tr><td>train/grad_norm</td><td>281.18451</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>26.9062</td></tr><tr><td>train_loss</td><td>32.47763</td></tr><tr><td>train_runtime</td><td>691.6179</td></tr><tr><td>train_samples_per_second</td><td>26.72</td></tr><tr><td>train_steps_per_second</td><td>0.831</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_1</strong> at: <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction/runs/wo7ll5re' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction/runs/wo7ll5re</a><br/> View project at: <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241130_072421-wo7ll5re/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 07:38:03,377] Trial 1 finished with value: 13.309263229370117 and parameters: {'learning_rate': 2.6587543983272713e-06, 'batch_size': 16, 'gradient_accumulation_steps': 2, 'warmup_ratio': 0.11118528947223794, 'weight_decay': 0.0019010245319870357, 'max_grad_norm': 0.9382169728028272, 'adam_beta1': 0.8866361843293691, 'adam_beta2': 0.9723474292266348, 'adam_epsilon': 3.7183641805732076e-08}. Best is trial 0 with value: 8.878494262695312.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/arunasrivastava/ML/notebooks/wandb/run-20241130_073803-26xh1c0b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction/runs/26xh1c0b' target=\"_blank\">trial_2</a></strong> to <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction/runs/26xh1c0b' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction/runs/26xh1c0b</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading pretrained model and processor...\n",
      "INFO:__main__:Initial vocabulary size: 315\n",
      "INFO:__main__:Initial special tokens setup:\n",
      "INFO:__main__:<pad>: 0\n",
      "INFO:__main__:<s>: 1\n",
      "INFO:__main__:</s>: 2\n",
      "INFO:__main__:<unk>: 3\n",
      "INFO:__main__:\n",
      "Verifying special token IDs in new tokenizer:\n",
      "INFO:__main__:<pad>: expected=0, actual=0\n",
      "INFO:__main__:<s>: expected=1, actual=1\n",
      "INFO:__main__:</s>: expected=2, actual=2\n",
      "INFO:__main__:<unk>: expected=3, actual=3\n",
      "INFO:__main__:\n",
      "Final vocabulary size: 41\n",
      "INFO:__main__:\n",
      "Final vocabulary check:\n",
      "INFO:__main__:<pad>: 0\n",
      "INFO:__main__:<s>: 1\n",
      "INFO:__main__:</s>: 2\n",
      "INFO:__main__:<unk>: 3\n",
      "INFO:__main__:Splitting dataset into train and evaluation...\n",
      "Map (num_proc=4):   0%|          | 0/3696 [00:00<?, ? examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   3%|▎         | 113/3696 [00:06<01:14, 48.30 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   9%|▊         | 317/3696 [00:09<01:10, 48.06 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):  18%|█▊        | 682/3696 [00:12<00:30, 98.97 examples/s] /home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4): 100%|██████████| 3696/3696 [01:26<00:00, 42.60 examples/s] \n",
      "Map (num_proc=4):   0%|          | 0/924 [00:00<?, ? examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   3%|▎         | 31/924 [00:02<00:36, 24.79 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):  10%|█         | 96/924 [00:03<00:12, 65.33 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):  23%|██▎       | 216/924 [00:04<00:06, 108.16 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4): 100%|██████████| 924/924 [00:18<00:00, 49.36 examples/s] \n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 18:26, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>57.265200</td>\n",
       "      <td>24.213387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>31.577800</td>\n",
       "      <td>15.262308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>27.315900</td>\n",
       "      <td>14.390940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>27.095500</td>\n",
       "      <td>13.345435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>25.954200</td>\n",
       "      <td>12.942028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>27.233300</td>\n",
       "      <td>12.364116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>23.471200</td>\n",
       "      <td>12.201485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>24.785000</td>\n",
       "      <td>11.946882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>23.619200</td>\n",
       "      <td>11.792094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>24.173800</td>\n",
       "      <td>11.642458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>23.502600</td>\n",
       "      <td>11.643061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='116' max='116' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [116/116 00:28]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_eval_loss</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▃▃▂▂▁▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▁▁▄▃▇▄▂▂█▃▅▁</td></tr><tr><td>eval/samples_per_second</td><td>██▅▆▂▄▆▇▁▆▄█</td></tr><tr><td>eval/steps_per_second</td><td>██▅▆▂▄▆▇▁▆▄█</td></tr><tr><td>final_train_loss</td><td>▁</td></tr><tr><td>hp_adam_beta1</td><td>▁</td></tr><tr><td>hp_adam_beta2</td><td>▁</td></tr><tr><td>hp_adam_epsilon</td><td>▁</td></tr><tr><td>hp_batch_size</td><td>▁</td></tr><tr><td>hp_gradient_accumulation_steps</td><td>▁</td></tr><tr><td>hp_learning_rate</td><td>▁</td></tr><tr><td>hp_max_grad_norm</td><td>▁</td></tr><tr><td>hp_warmup_ratio</td><td>▁</td></tr><tr><td>hp_weight_decay</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇██████</td></tr><tr><td>train/grad_norm</td><td>█▄▃▁▄▄▂▄▅▂▄▂▂▃▃▃▂▃▁▄▂█▃</td></tr><tr><td>train/learning_rate</td><td>▃▅▇████▇▇▆▆▅▅▄▄▃▃▂▂▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▇▄▂▂▂▂▂▂▁▂▂▁▁▂▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_eval_loss</td><td>11.64954</td></tr><tr><td>eval/loss</td><td>11.64954</td></tr><tr><td>eval/runtime</td><td>32.1084</td></tr><tr><td>eval/samples_per_second</td><td>28.778</td></tr><tr><td>eval/steps_per_second</td><td>3.613</td></tr><tr><td>final_train_loss</td><td>29.56763</td></tr><tr><td>hp_adam_beta1</td><td>0.88046</td></tr><tr><td>hp_adam_beta2</td><td>0.95479</td></tr><tr><td>hp_adam_epsilon</td><td>0.0</td></tr><tr><td>hp_batch_size</td><td>8</td></tr><tr><td>hp_gradient_accumulation_steps</td><td>2</td></tr><tr><td>hp_learning_rate</td><td>0.0</td></tr><tr><td>hp_max_grad_norm</td><td>1.7126</td></tr><tr><td>hp_warmup_ratio</td><td>0.14489</td></tr><tr><td>hp_weight_decay</td><td>0.08536</td></tr><tr><td>total_flos</td><td>5.596880800896e+18</td></tr><tr><td>train/epoch</td><td>5</td></tr><tr><td>train/global_step</td><td>1155</td></tr><tr><td>train/grad_norm</td><td>200.85458</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>23.6117</td></tr><tr><td>train_loss</td><td>29.56763</td></tr><tr><td>train_runtime</td><td>1109.825</td></tr><tr><td>train_samples_per_second</td><td>16.651</td></tr><tr><td>train_steps_per_second</td><td>1.041</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_2</strong> at: <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction/runs/26xh1c0b' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction/runs/26xh1c0b</a><br/> View project at: <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241130_073803-26xh1c0b/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 07:59:02,157] Trial 2 finished with value: 11.649544715881348 and parameters: {'learning_rate': 2.5081156860452325e-06, 'batch_size': 8, 'gradient_accumulation_steps': 2, 'warmup_ratio': 0.14488855372533332, 'weight_decay': 0.08536189862866832, 'max_grad_norm': 1.7125960221746916, 'adam_beta1': 0.8804613769173371, 'adam_beta2': 0.9547859335863128, 'adam_epsilon': 2.335963502626154e-08}. Best is trial 0 with value: 8.878494262695312.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/arunasrivastava/ML/notebooks/wandb/run-20241130_075902-62fjgxb1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction/runs/62fjgxb1' target=\"_blank\">trial_3</a></strong> to <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction/runs/62fjgxb1' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction/runs/62fjgxb1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading pretrained model and processor...\n",
      "INFO:__main__:Initial vocabulary size: 315\n",
      "INFO:__main__:Initial special tokens setup:\n",
      "INFO:__main__:<pad>: 0\n",
      "INFO:__main__:<s>: 1\n",
      "INFO:__main__:</s>: 2\n",
      "INFO:__main__:<unk>: 3\n",
      "INFO:__main__:\n",
      "Verifying special token IDs in new tokenizer:\n",
      "INFO:__main__:<pad>: expected=0, actual=0\n",
      "INFO:__main__:<s>: expected=1, actual=1\n",
      "INFO:__main__:</s>: expected=2, actual=2\n",
      "INFO:__main__:<unk>: expected=3, actual=3\n",
      "INFO:__main__:\n",
      "Final vocabulary size: 41\n",
      "INFO:__main__:\n",
      "Final vocabulary check:\n",
      "INFO:__main__:<pad>: 0\n",
      "INFO:__main__:<s>: 1\n",
      "INFO:__main__:</s>: 2\n",
      "INFO:__main__:<unk>: 3\n",
      "INFO:__main__:Splitting dataset into train and evaluation...\n",
      "Map (num_proc=4):   0%|          | 0/3696 [00:00<?, ? examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   3%|▎         | 106/3696 [00:06<02:21, 25.46 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   8%|▊         | 310/3696 [00:08<01:08, 49.78 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):  18%|█▊        | 674/3696 [00:12<00:24, 123.97 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4): 100%|██████████| 3696/3696 [01:18<00:00, 46.86 examples/s] \n",
      "Map (num_proc=4):   0%|          | 0/924 [00:00<?, ? examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   4%|▍         | 35/924 [00:02<00:32, 27.36 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):  12%|█▏        | 111/924 [00:03<00:11, 71.63 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):  27%|██▋       | 246/924 [00:04<00:05, 132.57 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4): 100%|██████████| 924/924 [00:18<00:00, 51.33 examples/s] \n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1155' max='1155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1155/1155 15:33, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>35.897100</td>\n",
       "      <td>14.861642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>25.821600</td>\n",
       "      <td>11.994327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>20.927300</td>\n",
       "      <td>10.201719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>20.370700</td>\n",
       "      <td>9.298597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>19.174600</td>\n",
       "      <td>9.135119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>21.370500</td>\n",
       "      <td>8.979573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>17.619400</td>\n",
       "      <td>9.034185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>19.263900</td>\n",
       "      <td>8.877196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>18.517100</td>\n",
       "      <td>8.966104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>19.020900</td>\n",
       "      <td>8.802933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>18.775100</td>\n",
       "      <td>8.838684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='116' max='116' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [116/116 00:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_eval_loss</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▅▃▂▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▆▇█▆▂▂▁▂▃▃▁▂</td></tr><tr><td>eval/samples_per_second</td><td>▂▂▁▃▇▇█▇▅▆█▇</td></tr><tr><td>eval/steps_per_second</td><td>▂▂▁▃▇▇█▇▅▆█▇</td></tr><tr><td>final_train_loss</td><td>▁</td></tr><tr><td>hp_adam_beta1</td><td>▁</td></tr><tr><td>hp_adam_beta2</td><td>▁</td></tr><tr><td>hp_adam_epsilon</td><td>▁</td></tr><tr><td>hp_batch_size</td><td>▁</td></tr><tr><td>hp_gradient_accumulation_steps</td><td>▁</td></tr><tr><td>hp_learning_rate</td><td>▁</td></tr><tr><td>hp_max_grad_norm</td><td>▁</td></tr><tr><td>hp_warmup_ratio</td><td>▁</td></tr><tr><td>hp_weight_decay</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇██████</td></tr><tr><td>train/grad_norm</td><td>█▁▃▁▁▅▂▂▃▄▂▂▂▂▄▃▃▂▁▄▁▅▂</td></tr><tr><td>train/learning_rate</td><td>▄████▇▇▇▆▆▅▅▄▄▃▃▂▂▂▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▄▃▂▂▂▂▁▂▁▂▂▁▁▂▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_eval_loss</td><td>8.82295</td></tr><tr><td>eval/loss</td><td>8.82295</td></tr><tr><td>eval/runtime</td><td>26.1023</td></tr><tr><td>eval/samples_per_second</td><td>35.399</td></tr><tr><td>eval/steps_per_second</td><td>4.444</td></tr><tr><td>final_train_loss</td><td>22.98853</td></tr><tr><td>hp_adam_beta1</td><td>0.86849</td></tr><tr><td>hp_adam_beta2</td><td>0.99751</td></tr><tr><td>hp_adam_epsilon</td><td>0.0</td></tr><tr><td>hp_batch_size</td><td>8</td></tr><tr><td>hp_gradient_accumulation_steps</td><td>2</td></tr><tr><td>hp_learning_rate</td><td>1e-05</td></tr><tr><td>hp_max_grad_norm</td><td>1.32007</td></tr><tr><td>hp_warmup_ratio</td><td>0.08117</td></tr><tr><td>hp_weight_decay</td><td>0.01097</td></tr><tr><td>total_flos</td><td>5.596880800896e+18</td></tr><tr><td>train/epoch</td><td>5</td></tr><tr><td>train/global_step</td><td>1155</td></tr><tr><td>train/grad_norm</td><td>175.87665</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>18.5841</td></tr><tr><td>train_loss</td><td>22.98853</td></tr><tr><td>train_runtime</td><td>936.8971</td></tr><tr><td>train_samples_per_second</td><td>19.725</td></tr><tr><td>train_steps_per_second</td><td>1.233</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_3</strong> at: <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction/runs/62fjgxb1' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction/runs/62fjgxb1</a><br/> View project at: <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241130_075902-62fjgxb1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 08:16:54,097] Trial 3 finished with value: 8.822948455810547 and parameters: {'learning_rate': 7.5911048052827045e-06, 'batch_size': 8, 'gradient_accumulation_steps': 2, 'warmup_ratio': 0.0811711076089411, 'weight_decay': 0.010968217207529524, 'max_grad_norm': 1.3200654190149195, 'adam_beta1': 0.8684854455525527, 'adam_beta2': 0.9975096467604634, 'adam_epsilon': 3.550304858128307e-08}. Best is trial 3 with value: 8.822948455810547.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/arunasrivastava/ML/notebooks/wandb/run-20241130_081654-f3eor5c5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction/runs/f3eor5c5' target=\"_blank\">trial_4</a></strong> to <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction/runs/f3eor5c5' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction/runs/f3eor5c5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading pretrained model and processor...\n",
      "INFO:__main__:Initial vocabulary size: 315\n",
      "INFO:__main__:Initial special tokens setup:\n",
      "INFO:__main__:<pad>: 0\n",
      "INFO:__main__:<s>: 1\n",
      "INFO:__main__:</s>: 2\n",
      "INFO:__main__:<unk>: 3\n",
      "INFO:__main__:\n",
      "Verifying special token IDs in new tokenizer:\n",
      "INFO:__main__:<pad>: expected=0, actual=0\n",
      "INFO:__main__:<s>: expected=1, actual=1\n",
      "INFO:__main__:</s>: expected=2, actual=2\n",
      "INFO:__main__:<unk>: expected=3, actual=3\n",
      "INFO:__main__:\n",
      "Final vocabulary size: 41\n",
      "INFO:__main__:\n",
      "Final vocabulary check:\n",
      "INFO:__main__:<pad>: 0\n",
      "INFO:__main__:<s>: 1\n",
      "INFO:__main__:</s>: 2\n",
      "INFO:__main__:<unk>: 3\n",
      "INFO:__main__:Splitting dataset into train and evaluation...\n",
      "Map (num_proc=4):   0%|          | 0/3696 [00:00<?, ? examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   3%|▎         | 102/3696 [00:05<01:21, 44.34 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   9%|▉         | 330/3696 [00:08<01:13, 45.78 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):  19%|█▉        | 716/3696 [00:11<00:22, 132.31 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4): 100%|██████████| 3696/3696 [01:12<00:00, 50.78 examples/s] \n",
      "Map (num_proc=4):   0%|          | 0/924 [00:00<?, ? examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   3%|▎         | 28/924 [00:02<00:35, 25.46 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):  10%|█         | 97/924 [00:02<00:10, 78.10 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):  26%|██▌       | 240/924 [00:03<00:05, 133.54 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4): 100%|██████████| 924/924 [00:17<00:00, 53.31 examples/s] \n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='285' max='285' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [285/285 08:50, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>41.279400</td>\n",
       "      <td>9.086864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>34.164200</td>\n",
       "      <td>8.070320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_eval_loss</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▃▁</td></tr><tr><td>eval/runtime</td><td>█▁▂</td></tr><tr><td>eval/samples_per_second</td><td>▁█▆</td></tr><tr><td>eval/steps_per_second</td><td>▁█▆</td></tr><tr><td>final_train_loss</td><td>▁</td></tr><tr><td>hp_adam_beta1</td><td>▁</td></tr><tr><td>hp_adam_beta2</td><td>▁</td></tr><tr><td>hp_adam_epsilon</td><td>▁</td></tr><tr><td>hp_batch_size</td><td>▁</td></tr><tr><td>hp_gradient_accumulation_steps</td><td>▁</td></tr><tr><td>hp_learning_rate</td><td>▁</td></tr><tr><td>hp_max_grad_norm</td><td>▁</td></tr><tr><td>hp_warmup_ratio</td><td>▁</td></tr><tr><td>hp_weight_decay</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▂▂▄▅▅▇██</td></tr><tr><td>train/global_step</td><td>▁▂▂▄▅▅▇███</td></tr><tr><td>train/grad_norm</td><td>█▁▃▄▄</td></tr><tr><td>train/learning_rate</td><td>█▇▅▃▁</td></tr><tr><td>train/loss</td><td>█▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_eval_loss</td><td>7.73059</td></tr><tr><td>eval/loss</td><td>7.73059</td></tr><tr><td>eval/runtime</td><td>26.6618</td></tr><tr><td>eval/samples_per_second</td><td>34.656</td></tr><tr><td>eval/steps_per_second</td><td>2.175</td></tr><tr><td>final_train_loss</td><td>43.74228</td></tr><tr><td>hp_adam_beta1</td><td>0.93287</td></tr><tr><td>hp_adam_beta2</td><td>0.96748</td></tr><tr><td>hp_adam_epsilon</td><td>0.0</td></tr><tr><td>hp_batch_size</td><td>16</td></tr><tr><td>hp_gradient_accumulation_steps</td><td>4</td></tr><tr><td>hp_learning_rate</td><td>8e-05</td></tr><tr><td>hp_max_grad_norm</td><td>0.90702</td></tr><tr><td>hp_warmup_ratio</td><td>0.08253</td></tr><tr><td>hp_weight_decay</td><td>0.00599</td></tr><tr><td>total_flos</td><td>5.524194037248e+18</td></tr><tr><td>train/epoch</td><td>4.93506</td></tr><tr><td>train/global_step</td><td>285</td></tr><tr><td>train/grad_norm</td><td>144.87592</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>32.6535</td></tr><tr><td>train_loss</td><td>43.74228</td></tr><tr><td>train_runtime</td><td>538.3573</td></tr><tr><td>train_samples_per_second</td><td>34.327</td></tr><tr><td>train_steps_per_second</td><td>0.529</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_4</strong> at: <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction/runs/f3eor5c5' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction/runs/f3eor5c5</a><br/> View project at: <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241130_081654-f3eor5c5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 08:28:03,769] Trial 4 finished with value: 7.730585098266602 and parameters: {'learning_rate': 7.568292060167621e-05, 'batch_size': 16, 'gradient_accumulation_steps': 4, 'warmup_ratio': 0.08253303307632644, 'weight_decay': 0.0059890036722543005, 'max_grad_norm': 0.9070235476608439, 'adam_beta1': 0.9328737509151929, 'adam_beta2': 0.9674809130079859, 'adam_epsilon': 3.6464395589807156e-09}. Best is trial 4 with value: 7.730585098266602.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/arunasrivastava/ML/notebooks/wandb/run-20241130_082803-mubdycj3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction/runs/mubdycj3' target=\"_blank\">trial_5</a></strong> to <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction/runs/mubdycj3' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-buckeye-phoneme-prediction/runs/mubdycj3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading pretrained model and processor...\n",
      "INFO:__main__:Initial vocabulary size: 315\n",
      "INFO:__main__:Initial special tokens setup:\n",
      "INFO:__main__:<pad>: 0\n",
      "INFO:__main__:<s>: 1\n",
      "INFO:__main__:</s>: 2\n",
      "INFO:__main__:<unk>: 3\n",
      "INFO:__main__:\n",
      "Verifying special token IDs in new tokenizer:\n",
      "INFO:__main__:<pad>: expected=0, actual=0\n",
      "INFO:__main__:<s>: expected=1, actual=1\n",
      "INFO:__main__:</s>: expected=2, actual=2\n",
      "INFO:__main__:<unk>: expected=3, actual=3\n",
      "INFO:__main__:\n",
      "Final vocabulary size: 41\n",
      "INFO:__main__:\n",
      "Final vocabulary check:\n",
      "INFO:__main__:<pad>: 0\n",
      "INFO:__main__:<s>: 1\n",
      "INFO:__main__:</s>: 2\n",
      "INFO:__main__:<unk>: 3\n",
      "INFO:__main__:Splitting dataset into train and evaluation...\n",
      "Map (num_proc=4):   0%|          | 0/3696 [00:00<?, ? examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   3%|▎         | 106/3696 [00:06<02:54, 20.56 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   9%|▊         | 323/3696 [00:08<00:37, 89.69 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):  19%|█▉        | 720/3696 [00:11<00:21, 135.63 examples/s]/home/arunasrivastava/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4): 100%|█████████▉| 3693/3696 [00:32<00:00, 17.75 examples/s] "
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from transformers import TrainingArguments, EarlyStoppingCallback\n",
    "from functools import partial\n",
    "import wandb\n",
    "\n",
    "def objective(trial, train_df, timit_vocab, base_output_dir=\"./results\"):\n",
    "    \"\"\"\n",
    "    Optuna objective function for hyperparameter optimization\n",
    "    \"\"\"\n",
    "    # Generate a unique run name\n",
    "    run_name = f\"trial_{trial.number}\"\n",
    "    output_dir = f\"{base_output_dir}/{run_name}\"\n",
    "    \n",
    "    # Initialize wandb for this trial\n",
    "    wandb.init(\n",
    "        project=\"xlsr-buckeye-phoneme-prediction\",\n",
    "        name=run_name,\n",
    "        config={\"trial_number\": trial.number},\n",
    "        reinit=True\n",
    "    )\n",
    "    \n",
    "    # Sample hyperparameters\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-6, 1e-4, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [4, 8, 16])\n",
    "    grad_accum = trial.suggest_categorical(\"gradient_accumulation_steps\", [2, 4, 8])\n",
    "    warmup_ratio = trial.suggest_float(\"warmup_ratio\", 0.05, 0.15)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 0.001, 0.1, log=True)\n",
    "    max_grad_norm = trial.suggest_float(\"max_grad_norm\", 0.5, 2.0)\n",
    "    adam_beta1 = trial.suggest_float(\"adam_beta1\", 0.85, 0.95)\n",
    "    adam_beta2 = trial.suggest_float(\"adam_beta2\", 0.95, 0.999)\n",
    "    adam_epsilon = trial.suggest_float(\"adam_epsilon\", 1e-9, 1e-7, log=True)\n",
    "    \n",
    "    # Prepare model and data\n",
    "    model, processor = prepare_model_and_processor(timit_vocab)\n",
    "    train_dataset, eval_dataset = prepare_datasets(train_df, processor)\n",
    "    \n",
    "    # Enable gradient checkpointing for memory efficiency\n",
    "    model.gradient_checkpointing_enable()\n",
    "    \n",
    "    # Create training arguments with sampled hyperparameters\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        learning_rate=learning_rate,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        gradient_accumulation_steps=grad_accum,\n",
    "        max_grad_norm=max_grad_norm,\n",
    "        warmup_ratio=warmup_ratio,\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "        weight_decay=weight_decay,\n",
    "        num_train_epochs=5,  # Reduced epochs for faster search\n",
    "        logging_dir=f'{output_dir}/logs',\n",
    "        logging_steps=50,\n",
    "        save_steps=500,\n",
    "        eval_steps=100,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"eval_loss\",\n",
    "        greater_is_better=False,\n",
    "        save_safetensors=True,\n",
    "        save_strategy=\"steps\",\n",
    "        save_total_limit=1,  # Keep only best model\n",
    "        fp16=True,\n",
    "        fp16_full_eval=True,\n",
    "        dataloader_num_workers=4,\n",
    "        dataloader_pin_memory=True,\n",
    "        gradient_checkpointing=True,\n",
    "        adam_beta1=adam_beta1,\n",
    "        adam_beta2=adam_beta2,\n",
    "        adam_epsilon=adam_epsilon,\n",
    "    )\n",
    "    \n",
    "    # Create early stopping callback\n",
    "    early_stopping_callback = EarlyStoppingCallback(\n",
    "        early_stopping_patience=3,\n",
    "        early_stopping_threshold=0.01\n",
    "    )\n",
    "    \n",
    "    # Create trainer with early stopping\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        data_collator=DataCollatorCTCWithPadding(processor=processor, padding=\"longest\"),\n",
    "        callbacks=[early_stopping_callback]  # Add early stopping callback\n",
    "    )\n",
    "    \n",
    "    # Train and get best eval loss\n",
    "    try:\n",
    "        train_result = trainer.train()\n",
    "        eval_result = trainer.evaluate()\n",
    "        \n",
    "        # Report to wandb\n",
    "        wandb.log({\n",
    "            \"best_eval_loss\": eval_result[\"eval_loss\"],\n",
    "            \"final_train_loss\": train_result.training_loss,\n",
    "            **{f\"hp_{k}\": v for k, v in trial.params.items()}\n",
    "        })\n",
    "        \n",
    "        wandb.finish()\n",
    "        \n",
    "        return eval_result[\"eval_loss\"]\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Trial {trial.number} failed with error: {str(e)}\")\n",
    "        wandb.finish()\n",
    "        return float('inf')\n",
    "\n",
    "def run_hyperparameter_search(train_df, timit_vocab, n_trials=20):\n",
    "    \"\"\"\n",
    "    Run the hyperparameter search\n",
    "    \"\"\"\n",
    "    study = optuna.create_study(\n",
    "        direction=\"minimize\",\n",
    "        sampler=optuna.samplers.TPESampler(seed=42),\n",
    "        pruner=optuna.pruners.MedianPruner(\n",
    "            n_startup_trials=5,\n",
    "            n_warmup_steps=5,\n",
    "            interval_steps=1\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    study.optimize(\n",
    "        partial(objective, train_df=train_df, timit_vocab=timit_vocab),\n",
    "        n_trials=n_trials,\n",
    "        timeout=3600 * 12  # 12 hour timeout\n",
    "    )\n",
    "    \n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "    print(f\"  Value: {trial.value}\")\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(f\"    {key}: {value}\")\n",
    "    \n",
    "    return study\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    study = run_hyperparameter_search(train_df, timit_vocab)\n",
    "    \n",
    "    # Save study results\n",
    "    import joblib\n",
    "    joblib.dump(study, \"hyperparam_study.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
