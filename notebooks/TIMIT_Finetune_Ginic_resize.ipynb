{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import zipfile\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "# run as much as possible accelerated by apple silicon, fall back to cpu if not possible\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from scripts.audio import audio_file_to_array\n",
    "from scripts.ipa import timit2ipa\n",
    "from scripts.ipa import filter_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append('..')\n",
    "from scripts.eval_tests.panphon_model_eval import panphon_model_eval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set espeak library path for macOS\n",
    "if sys.platform == \"darwin\":\n",
    "    from phonemizer.backend.espeak.wrapper import EspeakWrapper\n",
    "\n",
    "    _ESPEAK_LIBRARY = \"/opt/homebrew/Cellar/espeak/1.48.04_1/lib/libespeak.1.1.48.dylib\"\n",
    "    EspeakWrapper.set_library(_ESPEAK_LIBRARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, AutoModelForCTC, AutoTokenizer, AutoFeatureExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PRE_TRAINED_ID = \"ginic/gender_split_70_female_4_wav2vec2-large-xlsr-53-buckeye-ipa\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "timit = zipfile.ZipFile('../.data/TIMIT.zip', 'r')\n",
    "timit_files = timit.namelist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_files = list(set(map(lambda x: x.split('.')[0], filter(lambda x: x.startswith('data/TRAIN'), timit_files))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "WAV_HEADER_SIZE = 44\n",
    "def zipped_wav_to_array(filename):\n",
    "    with timit.open(filename) as wav_file:\n",
    "        return np.frombuffer(wav_file.read(), dtype=np.int16)[WAV_HEADER_SIZE//2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up Dataset Vocab \n",
    "You will see that the initial vocab of most multilingual phoneme transcription models is quite big (300-400 phonemes) we will reduce this in the dataset to improve overall performance for English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio</th>\n",
       "      <th>ipa</th>\n",
       "      <th>phoneme_starts</th>\n",
       "      <th>phoneme_ends</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[25971, 30303, 29285, 26995, 28271, 11552, 131...</td>\n",
       "      <td>ɹiɾiŋinpɔɹlaɪtɪvʒuaɪstɹeɪn</td>\n",
       "      <td>[0, 3600, 4511, 5800, 6240, 7440, 8480, 9520, ...</td>\n",
       "      <td>[3600, 4511, 5800, 6240, 7440, 8480, 9520, 101...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[25971, 30303, 29285, 26995, 28271, 11552, 131...</td>\n",
       "      <td>ɑbfaʊnmɔɹklæmzitðioʊʃnzʔɛddʒ</td>\n",
       "      <td>[0, 2148, 2667, 5085, 6558, 8000, 10960, 11947...</td>\n",
       "      <td>[2148, 2667, 5085, 6558, 8000, 10960, 11947, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[25971, 30303, 29285, 26995, 28271, 11552, 131...</td>\n",
       "      <td>oʊntæskmiɾikɹinʔɔɪliɹæɡlaɪkðæt</td>\n",
       "      <td>[0, 2180, 2400, 4240, 4707, 5600, 7610, 8740, ...</td>\n",
       "      <td>[2180, 2400, 4240, 4707, 5600, 7610, 8740, 956...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[25971, 30303, 29285, 26995, 28271, 11552, 131...</td>\n",
       "      <td>jukʊdɹndaʊnðəshoʊlmaʊntnsaɪdwəðəfaɪɹðætsaɪz</td>\n",
       "      <td>[0, 2157, 2607, 3509, 4120, 4469, 5800, 7160, ...</td>\n",
       "      <td>[2157, 2607, 3509, 4120, 4469, 5800, 7160, 764...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[25971, 30303, 29285, 26995, 28271, 11552, 131...</td>\n",
       "      <td>jʌŋpiplpɑɹtɪsəpeɪtʔɪnʔæθlɛɾikʔæktɪviɾiz</td>\n",
       "      <td>[0, 2605, 4113, 5597, 6597, 7268, 8020, 9000, ...</td>\n",
       "      <td>[2605, 4113, 5597, 6597, 7268, 8020, 9000, 100...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               audio  \\\n",
       "0  [25971, 30303, 29285, 26995, 28271, 11552, 131...   \n",
       "1  [25971, 30303, 29285, 26995, 28271, 11552, 131...   \n",
       "2  [25971, 30303, 29285, 26995, 28271, 11552, 131...   \n",
       "3  [25971, 30303, 29285, 26995, 28271, 11552, 131...   \n",
       "4  [25971, 30303, 29285, 26995, 28271, 11552, 131...   \n",
       "\n",
       "                                           ipa  \\\n",
       "0                   ɹiɾiŋinpɔɹlaɪtɪvʒuaɪstɹeɪn   \n",
       "1                 ɑbfaʊnmɔɹklæmzitðioʊʃnzʔɛddʒ   \n",
       "2               oʊntæskmiɾikɹinʔɔɪliɹæɡlaɪkðæt   \n",
       "3  jukʊdɹndaʊnðəshoʊlmaʊntnsaɪdwəðəfaɪɹðætsaɪz   \n",
       "4      jʌŋpiplpɑɹtɪsəpeɪtʔɪnʔæθlɛɾikʔæktɪviɾiz   \n",
       "\n",
       "                                      phoneme_starts  \\\n",
       "0  [0, 3600, 4511, 5800, 6240, 7440, 8480, 9520, ...   \n",
       "1  [0, 2148, 2667, 5085, 6558, 8000, 10960, 11947...   \n",
       "2  [0, 2180, 2400, 4240, 4707, 5600, 7610, 8740, ...   \n",
       "3  [0, 2157, 2607, 3509, 4120, 4469, 5800, 7160, ...   \n",
       "4  [0, 2605, 4113, 5597, 6597, 7268, 8020, 9000, ...   \n",
       "\n",
       "                                        phoneme_ends  \n",
       "0  [3600, 4511, 5800, 6240, 7440, 8480, 9520, 101...  \n",
       "1  [2148, 2667, 5085, 6558, 8000, 10960, 11947, 1...  \n",
       "2  [2180, 2400, 4240, 4707, 5600, 7610, 8740, 956...  \n",
       "3  [2157, 2607, 3509, 4120, 4469, 5800, 7160, 764...  \n",
       "4  [2605, 4113, 5597, 6597, 7268, 8020, 9000, 100...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, ensure that the simplify_timit function is available and works\n",
    "def simplify_timit(phoneme):\n",
    "    # Substitute the phoneme based on the dictionary\n",
    "    substitution_dict = {\n",
    "        'ɾ̃': 'ɾ',  # Replace nasalized flap with plain flap\n",
    "        'ŋ̍': 'ŋ',  # Remove syllabic marker from 'ŋ̍'\n",
    "        'ə̥': 'ə',  # Remove voiceless marker from 'ə̥'\n",
    "        'ɝ': 'ɹ',   # Simplify rhotacized schwa to 'ɹ'\n",
    "        'ɚ': 'ɹ',   # Simplify rhotacized schwa to 'ɹ'\n",
    "        'l̩': 'l',   # Remove syllabic marker from 'l̩'\n",
    "        'm̩': 'm',   # Remove syllabic marker from 'm̩'\n",
    "        'n̩': 'n',   # Remove syllabic marker from 'n̩'\n",
    "        '̩': '',     # Remove syllabic marker\n",
    "        'ʉ': 'u',    # Replace high central rounded vowel with high back rounded vowel\n",
    "        'ɨ': 'i',    # Replace high central unrounded vowel with high front unrounded vowel\n",
    "        ' ': '',     # Remove nasalization marker\n",
    "        'ɦ': 'h',    # Replace voiceless glottal fricative with voiceless glottal fricative\n",
    "        # Add other necessary substitutions if needed\n",
    "    }\n",
    "    # Apply the substitution for the phoneme\n",
    "    return substitution_dict.get(phoneme, phoneme)  # Return simplified phoneme or the original if no replacement\n",
    "\n",
    "def remove_stress_mark(text):\n",
    "    \"\"\"\n",
    "    Removes the combining double inverted breve (͡) from text.\n",
    "    \n",
    "    Args:\n",
    "        text: String or iterable containing IPA symbols\n",
    "        \n",
    "    Returns:\n",
    "        Text with stress marks removed\n",
    "    \"\"\"\n",
    "    if isinstance(text, str):\n",
    "        return text.replace('͡', '')\n",
    "    else:\n",
    "        raise TypeError(\"Input must be string, set, or list\")\n",
    "    \n",
    "# Updated timit_file_to_dict to use the simplified IPA phonemes\n",
    "def timit_file_to_dict(filename):\n",
    "    with timit.open(filename + '.PHN') as phn_file:\n",
    "        timestamped_phonemes = []\n",
    "        for line in phn_file.read().decode('utf-8').split('\\n'):\n",
    "            if line == '':\n",
    "                continue\n",
    "            start, end, phoneme = line.split()\n",
    "            \n",
    "            # Convert to IPA first and then simplify the phoneme\n",
    "            ipa_phonemes = timit2ipa(phoneme, \"eng\")\n",
    "            \n",
    "            # Now filter only the necessary characters (this simplifies the phoneme to the basic form)\n",
    "            cleaned_ipa = filter_chars(simplify_timit(ipa_phonemes), filter_type=\"letters\")\n",
    "            cleaned_ipa = remove_stress_mark(cleaned_ipa)\n",
    "            timestamped_phonemes.append((cleaned_ipa, int(start), int(end)))\n",
    "\n",
    "    return {'timestamped_phonemes': timestamped_phonemes, 'wav_filename': filename + '.WAV'}\n",
    "\n",
    "# Updated files_to_df to create DataFrame with cleaned-up phonemes\n",
    "def files_to_df(files):\n",
    "    records = []\n",
    "    for filename in files:\n",
    "        parsed = timit_file_to_dict(filename)\n",
    "        parsed['audio'] = zipped_wav_to_array(parsed['wav_filename'])\n",
    "        del parsed['wav_filename']\n",
    "        parsed['ipa'] = \"\".join(phoneme for phoneme, _, _ in parsed['timestamped_phonemes'])\n",
    "        parsed['phoneme_starts'] = [start for _, start, _ in parsed['timestamped_phonemes']]\n",
    "        parsed['phoneme_ends'] = [end for _, _, end in parsed['timestamped_phonemes']]\n",
    "        del parsed['timestamped_phonemes']\n",
    "        records.append(parsed)\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "# Call files_to_df for your test files\n",
    "train_df = files_to_df(training_files)\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Up Audio\n",
    "We will just crop out the start signal :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_audio(row):\n",
    "    # Access the phoneme_starts column and get the last value of the list\n",
    "    end = row['phoneme_starts'][-1]\n",
    "    # Access the phoneme_ends column and get the first value of the list\n",
    "    start = row['phoneme_ends'][0]\n",
    "    # Crop the audio from start to end\n",
    "    # note that start and end are in samples, not seconds\n",
    "    cropped_audio = row['audio'][start:end]\n",
    "    \n",
    "    return cropped_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# graph one audio to see start signal that we will remove\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_df['audio'][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio</th>\n",
       "      <th>ipa</th>\n",
       "      <th>phoneme_starts</th>\n",
       "      <th>phoneme_ends</th>\n",
       "      <th>cropped_audio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[25971, 30303, 29285, 26995, 28271, 11552, 131...</td>\n",
       "      <td>ɹiɾiŋinpɔɹlaɪtɪvʒuaɪstɹeɪn</td>\n",
       "      <td>[0, 3600, 4511, 5800, 6240, 7440, 8480, 9520, ...</td>\n",
       "      <td>[3600, 4511, 5800, 6240, 7440, 8480, 9520, 101...</td>\n",
       "      <td>[-3, -16, -33, -48, -57, -63, -66, -67, -63, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[25971, 30303, 29285, 26995, 28271, 11552, 131...</td>\n",
       "      <td>ɑbfaʊnmɔɹklæmzitðioʊʃnzʔɛddʒ</td>\n",
       "      <td>[0, 2148, 2667, 5085, 6558, 8000, 10960, 11947...</td>\n",
       "      <td>[2148, 2667, 5085, 6558, 8000, 10960, 11947, 1...</td>\n",
       "      <td>[2, -1, 1, -4, 2, 1, 2, 3, 3, 1, 2, 3, 0, 10, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[25971, 30303, 29285, 26995, 28271, 11552, 131...</td>\n",
       "      <td>oʊntæskmiɾikɹinʔɔɪliɹæɡlaɪkðæt</td>\n",
       "      <td>[0, 2180, 2400, 4240, 4707, 5600, 7610, 8740, ...</td>\n",
       "      <td>[2180, 2400, 4240, 4707, 5600, 7610, 8740, 956...</td>\n",
       "      <td>[3, 0, 3, 3, 3, 4, 3, 4, 3, 4, 2, 3, 1, 2, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[25971, 30303, 29285, 26995, 28271, 11552, 131...</td>\n",
       "      <td>jukʊdɹndaʊnðəshoʊlmaʊntnsaɪdwəðəfaɪɹðætsaɪz</td>\n",
       "      <td>[0, 2157, 2607, 3509, 4120, 4469, 5800, 7160, ...</td>\n",
       "      <td>[2157, 2607, 3509, 4120, 4469, 5800, 7160, 764...</td>\n",
       "      <td>[-1, -8, -4, 2, 11, 4, 2, 3, 2, 6, 8, 2, 2, -3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[25971, 30303, 29285, 26995, 28271, 11552, 131...</td>\n",
       "      <td>jʌŋpiplpɑɹtɪsəpeɪtʔɪnʔæθlɛɾikʔæktɪviɾiz</td>\n",
       "      <td>[0, 2605, 4113, 5597, 6597, 7268, 8020, 9000, ...</td>\n",
       "      <td>[2605, 4113, 5597, 6597, 7268, 8020, 9000, 100...</td>\n",
       "      <td>[4, 4, 4, 3, 1, 5, 4, 3, -1, 0, 0, -1, 0, -1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               audio  \\\n",
       "0  [25971, 30303, 29285, 26995, 28271, 11552, 131...   \n",
       "1  [25971, 30303, 29285, 26995, 28271, 11552, 131...   \n",
       "2  [25971, 30303, 29285, 26995, 28271, 11552, 131...   \n",
       "3  [25971, 30303, 29285, 26995, 28271, 11552, 131...   \n",
       "4  [25971, 30303, 29285, 26995, 28271, 11552, 131...   \n",
       "\n",
       "                                           ipa  \\\n",
       "0                   ɹiɾiŋinpɔɹlaɪtɪvʒuaɪstɹeɪn   \n",
       "1                 ɑbfaʊnmɔɹklæmzitðioʊʃnzʔɛddʒ   \n",
       "2               oʊntæskmiɾikɹinʔɔɪliɹæɡlaɪkðæt   \n",
       "3  jukʊdɹndaʊnðəshoʊlmaʊntnsaɪdwəðəfaɪɹðætsaɪz   \n",
       "4      jʌŋpiplpɑɹtɪsəpeɪtʔɪnʔæθlɛɾikʔæktɪviɾiz   \n",
       "\n",
       "                                      phoneme_starts  \\\n",
       "0  [0, 3600, 4511, 5800, 6240, 7440, 8480, 9520, ...   \n",
       "1  [0, 2148, 2667, 5085, 6558, 8000, 10960, 11947...   \n",
       "2  [0, 2180, 2400, 4240, 4707, 5600, 7610, 8740, ...   \n",
       "3  [0, 2157, 2607, 3509, 4120, 4469, 5800, 7160, ...   \n",
       "4  [0, 2605, 4113, 5597, 6597, 7268, 8020, 9000, ...   \n",
       "\n",
       "                                        phoneme_ends  \\\n",
       "0  [3600, 4511, 5800, 6240, 7440, 8480, 9520, 101...   \n",
       "1  [2148, 2667, 5085, 6558, 8000, 10960, 11947, 1...   \n",
       "2  [2180, 2400, 4240, 4707, 5600, 7610, 8740, 956...   \n",
       "3  [2157, 2607, 3509, 4120, 4469, 5800, 7160, 764...   \n",
       "4  [2605, 4113, 5597, 6597, 7268, 8020, 9000, 100...   \n",
       "\n",
       "                                       cropped_audio  \n",
       "0  [-3, -16, -33, -48, -57, -63, -66, -67, -63, -...  \n",
       "1  [2, -1, 1, -4, 2, 1, 2, 3, 3, 1, 2, 3, 0, 10, ...  \n",
       "2  [3, 0, 3, 3, 3, 4, 3, 4, 3, 4, 2, 3, 1, 2, 3, ...  \n",
       "3  [-1, -8, -4, 2, 11, 4, 2, 3, 2, 6, 8, 2, 2, -3...  \n",
       "4  [4, 4, 4, 3, 1, 5, 4, 3, -1, 0, 0, -1, 0, -1, ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the process_row function to each row in the DataFrame\n",
    "train_df['cropped_audio'] = train_df.apply(crop_audio, axis=1) \n",
    "train_df.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f5653a2a190>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize again, much better!\n",
    "plt.plot(train_df['cropped_audio'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ipa</th>\n",
       "      <th>audio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ɹiɾiŋinpɔɹlaɪtɪvʒuaɪstɹeɪn</td>\n",
       "      <td>[-3, -16, -33, -48, -57, -63, -66, -67, -63, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ɑbfaʊnmɔɹklæmzitðioʊʃnzʔɛddʒ</td>\n",
       "      <td>[2, -1, 1, -4, 2, 1, 2, 3, 3, 1, 2, 3, 0, 10, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oʊntæskmiɾikɹinʔɔɪliɹæɡlaɪkðæt</td>\n",
       "      <td>[3, 0, 3, 3, 3, 4, 3, 4, 3, 4, 2, 3, 1, 2, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jukʊdɹndaʊnðəshoʊlmaʊntnsaɪdwəðəfaɪɹðætsaɪz</td>\n",
       "      <td>[-1, -8, -4, 2, 11, 4, 2, 3, 2, 6, 8, 2, 2, -3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jʌŋpiplpɑɹtɪsəpeɪtʔɪnʔæθlɛɾikʔæktɪviɾiz</td>\n",
       "      <td>[4, 4, 4, 3, 1, 5, 4, 3, -1, 0, 0, -1, 0, -1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           ipa  \\\n",
       "0                   ɹiɾiŋinpɔɹlaɪtɪvʒuaɪstɹeɪn   \n",
       "1                 ɑbfaʊnmɔɹklæmzitðioʊʃnzʔɛddʒ   \n",
       "2               oʊntæskmiɾikɹinʔɔɪliɹæɡlaɪkðæt   \n",
       "3  jukʊdɹndaʊnðəshoʊlmaʊntnsaɪdwəðəfaɪɹðætsaɪz   \n",
       "4      jʌŋpiplpɑɹtɪsəpeɪtʔɪnʔæθlɛɾikʔæktɪviɾiz   \n",
       "\n",
       "                                               audio  \n",
       "0  [-3, -16, -33, -48, -57, -63, -66, -67, -63, -...  \n",
       "1  [2, -1, 1, -4, 2, 1, 2, 3, 3, 1, 2, 3, 0, 10, ...  \n",
       "2  [3, 0, 3, 3, 3, 4, 3, 4, 3, 4, 2, 3, 1, 2, 3, ...  \n",
       "3  [-1, -8, -4, 2, 11, 4, 2, 3, 2, 6, 8, 2, 2, -3...  \n",
       "4  [4, 4, 4, 3, 1, 5, 4, 3, -1, 0, 0, -1, 0, -1, ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_df comprised of just cropped_audio and phonemes\n",
    "train_df = train_df.drop(columns=['phoneme_starts', 'phoneme_ends', 'audio'])\n",
    "# rename cropped audio to audio\n",
    "train_df = train_df.rename(columns={'cropped_audio': 'audio'})\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset.from_pandas(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extend Phoneme Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'k', 'o', 'h', 'ŋ', 'p', 'ɡ', 'm', 'v', 'f', 'ʌ', 'e', 'ɛ', 'u', 'a', 'ɹ', 'n', 'ɑ', 'ð', 'ə', 't', 'z', 'ʒ', 'ʊ', 'ɔ', 'b', 's', 'w', 'd', 'æ', 'θ', 'ɾ', 'ʔ', 'ɪ', 'l', 'j', 'i', 'ʃ'}\n"
     ]
    }
   ],
   "source": [
    "timit_vocab = set(\"\".join(train_df['ipa']))\n",
    "print(timit_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 267, 'E': 45, 'H': 72, 'I': 20, 'O': 305, 'U': 292, '[PAD]': 310, '[UNK]': 309, '_': 182, 'a': 53, 'ã': 125, 'b': 113, 'b̪': 177, 'b̪͡v': 289, 'b͡ꞵ': 287, 'c': 25, 'cʼ': 229, 'c͡ç': 66, 'd': 176, 'd̼': 118, 'd͡z': 263, 'd͡ð': 244, 'd͡ɮ': 18, 'd͡ʑ': 94, 'd͡ʒ': 280, 'e': 175, 'ẽ': 211, 'e̞': 114, 'ẽ̞': 265, 'f': 139, 'fʼ': 249, 'h': 179, 'i': 245, 'j': 215, 'k': 282, 'kxʼ': 281, 'kǀ': 41, 'kǁ': 61, 'kǂ': 21, 'kǃ': 70, 'kʘ': 79, 'kʼ': 39, 'k̚': 89, 'k͡p': 48, 'k͡x': 198, 'l': 303, 'm': 75, 'm̥': 172, 'n': 102, 'n̥': 28, 'n̼': 169, 'o': 117, 'õ': 119, 'o̞': 62, 'õ̞': 234, 'p': 259, 'pʼ': 286, 'p̚': 149, 'p̪': 273, 'p̪͡f': 105, 'p͡f': 225, 'p͡ɸ': 103, 'q': 130, 'qǀ': 302, 'qǁ': 126, 'qǂ': 299, 'qǃ': 37, 'qʘ': 261, 'qʼ': 58, 'q͡ʡ': 127, 'q͡χʼ': 291, 'q͡ꭓ': 4, 'r': 82, 'r̥': 34, 's': 247, 'sʼ': 200, 't': 307, 'tʼ': 183, 't̚': 241, 't̪͡θʼ': 216, 't̼': 87, 't͡s': 156, 't͡sʼ': 43, 't͡ɕ': 264, 't͡ɬ': 170, 't͡ɬʼ': 164, 't͡ʃ': 91, 't͡ʃʼ': 108, 't͡θ': 140, 'u': 154, 'ũ': 81, 'v': 243, 'w': 143, 'x': 133, 'xʼ': 129, 'y': 214, 'ỹ': 277, 'z': 271, '{': 251, '}': 74, 'ã': 99, 'ä': 165, 'ä̃': 115, 'æ': 191, 'æ̃': 217, 'ç': 71, 'ð': 69, 'ð̠': 192, 'ð̼': 9, 'õ': 157, 'ø': 47, 'ø̃': 46, 'ø̞': 112, 'ø̞̃': 12, 'ħ': 224, 'ĩ': 180, 'ŋ': 213, 'ŋǀ': 231, 'ŋǁ': 304, 'ŋǂ': 301, 'ŋǃ': 284, 'ŋʘ': 168, 'ŋ̊': 27, 'ŋ͡m': 296, 'œ': 29, 'œ̃': 153, 'ũ': 31, 'ɐ': 142, 'ɐ̃': 7, 'ɑ': 49, 'ɑ̃': 50, 'ɒ': 116, 'ɒ̃': 85, 'ɓ': 178, 'ɓ̥': 13, 'ɔ': 228, 'ɔ̃': 186, 'ɕ': 220, 'ɕʼ': 36, 'ɖ': 256, 'ɖ͡ʐ': 77, 'ɗ': 93, 'ɗ̥': 270, 'ɘ': 104, 'ɘ̃': 189, 'ə': 6, 'ə̃': 294, 'ɚ': 184, 'ɛ': 293, 'ɛ̃': 98, 'ɜ': 92, 'ɜ̃': 73, 'ɝ': 196, 'ɞ': 210, 'ɞ̃': 54, 'ɟ': 68, 'ɟ͡ʝ': 86, 'ɠ': 160, 'ɠ̊': 1, 'ɡ': 252, 'ɡǀ': 19, 'ɡǁ': 226, 'ɡǂ': 131, 'ɡǃ': 152, 'ɡʘ': 162, 'ɡ̆': 201, 'ɡ͡b': 185, 'ɡ͡ɣ': 78, 'ɢ': 195, 'ɢǀ': 88, 'ɢǁ': 258, 'ɢǂ': 64, 'ɢǃ': 308, 'ɢʘ': 107, 'ɢ̆': 123, 'ɢ͡ʁ': 111, 'ɣ': 219, 'ɤ': 194, 'ɤ̃': 17, 'ɤ̞': 187, 'ɤ̞̃': 60, 'ɥ': 24, 'ɥ̊': 135, 'ɧ': 246, 'ɨ': 40, 'ɨ̃': 109, 'ɪ': 8, 'ɪ̃': 97, 'ɬ': 121, 'ɬʼ': 3, 'ɭ': 290, 'ɭ˔': 279, 'ɭ̆': 236, 'ɭ̥̆': 240, 'ɮ': 266, 'ɯ': 275, 'ɯ̃': 300, 'ɰ': 208, 'ɱ': 295, 'ɲ': 128, 'ɲ̊': 197, 'ɳ': 63, 'ɳ̊': 144, 'ɴ': 136, 'ɴǀ': 101, 'ɴǁ': 14, 'ɴǂ': 238, 'ɴǃ': 147, 'ɴʘ': 221, 'ɵ': 95, 'ɵ̃': 51, 'ɶ': 145, 'ɶ̃': 146, 'ɸ': 166, 'ɸʼ': 306, 'ɹ': 223, 'ɹ̠˔': 202, 'ɹ̠̊˔': 173, 'ɺ': 76, 'ɺ̥': 181, 'ɻ': 163, 'ɻ˔': 30, 'ɻ̊˔': 42, 'ɽ': 254, 'ɽ̊': 218, 'ɾ': 232, 'ɾ̥': 120, 'ɾ̼': 32, 'ʀ': 52, 'ʀ̥': 148, 'ʁ': 239, 'ʂ': 242, 'ʂʼ': 110, 'ʃ': 253, 'ʃʼ': 230, 'ʄ': 132, 'ʄ̊': 155, 'ʈ': 199, 'ʈʼ': 44, 'ʈ͡ʂ': 190, 'ʈ͡ʂʼ': 67, 'ʉ': 80, 'ʉ̃': 250, 'ʊ': 83, 'ʊ̃': 205, 'ʋ': 106, 'ʌ': 272, 'ʌ̃': 158, 'ʍ': 141, 'ʎ': 276, 'ʎ̆': 84, 'ʎ̝': 262, 'ʎ̝̊': 59, 'ʏ': 23, 'ʏ̃': 237, 'ʐ': 209, 'ʑ': 137, 'ʒ': 171, 'ʔ': 10, 'ʔ̞': 257, 'ʔ͡h': 203, 'ʕ': 38, 'ʙ': 274, 'ʙ̥': 167, 'ʛ': 233, 'ʛ̥': 159, 'ʜ': 298, 'ʝ': 35, 'ʟ': 150, 'ʟ̆': 248, 'ʟ̝': 33, 'ʟ̝̊': 161, 'ʟ̠': 285, 'ʡ': 174, 'ʡʼ': 5, 'ʡ̆': 22, 'ʡ͡ʜ': 56, 'ʡ͡ʢ': 255, 'ʢ': 188, 'ʰ': 206, 'ʲ': 0, 'ʷ': 288, 'ː': 235, '˞': 90, 'ˠ': 122, 'ˡ': 16, 'ˣ': 96, 'ˤ': 15, '̃': 57, '̩': 204, 'β': 269, 'θ': 283, 'θʼ': 26, 'θ̠': 100, 'θ̼': 227, 'χ': 65, 'χʼ': 260, 'ᵐ': 124, 'ᵑ': 297, 'ᶑ': 212, 'ᶑ̊': 268, 'ᶬ': 151, 'ᶮ': 55, 'ᶯ': 207, 'ᶰ': 11, 'ᶿ': 138, 'ẽ': 2, 'ⁿ': 222, 'ⱱ': 134, 'ⱱ̟': 193, 'ꞎ': 278, '<s>': 311, '</s>': 312}\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(PRE_TRAINED_ID)\n",
    "vocab = tokenizer.get_vocab()\n",
    "# you will see how large the vocab is, we will resize our linear layer later to make it work for our smaller vocab\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens that are in timit but not in the pretrained model set()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "additional_vocab = timit_vocab.difference(set(vocab.keys()) | {' '})\n",
    "print(\"tokens that are in timit but not in the pretrained model\", additional_vocab)\n",
    "tokenizer.add_tokens(list(additional_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = AutoFeatureExtractor.from_pretrained(PRE_TRAINED_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't need to update the feature extractor since it has been pretrained on 16kHz audio which matches the TIMIT dataset.\n",
    "\n",
    "For datasets with different sampling rates, the feature extractor should be updated or the audio resampled (easier).\n",
    "\n",
    "This is also where code to add extra features (such as conditioning on speaker's native language etc.) would be added."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hyperparam search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchaudio in /home/arunasri/ML/venv/lib/python3.8/site-packages (2.4.1)\n",
      "Requirement already satisfied: torch==2.4.1 in /home/arunasri/ML/venv/lib/python3.8/site-packages (from torchaudio) (2.4.1)\n",
      "Requirement already satisfied: filelock in /home/arunasri/ML/venv/lib/python3.8/site-packages (from torch==2.4.1->torchaudio) (3.13.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/arunasri/ML/venv/lib/python3.8/site-packages (from torch==2.4.1->torchaudio) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/arunasri/ML/venv/lib/python3.8/site-packages (from torch==2.4.1->torchaudio) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/arunasri/ML/venv/lib/python3.8/site-packages (from torch==2.4.1->torchaudio) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/arunasri/ML/venv/lib/python3.8/site-packages (from torch==2.4.1->torchaudio) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/arunasri/ML/venv/lib/python3.8/site-packages (from torch==2.4.1->torchaudio) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/arunasri/ML/venv/lib/python3.8/site-packages (from torch==2.4.1->torchaudio) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/arunasri/ML/venv/lib/python3.8/site-packages (from torch==2.4.1->torchaudio) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/arunasri/ML/venv/lib/python3.8/site-packages (from torch==2.4.1->torchaudio) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/arunasri/ML/venv/lib/python3.8/site-packages (from torch==2.4.1->torchaudio) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/arunasri/ML/venv/lib/python3.8/site-packages (from torch==2.4.1->torchaudio) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/arunasri/ML/venv/lib/python3.8/site-packages (from torch==2.4.1->torchaudio) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/arunasri/ML/venv/lib/python3.8/site-packages (from torch==2.4.1->torchaudio) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/arunasri/ML/venv/lib/python3.8/site-packages (from torch==2.4.1->torchaudio) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/arunasri/ML/venv/lib/python3.8/site-packages (from torch==2.4.1->torchaudio) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/arunasri/ML/venv/lib/python3.8/site-packages (from torch==2.4.1->torchaudio) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/arunasri/ML/venv/lib/python3.8/site-packages (from torch==2.4.1->torchaudio) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/arunasri/ML/venv/lib/python3.8/site-packages (from torch==2.4.1->torchaudio) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/arunasri/ML/venv/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.1->torchaudio) (12.6.85)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/arunasri/ML/venv/lib/python3.8/site-packages (from jinja2->torch==2.4.1->torchaudio) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/arunasri/ML/venv/lib/python3.8/site-packages (from sympy->torch==2.4.1->torchaudio) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V2 resize finetuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:e67l6duv) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁</td></tr><tr><td>train/global_step</td><td>▁</td></tr><tr><td>train/grad_norm</td><td>▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>0.10823</td></tr><tr><td>train/global_step</td><td>50</td></tr><tr><td>train/grad_norm</td><td>6.65324</td></tr><tr><td>train/learning_rate</td><td>2e-05</td></tr><tr><td>train/loss</td><td>2.7134</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">finetuning_optimal_params</strong> at: <a href='https://wandb.ai/aruna-team/xlsr-phoneme-finetuning-final/runs/e67l6duv' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-phoneme-finetuning-final/runs/e67l6duv</a><br/> View project at: <a href='https://wandb.ai/aruna-team/xlsr-phoneme-finetuning-final' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-phoneme-finetuning-final</a><br/>Synced 4 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250123_061312-e67l6duv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:e67l6duv). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/arunasri/ML/notebooks/wandb/run-20250123_061518-srwee015</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aruna-team/xlsr-phoneme-finetuning-final/runs/srwee015' target=\"_blank\">finetuning_optimal_params</a></strong> to <a href='https://wandb.ai/aruna-team/xlsr-phoneme-finetuning-final' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aruna-team/xlsr-phoneme-finetuning-final' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-phoneme-finetuning-final</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aruna-team/xlsr-phoneme-finetuning-final/runs/srwee015' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-phoneme-finetuning-final/runs/srwee015</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Step model_init_start completed after 0.08s\n",
      "INFO:__main__:Loading pretrained model and processor...\n",
      "INFO:__main__:Initial vocabulary size: 313\n",
      "INFO:__main__:New vocabulary size: 41\n",
      "INFO:__main__:Transferred weights for 41 tokens\n",
      "INFO:__main__:Step model_init_complete completed after 1.43s\n",
      "INFO:__main__:Step dataset_prep_start completed after 1.52s\n",
      "INFO:__main__:Splitting dataset into train and evaluation...\n",
      "Map (num_proc=4):   0%|          | 0/3696 [00:00<?, ? examples/s]/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   2%|▏         | 77/3696 [00:04<01:46, 33.87 examples/s] /home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   8%|▊         | 279/3696 [00:06<00:34, 97.74 examples/s]/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):  17%|█▋        | 641/3696 [00:09<00:20, 145.66 examples/s]/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4): 100%|██████████| 3696/3696 [01:03<00:00, 58.04 examples/s] \n",
      "Map (num_proc=4):   0%|          | 0/924 [00:00<?, ? examples/s]/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   3%|▎         | 27/924 [00:01<00:29, 30.05 examples/s]/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):   9%|▉         | 86/924 [00:02<00:09, 84.46 examples/s]/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4):  19%|█▉        | 177/924 [00:02<00:05, 128.39 examples/s]/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map (num_proc=4): 100%|██████████| 924/924 [00:16<00:00, 56.74 examples/s] \n",
      "INFO:__main__:Step dataset_prep_complete completed after 83.70s\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "INFO:__main__:Step training_start completed after 84.43s\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2700' max='9240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2700/9240 26:39 < 1:04:38, 1.69 it/s, Epoch 5/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.569100</td>\n",
       "      <td>1.026895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.741500</td>\n",
       "      <td>0.663627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.357500</td>\n",
       "      <td>0.535806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.200100</td>\n",
       "      <td>0.478389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.065200</td>\n",
       "      <td>0.443260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.011700</td>\n",
       "      <td>0.424576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.996900</td>\n",
       "      <td>0.381558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.904400</td>\n",
       "      <td>0.385093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.855800</td>\n",
       "      <td>0.365180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.854800</td>\n",
       "      <td>0.358211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.784700</td>\n",
       "      <td>0.347438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.746900</td>\n",
       "      <td>0.345812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.736500</td>\n",
       "      <td>0.359272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.701000</td>\n",
       "      <td>0.332489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.673600</td>\n",
       "      <td>0.341796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.620700</td>\n",
       "      <td>0.330050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.616500</td>\n",
       "      <td>0.322900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.657700</td>\n",
       "      <td>0.326625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.531000</td>\n",
       "      <td>0.335419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.543000</td>\n",
       "      <td>0.337309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.521300</td>\n",
       "      <td>0.330066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.551900</td>\n",
       "      <td>0.309476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.568600</td>\n",
       "      <td>0.325244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.484200</td>\n",
       "      <td>0.330299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.463800</td>\n",
       "      <td>0.329950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.493200</td>\n",
       "      <td>0.317444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.449900</td>\n",
       "      <td>0.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "INFO:__main__:Step training_complete completed after 1690.13s\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/arunasri/ML/venv/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='231' max='231' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [231/231 00:13]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Step evaluation_complete completed after 1708.74s\n",
      "INFO:__main__:Saving final model and processor...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▃▁▂▁█▃▂▄▃▁▁▂▂▂▅▃▁▃▂▂▃▃▃▃▄▃▂▃</td></tr><tr><td>eval/samples_per_second</td><td>▆▇▇█▁▆▇▅▆██▇▇▇▄▆█▆▇▇▅▆▆▆▅▆▇▆</td></tr><tr><td>eval/steps_per_second</td><td>▆▇▇█▁▆▇▅▆██▇▇▇▄▆█▆▇▇▅▆▆▆▅▆▇▆</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>train/grad_norm</td><td>▂▂█▃▄▂▃▂▂▂▂▂▃▃▁▂▂▁▂▂▂▁▁▁▃▁▁▁▂▂▂▂▂▁▁▁▁▂▁▁</td></tr><tr><td>train/learning_rate</td><td>▁▁▂▂▃▃▄▄▅▅▆▆▇▇▇████████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆</td></tr><tr><td>train/loss</td><td>█▇▆▅▄▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.30948</td></tr><tr><td>eval/runtime</td><td>18.4757</td></tr><tr><td>eval/samples_per_second</td><td>50.012</td></tr><tr><td>eval/steps_per_second</td><td>12.503</td></tr><tr><td>total_flos</td><td>6.54180872832e+18</td></tr><tr><td>train/epoch</td><td>5.84416</td></tr><tr><td>train/global_step</td><td>2700</td></tr><tr><td>train/grad_norm</td><td>2.29808</td></tr><tr><td>train/learning_rate</td><td>8e-05</td></tr><tr><td>train/loss</td><td>0.4499</td></tr><tr><td>train_loss</td><td>0.86214</td></tr><tr><td>train_runtime</td><td>1605.0532</td></tr><tr><td>train_samples_per_second</td><td>46.055</td></tr><tr><td>train_steps_per_second</td><td>5.757</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">finetuning_optimal_params</strong> at: <a href='https://wandb.ai/aruna-team/xlsr-phoneme-finetuning-final/runs/srwee015' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-phoneme-finetuning-final/runs/srwee015</a><br/> View project at: <a href='https://wandb.ai/aruna-team/xlsr-phoneme-finetuning-final' target=\"_blank\">https://wandb.ai/aruna-team/xlsr-phoneme-finetuning-final</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250123_061518-srwee015/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import logging\n",
    "import tempfile\n",
    "import wandb\n",
    "import numpy as np\n",
    "from transformers import (\n",
    "    AutoProcessor, \n",
    "    AutoModelForCTC, \n",
    "    Trainer, \n",
    "    TrainingArguments,\n",
    "    Wav2Vec2CTCTokenizer,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from datasets import Dataset\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Union\n",
    "import torchaudio\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "import GPUtil\n",
    "import psutil\n",
    "\n",
    "# Constants and logging setup as before\n",
    "SAMPLING_RATE = 16000\n",
    "MAX_AUDIO_LENGTH = 160000\n",
    "MAX_LABEL_LENGTH = 100\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class TrialTimeTracker:\n",
    "    def __init__(self, output_file):\n",
    "        self.output_file = output_file\n",
    "        self.current_trial = None\n",
    "        self.start_time = None\n",
    "        \n",
    "    def start_trial(self, config):\n",
    "        self.current_trial = {\n",
    "            'config': config,\n",
    "            'start_time': datetime.now().isoformat(),\n",
    "            'gpu_type': self._get_gpu_type(),\n",
    "            'timestamps': []\n",
    "        }\n",
    "        self.start_time = time.time()\n",
    "        \n",
    "    def log_timestamp(self, step_name):\n",
    "        if self.current_trial:\n",
    "            gpu_metrics = self._get_gpu_metrics()\n",
    "            timestamp = {\n",
    "                'step': step_name,\n",
    "                'elapsed_seconds': time.time() - self.start_time,\n",
    "                **gpu_metrics\n",
    "            }\n",
    "            self.current_trial['timestamps'].append(timestamp)\n",
    "            logger.info(f\"Step {step_name} completed after {timestamp['elapsed_seconds']:.2f}s\")\n",
    "    \n",
    "    def _get_gpu_type(self):\n",
    "        try:\n",
    "            gpu = GPUtil.getGPUs()[0]\n",
    "            return gpu.name\n",
    "        except:\n",
    "            return \"Unknown\"\n",
    "            \n",
    "    def _get_gpu_metrics(self):\n",
    "        try:\n",
    "            gpu = GPUtil.getGPUs()[0]\n",
    "            return {\n",
    "                'gpu_utilization': gpu.load * 100,\n",
    "                'gpu_memory_used': gpu.memoryUsed,\n",
    "                'gpu_memory_total': gpu.memoryTotal\n",
    "            }\n",
    "        except:\n",
    "            return {\n",
    "                'gpu_utilization': None,\n",
    "                'gpu_memory_used': None,\n",
    "                'gpu_memory_total': None\n",
    "            }\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorCTCWithPadding:\n",
    "    # Same as before\n",
    "    processor: AutoProcessor\n",
    "    padding: Union[bool, str] = \"longest\"\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        max_length = min(\n",
    "            max(len(feature[\"input_values\"]) for feature in features),\n",
    "            MAX_AUDIO_LENGTH\n",
    "        )\n",
    "        padded_inputs = []\n",
    "        attention_mask = []\n",
    "        \n",
    "        for feature in features:\n",
    "            input_length = len(feature[\"input_values\"])\n",
    "            padding_length = max_length - input_length\n",
    "            \n",
    "            if isinstance(feature[\"input_values\"], list):\n",
    "                input_values = torch.tensor(feature[\"input_values\"])\n",
    "            else:\n",
    "                input_values = feature[\"input_values\"]\n",
    "            \n",
    "            input_values = input_values.squeeze()\n",
    "            \n",
    "            if padding_length > 0:\n",
    "                padded_input = torch.nn.functional.pad(input_values, (0, padding_length))\n",
    "                attention_mask.append(torch.cat([torch.ones(input_length), torch.zeros(padding_length)]))\n",
    "            else:\n",
    "                padded_input = input_values\n",
    "                attention_mask.append(torch.ones(input_length))\n",
    "            \n",
    "            padded_inputs.append(padded_input)\n",
    "\n",
    "        batch = {\n",
    "            \"input_values\": torch.stack(padded_inputs),\n",
    "            \"attention_mask\": torch.stack(attention_mask)\n",
    "        }\n",
    "\n",
    "        with self.processor.as_target_processor():\n",
    "            label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "            labels_batch = self.processor.pad(\n",
    "                label_features,\n",
    "                padding=self.padding,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch\n",
    "\n",
    "def prepare_model_and_processor(pre_trained_id, timit_vocab, base_dir):\n",
    "    \"\"\"Prepare model and processor with vocabulary resizing\"\"\"\n",
    "    logger.info(\"Loading pretrained model and processor...\")\n",
    "    \n",
    "    os.makedirs(base_dir, exist_ok=True)\n",
    "    processor = AutoProcessor.from_pretrained(pre_trained_id)\n",
    "    model = AutoModelForCTC.from_pretrained(pre_trained_id)\n",
    "    \n",
    "    old_vocab = processor.tokenizer.get_vocab()\n",
    "    logger.info(f\"Initial vocabulary size: {len(old_vocab)}\")\n",
    "    \n",
    "    special_tokens = {\n",
    "        \"[PAD]\": 0,\n",
    "        \"<s>\": 1,\n",
    "        \"</s>\": 2,\n",
    "        \"[UNK]\": 3\n",
    "    }\n",
    "    \n",
    "    regular_tokens = sorted(list(timit_vocab - set(['<pad>', '<unk>'])))\n",
    "    vocab = {**special_tokens}\n",
    "    \n",
    "    for idx, token in enumerate(regular_tokens):\n",
    "        vocab[token] = idx + len(special_tokens)\n",
    "    \n",
    "    logger.info(f\"New vocabulary size: {len(vocab)}\")\n",
    "    \n",
    "    vocab_file = os.path.join(base_dir, \"vocab.json\")\n",
    "    with open(vocab_file, 'w') as f:\n",
    "        json.dump(vocab, f, indent=2)\n",
    "    \n",
    "    tokenizer_config = {\n",
    "        \"vocab\": vocab,\n",
    "        \"pad_token\": \"[PAD]\",\n",
    "        \"bos_token\": \"<s>\",\n",
    "        \"eos_token\": \"</s>\",\n",
    "        \"unk_token\": \"[UNK]\",\n",
    "    }\n",
    "    \n",
    "    with tempfile.NamedTemporaryFile(mode='w', delete=False) as f:\n",
    "        json.dump(vocab, f)\n",
    "        vocab_path = f.name\n",
    "    \n",
    "    new_tokenizer = Wav2Vec2CTCTokenizer(\n",
    "        vocab_path,\n",
    "        **{k: v for k, v in tokenizer_config.items() if k != \"vocab\"}\n",
    "    )\n",
    "    \n",
    "    processor.tokenizer = new_tokenizer\n",
    "    \n",
    "    # Save processor configuration\n",
    "    processor_path = os.path.join(base_dir, \"processor\")\n",
    "    processor.save_pretrained(processor_path)\n",
    "    \n",
    "    # Resize the linear head\n",
    "    old_weights = model.lm_head.weight.data\n",
    "    old_bias = model.lm_head.bias.data\n",
    "    \n",
    "    new_layer = torch.nn.Linear(model.lm_head.in_features, len(processor.tokenizer))\n",
    "    torch.nn.init.xavier_uniform_(new_layer.weight.data, gain=0.1)\n",
    "    new_layer.bias.data.uniform_(-0.1, 0.1)\n",
    "    \n",
    "    transfer_count = 0\n",
    "    for token, new_idx in vocab.items():\n",
    "        if token in old_vocab:\n",
    "            old_idx = old_vocab[token]\n",
    "            new_layer.weight.data[new_idx, :] = old_weights[old_idx, :]\n",
    "            new_layer.bias.data[new_idx] = old_bias[old_idx]\n",
    "            transfer_count += 1\n",
    "            \n",
    "    logger.info(f\"Transferred weights for {transfer_count} tokens\")\n",
    "    \n",
    "    model.lm_head = new_layer\n",
    "    model.config.vocab_size = len(vocab)\n",
    "    model.config.pad_token_id = special_tokens[\"[PAD]\"]\n",
    "    model.config.bos_token_id = special_tokens[\"<s>\"]\n",
    "    model.config.eos_token_id = special_tokens[\"</s>\"]\n",
    "    model.config.unk_token_id = special_tokens[\"[UNK]\"]\n",
    "    \n",
    "    return model, processor\n",
    "\n",
    "def prepare_datasets(train_df, processor):\n",
    "    \"\"\"Dataset preparation with optimized batch processing\"\"\"\n",
    "    # Same as before\n",
    "    logger.info(\"Splitting dataset into train and evaluation...\")\n",
    "    \n",
    "    train_data, eval_data = train_test_split(train_df, test_size=0.2, random_state=42)\n",
    "    \n",
    "    def process_data(batch):\n",
    "        audio = preprocess_audio(batch[\"audio\"])\n",
    "        audio = audio.squeeze()\n",
    "        \n",
    "        inputs = processor(\n",
    "            audio, \n",
    "            sampling_rate=SAMPLING_RATE, \n",
    "            return_tensors=None\n",
    "        )\n",
    "        \n",
    "        input_values = np.squeeze(inputs[\"input_values\"])\n",
    "        \n",
    "        with processor.as_target_processor():\n",
    "            labels = processor(batch[\"ipa\"]).input_ids\n",
    "        \n",
    "        return {\n",
    "            \"input_values\": input_values,\n",
    "            \"labels\": labels,\n",
    "            \"audio\": audio\n",
    "        }\n",
    "    \n",
    "    train_dataset = Dataset.from_pandas(train_data)\n",
    "    eval_dataset = Dataset.from_pandas(eval_data)\n",
    "    \n",
    "    train_dataset = train_dataset.map(\n",
    "        process_data,\n",
    "        batch_size=32,\n",
    "        num_proc=4,\n",
    "        remove_columns=[col for col in train_dataset.column_names if col != \"audio\"]\n",
    "    )\n",
    "    eval_dataset = eval_dataset.map(\n",
    "        process_data,\n",
    "        batch_size=32,\n",
    "        num_proc=4,\n",
    "        remove_columns=[col for col in eval_dataset.column_names if col != \"audio\"]\n",
    "    )\n",
    "    \n",
    "    return train_dataset, eval_dataset\n",
    "\n",
    "def preprocess_audio(audio_input):\n",
    "    \"\"\"Audio preprocessing function\"\"\"\n",
    "    # Same as before\n",
    "    if isinstance(audio_input, str):\n",
    "        waveform, sample_rate = torchaudio.load(audio_input)\n",
    "        audio_numpy = waveform.squeeze().numpy()\n",
    "    elif isinstance(audio_input, (list, np.ndarray, torch.Tensor)):\n",
    "        audio_numpy = np.array(audio_input, dtype=np.float32)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported audio type: {type(audio_input)}\")\n",
    "    \n",
    "    audio_numpy = audio_numpy.astype(np.float32)\n",
    "    if len(audio_numpy.shape) > 1:\n",
    "        audio_numpy = np.mean(audio_numpy, axis=0)\n",
    "    \n",
    "    if np.abs(audio_numpy).max() > 1:\n",
    "        audio_numpy = audio_numpy / np.abs(audio_numpy).max()\n",
    "    \n",
    "    if len(audio_numpy) > MAX_AUDIO_LENGTH:\n",
    "        audio_numpy = audio_numpy[:MAX_AUDIO_LENGTH]\n",
    "    elif len(audio_numpy) < MAX_AUDIO_LENGTH:\n",
    "        padding = np.zeros(MAX_AUDIO_LENGTH - len(audio_numpy), dtype=np.float32)\n",
    "        audio_numpy = np.concatenate([audio_numpy, padding])\n",
    "    \n",
    "    return audio_numpy\n",
    "\n",
    "def run_finetuning(train_df, pre_trained_id, timit_vocab, output_dir):\n",
    "    \"\"\"Run finetuning with optimal hyperparameters\"\"\"\n",
    "    tracker = TrialTimeTracker(os.path.join(output_dir, \"finetuning_log.jsonl\"))\n",
    "    \n",
    "    config = {\n",
    "        \"learning_rate\": 9.999999999999999e-05,\n",
    "        \"per_device_train_batch_size\": 4,\n",
    "        \"per_device_eval_batch_size\": 4,\n",
    "        \"gradient_accumulation_steps\": 2,\n",
    "        \"warmup_ratio\": 0.1,\n",
    "        \"weight_decay\": 0.01,\n",
    "        \"max_grad_norm\": 1.0,\n",
    "        \"adam_beta1\": 0.9,\n",
    "        \"adam_beta2\": 0.975,\n",
    "        \"adam_epsilon\": 1e-08\n",
    "    }\n",
    "    \n",
    "    wandb.init(\n",
    "        project=\"xlsr-phoneme-finetuning-final\",\n",
    "        name=\"finetuning_optimal_params\",\n",
    "        config=config\n",
    "    )\n",
    "    \n",
    "    tracker.start_trial(config)\n",
    "    \n",
    "    tracker.log_timestamp(\"model_init_start\")\n",
    "    model, processor = prepare_model_and_processor(pre_trained_id, timit_vocab, output_dir)\n",
    "    model.gradient_checkpointing_enable()\n",
    "    tracker.log_timestamp(\"model_init_complete\")\n",
    "    \n",
    "    tracker.log_timestamp(\"dataset_prep_start\")\n",
    "    train_dataset, eval_dataset = prepare_datasets(train_df, processor)\n",
    "    tracker.log_timestamp(\"dataset_prep_complete\")\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        **config,\n",
    "        num_train_epochs=20,\n",
    "        logging_steps=50,\n",
    "        save_steps=100,\n",
    "        eval_steps=100,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"eval_loss\",\n",
    "        greater_is_better=False,\n",
    "        save_strategy=\"steps\",\n",
    "        save_total_limit=2,\n",
    "        fp16=True,\n",
    "        dataloader_num_workers=16,\n",
    "        gradient_checkpointing=True,\n",
    "        dataloader_prefetch_factor=4,\n",
    "        ddp_find_unused_parameters=False\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        data_collator=DataCollatorCTCWithPadding(processor=processor, padding=\"longest\"),\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=5)]\n",
    "    )\n",
    "    \n",
    "    tracker.log_timestamp(\"training_start\")\n",
    "    train_result = trainer.train()\n",
    "    tracker.log_timestamp(\"training_complete\")\n",
    "    \n",
    "    eval_result = trainer.evaluate()\n",
    "    tracker.log_timestamp(\"evaluation_complete\")\n",
    "    \n",
    "    logger.info(\"Saving final model and processor...\")\n",
    "    trainer.save_model(os.path.join(output_dir, \"final_model\"))\n",
    "    processor.save_pretrained(os.path.join(output_dir, \"final_processor\"))\n",
    "    \n",
    "    wandb.finish()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_finetuning(\n",
    "        train_df=train_df,  # Your training DataFrame\n",
    "        pre_trained_id=PRE_TRAINED_ID,  # Your pretrained model ID\n",
    "        timit_vocab=timit_vocab,  # Your TIMIT vocabulary set\n",
    "        output_dir=\"./results/finetune_resize_final\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## v2 debug: changing handling of special tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import logging\n",
    "import tempfile\n",
    "import wandb\n",
    "import numpy as np\n",
    "from transformers import (\n",
    "    AutoProcessor, \n",
    "    AutoModelForCTC, \n",
    "    Trainer, \n",
    "    TrainingArguments, \n",
    "    Wav2Vec2CTCTokenizer,\n",
    "    EarlyStoppingCallback,\n",
    "    TrainerCallback\n",
    ")\n",
    "from datasets import Dataset\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional, Union\n",
    "import torchaudio\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import product\n",
    "from datetime import datetime\n",
    "import time\n",
    "import GPUtil\n",
    "import psutil\n",
    "\n",
    "class TrialTimeTracker:\n",
    "    \"\"\"Track detailed timing information for each trial\"\"\"\n",
    "    def __init__(self, output_file):\n",
    "        self.output_file = output_file\n",
    "        self.current_trial = None\n",
    "        self.start_time = None\n",
    "        \n",
    "    def start_trial(self, trial_config, trial_id):\n",
    "        self.current_trial = {\n",
    "            'trial_id': trial_id,\n",
    "            'config': trial_config,\n",
    "            'start_time': datetime.now().isoformat(),\n",
    "            'gpu_type': self._get_gpu_type(),\n",
    "            'timestamps': []\n",
    "        }\n",
    "        self.start_time = time.time()\n",
    "        \n",
    "    def log_timestamp(self, step_name):\n",
    "        if self.current_trial:\n",
    "            gpu_metrics = self._get_gpu_metrics()\n",
    "            timestamp = {\n",
    "                'step': step_name,\n",
    "                'elapsed_seconds': time.time() - self.start_time,\n",
    "                **gpu_metrics\n",
    "            }\n",
    "            self.current_trial['timestamps'].append(timestamp)\n",
    "            logger.info(f\"Step {step_name} completed after {timestamp['elapsed_seconds']:.2f}s\")\n",
    "            \n",
    "    def end_trial(self, eval_loss=None):\n",
    "        if self.current_trial:\n",
    "            self.current_trial['total_time'] = time.time() - self.start_time\n",
    "            if eval_loss is not None:\n",
    "                self.current_trial['eval_loss'] = eval_loss\n",
    "            \n",
    "            with open(self.output_file, 'a') as f:\n",
    "                json.dump(self.current_trial, f)\n",
    "                f.write('\\n')\n",
    "            \n",
    "            trial_summary = self.current_trial.copy()\n",
    "            self.current_trial = None\n",
    "            return trial_summary\n",
    "    \n",
    "    def _get_gpu_type(self):\n",
    "        try:\n",
    "            gpu = GPUtil.getGPUs()[0]\n",
    "            return gpu.name\n",
    "        except:\n",
    "            return \"Unknown\"\n",
    "            \n",
    "    def _get_gpu_metrics(self):\n",
    "        try:\n",
    "            gpu = GPUtil.getGPUs()[0]\n",
    "            return {\n",
    "                'gpu_utilization': gpu.load * 100,\n",
    "                'gpu_memory_used': gpu.memoryUsed,\n",
    "                'gpu_memory_total': gpu.memoryTotal\n",
    "            }\n",
    "        except:\n",
    "            return {\n",
    "                'gpu_utilization': None,\n",
    "                'gpu_memory_used': None,\n",
    "                'gpu_memory_total': None\n",
    "            }\n",
    "\n",
    "# Constants\n",
    "SAMPLING_RATE = 16000\n",
    "MAX_AUDIO_LENGTH = 160000  # 10 seconds at 16kHz\n",
    "MAX_LABEL_LENGTH = 100\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorCTCWithPadding:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs received.\n",
    "    \"\"\"\n",
    "    processor: AutoProcessor\n",
    "    padding: Union[bool, str] = \"longest\"\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        max_length = min(\n",
    "            max(len(feature[\"input_values\"]) for feature in features),\n",
    "            MAX_AUDIO_LENGTH\n",
    "        )\n",
    "        padded_inputs = []\n",
    "        attention_mask = []\n",
    "        for feature in features:\n",
    "            input_length = len(feature[\"input_values\"])\n",
    "            padding_length = max_length - input_length\n",
    "            \n",
    "            if isinstance(feature[\"input_values\"], list):\n",
    "                input_values = torch.tensor(feature[\"input_values\"])\n",
    "            else:\n",
    "                input_values = feature[\"input_values\"]\n",
    "            \n",
    "            input_values = input_values.squeeze()\n",
    "            \n",
    "            if padding_length > 0:\n",
    "                padded_input = torch.nn.functional.pad(input_values, (0, padding_length))\n",
    "                attention_mask.append(torch.cat([torch.ones(input_length), torch.zeros(padding_length)]))\n",
    "            else:\n",
    "                padded_input = input_values\n",
    "                attention_mask.append(torch.ones(input_length))\n",
    "            \n",
    "            padded_inputs.append(padded_input)\n",
    "\n",
    "        batch = {\n",
    "            \"input_values\": torch.stack(padded_inputs),\n",
    "            \"attention_mask\": torch.stack(attention_mask)\n",
    "        }\n",
    "\n",
    "        with self.processor.as_target_processor():\n",
    "            label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "            labels_batch = self.processor.pad(\n",
    "                label_features,\n",
    "                padding=self.padding,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch\n",
    "\n",
    "def prepare_datasets(train_df, processor):\n",
    "    \"\"\"\n",
    "    Dataset preparation with optimized batch processing\n",
    "    \"\"\"\n",
    "    logger.info(\"Splitting dataset into train and evaluation...\")\n",
    "    \n",
    "    train_data, eval_data = train_test_split(train_df, test_size=0.2, random_state=42)\n",
    "    \n",
    "    def process_data(batch):\n",
    "        # Preprocess audio\n",
    "        audio = preprocess_audio(batch[\"audio\"])\n",
    "        audio = audio.squeeze()\n",
    "        \n",
    "        # Process audio without padding or tensor conversion\n",
    "        inputs = processor(\n",
    "            audio, \n",
    "            sampling_rate=SAMPLING_RATE, \n",
    "            return_tensors=None\n",
    "        )\n",
    "        \n",
    "        input_values = np.squeeze(inputs[\"input_values\"])\n",
    "        \n",
    "        # Process labels\n",
    "        with processor.as_target_processor():\n",
    "            labels = processor(batch[\"ipa\"]).input_ids\n",
    "        \n",
    "        return {\n",
    "            \"input_values\": input_values,\n",
    "            \"labels\": labels,\n",
    "            \"audio\": audio\n",
    "        }\n",
    "    \n",
    "    # Convert DataFrames to Datasets with optimized batch processing\n",
    "    train_dataset = Dataset.from_pandas(train_data)\n",
    "    eval_dataset = Dataset.from_pandas(eval_data)\n",
    "    \n",
    "    # Apply processing with larger batches\n",
    "    train_dataset = train_dataset.map(\n",
    "        process_data,\n",
    "        batch_size=32,\n",
    "        num_proc=4,\n",
    "        remove_columns=[col for col in train_dataset.column_names if col != \"audio\"]\n",
    "    )\n",
    "    eval_dataset = eval_dataset.map(\n",
    "        process_data,\n",
    "        batch_size=32,\n",
    "        num_proc=4,\n",
    "        remove_columns=[col for col in eval_dataset.column_names if col != \"audio\"]\n",
    "    )\n",
    "    \n",
    "    return train_dataset, eval_dataset\n",
    "\n",
    "def preprocess_audio(audio_input):\n",
    "    \"\"\"\n",
    "    Load and preprocess audio to match expected format.\n",
    "    \"\"\"\n",
    "    # Handle different input types\n",
    "    if isinstance(audio_input, str):  # File path\n",
    "        waveform, sample_rate = torchaudio.load(audio_input)\n",
    "        audio_numpy = waveform.squeeze().numpy()\n",
    "        \n",
    "    elif isinstance(audio_input, list):  # List input\n",
    "        audio_numpy = np.array(audio_input, dtype=np.float32)\n",
    "        \n",
    "    elif isinstance(audio_input, np.ndarray):  # Already numpy array\n",
    "        audio_numpy = audio_input\n",
    "        \n",
    "    elif isinstance(audio_input, torch.Tensor):  # Torch tensor\n",
    "        audio_numpy = audio_input.numpy()\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported audio type: {type(audio_input)}\")\n",
    "    \n",
    "    # Ensure float32 dtype\n",
    "    audio_numpy = audio_numpy.astype(np.float32)\n",
    "    \n",
    "    # Ensure 1D array\n",
    "    if len(audio_numpy.shape) > 1:\n",
    "        audio_numpy = np.mean(audio_numpy, axis=0)\n",
    "    \n",
    "    # Normalize audio\n",
    "    if np.abs(audio_numpy).max() > 1:\n",
    "        audio_numpy = audio_numpy / np.abs(audio_numpy).max()\n",
    "    \n",
    "    # Trim or pad to max length\n",
    "    if len(audio_numpy) > MAX_AUDIO_LENGTH:\n",
    "        audio_numpy = audio_numpy[:MAX_AUDIO_LENGTH]\n",
    "    elif len(audio_numpy) < MAX_AUDIO_LENGTH:\n",
    "        padding = np.zeros(MAX_AUDIO_LENGTH - len(audio_numpy), dtype=np.float32)\n",
    "        audio_numpy = np.concatenate([audio_numpy, padding])\n",
    "    \n",
    "    return audio_numpy\n",
    "\n",
    "def prepare_model_and_processor(pre_trained_id, timit_vocab):\n",
    "    \"\"\"\n",
    "    Prepare the model and processor with reduced vocabulary and resized linear head.\n",
    "    \"\"\"\n",
    "    logger.info(\"Loading pretrained model and processor...\")\n",
    "    \n",
    "    # Create base directory\n",
    "    base_dir = \"/home/arunasri/ML/notebooks/results/a100_resize_structured_v4\"\n",
    "    os.makedirs(base_dir, exist_ok=True)\n",
    "    \n",
    "    processor = AutoProcessor.from_pretrained(pre_trained_id)\n",
    "    model = AutoModelForCTC.from_pretrained(pre_trained_id)\n",
    "    \n",
    "    # Log initial vocabulary details\n",
    "    old_vocab = processor.tokenizer.get_vocab()\n",
    "    logger.info(f\"Initial vocabulary size: {len(old_vocab)}\")\n",
    "    \n",
    "    # Define special tokens with fixed positions matching pretrained model\n",
    "    special_tokens = {\n",
    "        \"[PAD]\": 0,\n",
    "        \"<s>\": 1,\n",
    "        \"</s>\": 2,\n",
    "        \"[UNK]\": 3\n",
    "    }\n",
    "    \n",
    "    # Create new vocabulary\n",
    "    regular_tokens = sorted(list(timit_vocab - set(['<pad>', '<unk>'])))  # Remove old-style tokens if present\n",
    "    vocab = {**special_tokens}\n",
    "    \n",
    "    for idx, token in enumerate(regular_tokens):\n",
    "        vocab[token] = idx + len(special_tokens)\n",
    "    \n",
    "    logger.info(f\"New vocabulary size: {len(vocab)}\")\n",
    "    \n",
    "    # Save vocabulary for inspection\n",
    "    vocab_file = os.path.join(base_dir, \"vocab.json\")\n",
    "    with open(vocab_file, 'w') as f:\n",
    "        json.dump(vocab, f, indent=2)\n",
    "    \n",
    "    # Create new tokenizer with matching special tokens\n",
    "    tokenizer_config = {\n",
    "        \"vocab\": vocab,\n",
    "        \"pad_token\": \"[PAD]\",\n",
    "        \"bos_token\": \"<s>\",\n",
    "        \"eos_token\": \"</s>\",\n",
    "        \"unk_token\": \"[UNK]\",\n",
    "    }\n",
    "    \n",
    "    with tempfile.NamedTemporaryFile(mode='w', delete=False) as f:\n",
    "        json.dump(vocab, f)\n",
    "        vocab_path = f.name\n",
    "    \n",
    "    new_tokenizer = Wav2Vec2CTCTokenizer(\n",
    "        vocab_path,\n",
    "        **{k: v for k, v in tokenizer_config.items() if k != \"vocab\"}\n",
    "    )\n",
    "    \n",
    "    processor.tokenizer = new_tokenizer\n",
    "    \n",
    "    # Save processor configuration\n",
    "    processor_path = os.path.join(base_dir, \"processor\")\n",
    "    processor.save_pretrained(processor_path)\n",
    "    logger.info(f\"Saved processor configuration to {processor_path}\")\n",
    "    \n",
    "    # Resize the linear head\n",
    "    old_weights = model.lm_head.weight.data\n",
    "    old_bias = model.lm_head.bias.data\n",
    "    \n",
    "    new_layer = torch.nn.Linear(model.lm_head.in_features, len(processor.tokenizer))\n",
    "    torch.nn.init.xavier_uniform_(new_layer.weight.data, gain=0.1)\n",
    "    new_layer.bias.data.uniform_(-0.1, 0.1)\n",
    "    \n",
    "    # Transfer weights for matching tokens\n",
    "    transfer_count = 0\n",
    "    for token, new_idx in vocab.items():\n",
    "        if token in old_vocab:\n",
    "            old_idx = old_vocab[token]\n",
    "            new_layer.weight.data[new_idx, :] = old_weights[old_idx, :]\n",
    "            new_layer.bias.data[new_idx] = old_bias[old_idx]\n",
    "            transfer_count += 1\n",
    "            logger.info(f\"Transferred token '{token}' from position {old_idx} to {new_idx}\")\n",
    "    \n",
    "    logger.info(f\"Transferred weights for {transfer_count} tokens\")\n",
    "    \n",
    "    # Update model configuration\n",
    "    model.lm_head = new_layer\n",
    "    model.config.vocab_size = len(vocab)\n",
    "    model.config.pad_token_id = special_tokens[\"[PAD]\"]\n",
    "    model.config.bos_token_id = special_tokens[\"<s>\"]\n",
    "    model.config.eos_token_id = special_tokens[\"</s>\"]\n",
    "    model.config.unk_token_id = special_tokens[\"[UNK]\"]\n",
    "    \n",
    "    return model, processor\n",
    "\n",
    "def generate_systematic_configs():\n",
    "    \"\"\"Generate systematic hyperparameter configurations\"\"\"\n",
    "    learning_rates = np.logspace(-6, -4, num=5)\n",
    "    batch_sizes = [4, 8, 16]\n",
    "    grad_accums = [2, 4, 8]\n",
    "    warmup_ratios = [0.05, 0.1, 0.15]\n",
    "    weight_decays = np.logspace(-3, -1, num=3)\n",
    "    max_grad_norms = [0.5, 1.0, 2.0]\n",
    "    adam_beta1s = [0.85, 0.9, 0.95]\n",
    "    adam_beta2s = [0.95, 0.975, 0.999]\n",
    "    adam_epsilons = np.logspace(-9, -7, num=3)\n",
    "    \n",
    "    primary_configs = list(product(\n",
    "        learning_rates,\n",
    "        batch_sizes,\n",
    "        grad_accums\n",
    "    ))\n",
    "    \n",
    "    secondary_params = {\n",
    "        'warmup_ratio': warmup_ratios[1],\n",
    "        'weight_decay': weight_decays[1],\n",
    "        'max_grad_norm': max_grad_norms[1],\n",
    "        'adam_beta1': adam_beta1s[1],\n",
    "        'adam_beta2': adam_beta2s[1],\n",
    "        'adam_epsilon': adam_epsilons[1]\n",
    "    }\n",
    "    \n",
    "    configs = []\n",
    "    for lr, bs, ga in primary_configs:\n",
    "        config = {\n",
    "            'learning_rate': float(lr),\n",
    "            'per_device_train_batch_size': bs,\n",
    "            'per_device_eval_batch_size': bs,\n",
    "            'gradient_accumulation_steps': ga,\n",
    "            **secondary_params\n",
    "        }\n",
    "        configs.append(config)\n",
    "    \n",
    "    return configs\n",
    "class LossMonitorCallback(TrainerCallback):\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs:\n",
    "            if 'loss' in logs:\n",
    "                current_loss = logs['loss']\n",
    "                if current_loss > 10.0:\n",
    "                    logger.warning(f\"High loss detected: {current_loss}\")\n",
    "                    logger.warning(\"This may indicate issues with vocabulary handling or model configuration\")\n",
    "                elif current_loss < 0.1:\n",
    "                    logger.warning(f\"Unusually low loss detected: {current_loss}\")\n",
    "                    logger.warning(\"This may indicate potential issues with loss computation\")\n",
    "\n",
    "def run_systematic_search(train_df, pre_trained_id, timit_vocab, resume_file=\"a100_resize_structured_search_v4.jsonl\", start_trial=0):\n",
    "    \"\"\"Run systematic hyperparameter search with enhanced monitoring\"\"\"\n",
    "    configs = generate_systematic_configs()\n",
    "    logger.info(f\"Generated {len(configs)} configurations for systematic search\")\n",
    "    logger.info(f\"Starting from trial {start_trial}\")\n",
    "    \n",
    "    # Initialize tracking file - but only truncate if starting from beginning\n",
    "    if start_trial == 0:\n",
    "        tracker = TrialTimeTracker(output_file=resume_file)\n",
    "        logger.info(f\"Starting fresh search with results saved to {resume_file}\")\n",
    "    else:\n",
    "        # Append mode for resuming\n",
    "        tracker = TrialTimeTracker(output_file=resume_file)\n",
    "        logger.info(f\"Resuming search from trial {start_trial}, appending to {resume_file}\")\n",
    "    \n",
    "    # Skip trials before start_trial\n",
    "    for trial_idx, config in enumerate(configs[start_trial:], start=start_trial):\n",
    "        logger.info(f\"\\nStarting trial {trial_idx + 1}/{len(configs)}\")\n",
    "        logger.info(f\"Configuration: {json.dumps(config, indent=2)}\")\n",
    "        \n",
    "        run_name = f\"trial_{trial_idx}_resize_v4\"\n",
    "        wandb.init(\n",
    "            project=\"xlsr-buckeye-phoneme-a100-resize-structured-v4-tokenizer\",\n",
    "            name=run_name,\n",
    "            config=config,\n",
    "            reinit=True\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            tracker.start_trial(config, trial_idx)\n",
    "            \n",
    "            # Initialize model and processor with validation\n",
    "            tracker.log_timestamp(\"model_init_start\")\n",
    "            model, processor = prepare_model_and_processor(pre_trained_id, timit_vocab)\n",
    "            model.gradient_checkpointing_enable()\n",
    "            tracker.log_timestamp(\"model_init_complete\")\n",
    "            \n",
    "            # Prepare datasets\n",
    "            tracker.log_timestamp(\"dataset_prep_start\")\n",
    "            train_dataset, eval_dataset = prepare_datasets(train_df, processor)\n",
    "            tracker.log_timestamp(\"dataset_prep_complete\")\n",
    "            \n",
    "            # Training setup\n",
    "            output_dir = f\"./results/a100_resize_structured_v4_tokenizer/trial_{trial_idx}\"\n",
    "            training_args = TrainingArguments(\n",
    "                output_dir=output_dir,\n",
    "                **config,\n",
    "                num_train_epochs=5,\n",
    "                logging_steps=50,\n",
    "                save_steps=100,\n",
    "                eval_steps=100,\n",
    "                evaluation_strategy=\"steps\",\n",
    "                load_best_model_at_end=True,\n",
    "                metric_for_best_model=\"eval_loss\",\n",
    "                greater_is_better=False,\n",
    "                save_strategy=\"steps\",\n",
    "                save_total_limit=2,\n",
    "                fp16=True,\n",
    "                dataloader_num_workers=16,\n",
    "                gradient_checkpointing=True,\n",
    "                dataloader_prefetch_factor=4,\n",
    "                ddp_find_unused_parameters=False,\n",
    "                resume_from_checkpoint=True\n",
    "            )\n",
    "            \n",
    "            # Initialize trainer with callbacks\n",
    "            trainer = Trainer(\n",
    "                model=model,\n",
    "                args=training_args,\n",
    "                train_dataset=train_dataset,\n",
    "                eval_dataset=eval_dataset,\n",
    "                data_collator=DataCollatorCTCWithPadding(processor=processor, padding=\"longest\"),\n",
    "                callbacks=[\n",
    "                    EarlyStoppingCallback(early_stopping_patience=3),\n",
    "                    LossMonitorCallback()\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            # Training\n",
    "            tracker.log_timestamp(\"training_start\")\n",
    "            train_result = trainer.train()\n",
    "            tracker.log_timestamp(\"training_complete\")\n",
    "            \n",
    "            # Evaluation\n",
    "            eval_result = trainer.evaluate()\n",
    "            tracker.log_timestamp(\"evaluation_complete\")\n",
    "            \n",
    "            # Log results\n",
    "            wandb.log({\n",
    "                \"eval_loss\": eval_result[\"eval_loss\"],\n",
    "                \"train_loss\": train_result.training_loss,\n",
    "                \"total_training_time\": train_result.metrics[\"train_runtime\"],\n",
    "                \"samples_per_second\": train_result.metrics[\"train_samples_per_second\"]\n",
    "            })\n",
    "            \n",
    "            tracker.end_trial(eval_loss=eval_result[\"eval_loss\"])\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in trial {trial_idx}: {str(e)}\")\n",
    "            tracker.end_trial()\n",
    "        \n",
    "        finally:\n",
    "            wandb.finish()\n",
    "    \n",
    "    return resume_file\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results_file = run_systematic_search(\n",
    "        train_df=train_df,\n",
    "        pre_trained_id=PRE_TRAINED_ID,\n",
    "        timit_vocab=timit_vocab,\n",
    "        start_trial=15\n",
    "    )\n",
    "    logger.info(f\"Results saved to {results_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model on Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCTC, Wav2Vec2Processor\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Log in to Hugging Face (if not already logged in)\n",
    "# login(\"your-huggingface-api-token\")\n",
    "\n",
    "# Load the model and processor from your local directory\n",
    "model = AutoModelForCTC.from_pretrained(\"/home/arunasrivastava/ML/notebooks/results-b0\")\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"/home/arunasrivastava/ML/notebooks/results-b0\")\n",
    "\n",
    "# Specify the directory where you want to save the model\n",
    "save_directory = \"./xlsr-timit-b0\"\n",
    "\n",
    "# Save and upload to Hugging Face Model Hub under an organization\n",
    "model.save_pretrained(save_directory, push_to_hub=True, repo_id=\"KoelLabs/xlsr-timit-b0\")\n",
    "processor.save_pretrained(save_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions to Upload Model to Hugging Face\n",
    "\n",
    "1. **Login to Hugging Face**  \n",
    "   Run the following command to log in to your Hugging Face account:\n",
    "   ```bash\n",
    "   huggingface-cli login\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Create a Repository**  \n",
    "   Run the following command to log in to your Hugging Face account:\n",
    "   ```bash\n",
    "   huggingface-cli repo create your-model-name --organization your-org-name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Git clone**  \n",
    "   Run the following command to clone your repo:\n",
    "   ```bash \n",
    "   git clone https://huggingface.co/your-org-name/your-model-name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Upload Model**  (if you did not make it on Hugging Face already)\n",
    "   Run the following command to clone your repo:\n",
    "   ```bash \n",
    "   huggingface-cli repo upload --path ./<path here>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **Move Other Files**  \n",
    "   Run the following command to copy each file into the repo:\n",
    "   ```bash\n",
    "   cp -r ./<path here> <your-cloned-repo-folder> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. **Stage & Commit!**\n",
    "    Run the following git commands\n",
    "    ```bash\n",
    "    git add README.md\n",
    "    git commit -m \"Add model card\"\n",
    "    git push\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YAAAAY CONGRATULATIONS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Optional) Hyperparam search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install optuna joblib\n",
    "# you can use WADNB sweeps as well, whatever is easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
