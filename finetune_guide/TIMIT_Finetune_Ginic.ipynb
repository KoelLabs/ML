{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 游꿗 Speech-to-Phoneme Model Finetuning! 游뿏\n",
    "===============================\n",
    "\n",
    "Hey there, future speech recognition wizard! This notebook helps you train a model\n",
    "to convert speech into IPA phonemes (those tiny sound units that make up words).\n",
    "Think of it like teaching a robot to hear \"cat\" and write out \"k 칝 t\"!\n",
    "\n",
    "What's a phoneme? It's like the DNA of speech! For example:\n",
    "- \"cat\" = /k/ + /칝/ + /t/\n",
    "- \"dog\" = /d/ + /톖/ + /g/\n",
    "- \"fish\" = /f/ + /톩/ + /툮/\n",
    "\n",
    "Let's make some speech recognition magic happen! 游꿢"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arunasrivastava/Koel/ML-eval/ML/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'repos'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscripts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m audio_file_to_array\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscripts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mipa\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m timit2ipa\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscripts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mipa\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m filter_chars\n",
      "File \u001b[0;32m~/Koel/ML-eval/ML/finetune_guide/../scripts/ipa.py:15\u001b[0m\n\u001b[1;32m     12\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(\u001b[38;5;18m__file__\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     14\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(\u001b[38;5;18m__file__\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../repos/phonecodes/src\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrepos\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mphonecodes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m phonecodes\n\u001b[1;32m     17\u001b[0m CODES \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mipa\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marpabet\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxsampa\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallhome\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     18\u001b[0m LANGUAGES \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meng\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeu\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnld\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marz\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcmn\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspa\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlao\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvie\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'repos'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import zipfile\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "# run as much as possible accelerated by apple silicon, fall back to cpu if not possible\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from scripts.audio import audio_file_to_array\n",
    "from scripts.ipa import timit2ipa\n",
    "from scripts.ipa import filter_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append('..')\n",
    "from scripts.eval_tests.panphon_model_eval import panphon_model_eval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set espeak library path for macOS\n",
    "if sys.platform == \"darwin\":\n",
    "    from phonemizer.backend.espeak.wrapper import EspeakWrapper\n",
    "\n",
    "    _ESPEAK_LIBRARY = \"/opt/homebrew/Cellar/espeak/1.48.04_1/lib/libespeak.1.1.48.dylib\"\n",
    "    EspeakWrapper.set_library(_ESPEAK_LIBRARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, AutoModelForCTC, AutoTokenizer, AutoFeatureExtractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can select any model to fine-tune upon, here is a checkpoint that could work. You can also try our model: KoelLabs/xlsr-timit-b0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = os.path.join('..', 'models', 'timit-xlsr-finetune-B')\n",
    "PRE_TRAINED_ID = \"ginic/data_seed_4_wav2vec2-large-xlsr-buckeye-ipa\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TIMIT dataset needs to parsed into a set of phoneme and .WAV (audio) files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "timit = zipfile.ZipFile('../.data/TIMIT.zip', 'r')\n",
    "timit_files = timit.namelist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_files = list(set(map(lambda x: x.split('.')[0], filter(lambda x: x.startswith('data/TRAIN'), timit_files))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "WAV_HEADER_SIZE = 44\n",
    "def zipped_wav_to_array(filename):\n",
    "    with timit.open(filename) as wav_file:\n",
    "        return np.frombuffer(wav_file.read(), dtype=np.int16)[WAV_HEADER_SIZE//2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up Dataset Vocab \n",
    "You will see that the initial vocab of most multilingual phoneme transcription models is quite big (300-400 phonemes) we will reduce this in the dataset to improve overall performance for English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these functions will just help us map to simpler IPA. if you skip this step, you may find it a bit more difficult to build a generalizable model\n",
    "def simplify_timit(phoneme):\n",
    "    # Substitute the phoneme based on the dictionary\n",
    "    substitution_dict = {\n",
    "        '쮋': '',  # Replace nasalized flap with plain flap\n",
    "        '콂팴': '콂',  # Remove syllabic marker from '콂팴'\n",
    "        '톛퍈': '톛',  # Remove voiceless marker from '톛퍈'\n",
    "        '톟': '톷',   # Simplify rhotacized schwa to '톷'\n",
    "        '톜': '톷',   # Simplify rhotacized schwa to '톷'\n",
    "        'l퍌': 'l',   # Remove syllabic marker from 'l퍌'\n",
    "        'm퍌': 'm',   # Remove syllabic marker from 'm퍌'\n",
    "        'n퍌': 'n',   # Remove syllabic marker from 'n퍌'\n",
    "        '퍌': '',     # Remove syllabic marker\n",
    "        '툴': 'u',    # Replace high central rounded vowel with high back rounded vowel\n",
    "        '톧': 'i',    # Replace high central unrounded vowel with high front unrounded vowel\n",
    "        ' ': '',     # Remove nasalization marker\n",
    "        '톥': 'h',    # Replace voiceless glottal fricative with voiceless glottal fricative\n",
    "        # Add other necessary substitutions if needed\n",
    "    }\n",
    "    # Apply the substitution for the phoneme\n",
    "    return substitution_dict.get(phoneme, phoneme)  # Return simplified phoneme or the original if no replacement\n",
    "\n",
    "def remove_stress_mark(text):\n",
    "    \"\"\"\n",
    "    Removes the combining double inverted breve (포) from text.\n",
    "    \n",
    "    Args:\n",
    "        text: String or iterable containing IPA symbols\n",
    "        \n",
    "    Returns:\n",
    "        Text with stress marks removed\n",
    "    \"\"\"\n",
    "    if isinstance(text, str):\n",
    "        return text.replace('포', '')\n",
    "    else:\n",
    "        raise TypeError(\"Input must be string, set, or list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio</th>\n",
       "      <th>ipa</th>\n",
       "      <th>phoneme_starts</th>\n",
       "      <th>phoneme_ends</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[25971, 30303, 29285, 26995, 28271, 11552, 131...</td>\n",
       "      <td>톷톝토톷int톔mtt툮툵zt톛w톔tt툮k톔톷tunzni톝ft톷nun</td>\n",
       "      <td>[0, 2346, 2709, 3467, 4646, 5101, 6558, 7394, ...</td>\n",
       "      <td>[2346, 2709, 3467, 4646, 5101, 6558, 7394, 836...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[25971, 30303, 29285, 26995, 28271, 11552, 131...</td>\n",
       "      <td>w톩tt툮tt툮톷tt툮du칧톩sm톩풪sw톷툮ip톩n</td>\n",
       "      <td>[0, 2095, 2892, 3718, 4530, 5760, 6732, 8731, ...</td>\n",
       "      <td>[2095, 2892, 3718, 4530, 5760, 6732, 8731, 107...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[25971, 30303, 29285, 26995, 28271, 11552, 131...</td>\n",
       "      <td>툮ih칝dd뉄젻톔톷ksu툾n톷isiw톖툮w톖쮈좕덀닯j톩톷</td>\n",
       "      <td>[0, 4760, 6520, 7561, 8280, 10193, 10920, 1156...</td>\n",
       "      <td>[4760, 6520, 7561, 8280, 10193, 10920, 11560, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[25971, 30303, 29285, 26995, 28271, 11552, 131...</td>\n",
       "      <td>톛bl톩si쬴h톝no툵쮈져톩i쬴토o툵h칝ndinh칝nd</td>\n",
       "      <td>[0, 2200, 3091, 3880, 5347, 5848, 6365, 7400, ...</td>\n",
       "      <td>[2200, 3091, 3880, 5347, 5848, 6365, 7400, 960...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[25971, 30303, 29285, 26995, 28271, 11552, 131...</td>\n",
       "      <td>hiniv톝lfi콂f톩lmm톝쬴t톔ksikimiklz톷juzd</td>\n",
       "      <td>[0, 2007, 2571, 3020, 4014, 4238, 4687, 5713, ...</td>\n",
       "      <td>[2007, 2571, 3020, 4014, 4238, 4687, 5713, 763...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               audio  \\\n",
       "0  [25971, 30303, 29285, 26995, 28271, 11552, 131...   \n",
       "1  [25971, 30303, 29285, 26995, 28271, 11552, 131...   \n",
       "2  [25971, 30303, 29285, 26995, 28271, 11552, 131...   \n",
       "3  [25971, 30303, 29285, 26995, 28271, 11552, 131...   \n",
       "4  [25971, 30303, 29285, 26995, 28271, 11552, 131...   \n",
       "\n",
       "                                     ipa  \\\n",
       "0  톷톝토톷int톔mtt툮툵zt톛w톔tt툮k톔톷tunzni톝ft톷nun   \n",
       "1           w톩tt툮tt툮톷tt툮du칧톩sm톩풪sw톷툮ip톩n   \n",
       "2      툮ih칝dd뉄젻톔톷ksu툾n톷isiw톖툮w톖쮈좕덀닯j톩톷   \n",
       "3      톛bl톩si쬴h톝no툵쮈져톩i쬴토o툵h칝ndinh칝nd   \n",
       "4    hiniv톝lfi콂f톩lmm톝쬴t톔ksikimiklz톷juzd   \n",
       "\n",
       "                                      phoneme_starts  \\\n",
       "0  [0, 2346, 2709, 3467, 4646, 5101, 6558, 7394, ...   \n",
       "1  [0, 2095, 2892, 3718, 4530, 5760, 6732, 8731, ...   \n",
       "2  [0, 4760, 6520, 7561, 8280, 10193, 10920, 1156...   \n",
       "3  [0, 2200, 3091, 3880, 5347, 5848, 6365, 7400, ...   \n",
       "4  [0, 2007, 2571, 3020, 4014, 4238, 4687, 5713, ...   \n",
       "\n",
       "                                        phoneme_ends  \n",
       "0  [2346, 2709, 3467, 4646, 5101, 6558, 7394, 836...  \n",
       "1  [2095, 2892, 3718, 4530, 5760, 6732, 8731, 107...  \n",
       "2  [4760, 6520, 7561, 8280, 10193, 10920, 11560, ...  \n",
       "3  [2200, 3091, 3880, 5347, 5848, 6365, 7400, 960...  \n",
       "4  [2007, 2571, 3020, 4014, 4238, 4687, 5713, 763...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Updated timit_file_to_dict to use the simplified IPA phonemes\n",
    "def timit_file_to_dict(filename):\n",
    "    with timit.open(filename + '.PHN') as phn_file:\n",
    "        timestamped_phonemes = []\n",
    "        for line in phn_file.read().decode('utf-8').split('\\n'):\n",
    "            if line == '':\n",
    "                continue\n",
    "            start, end, phoneme = line.split()\n",
    "            \n",
    "            # Convert to IPA first and then simplify the phoneme\n",
    "            ipa_phonemes = timit2ipa(phoneme, \"eng\")\n",
    "            \n",
    "            # Now filter only the necessary characters (this simplifies the phoneme to the basic form)\n",
    "            cleaned_ipa = filter_chars(simplify_timit(ipa_phonemes), filter_type=\"letters\")\n",
    "            cleaned_ipa = remove_stress_mark(cleaned_ipa)\n",
    "            timestamped_phonemes.append((cleaned_ipa, int(start), int(end)))\n",
    "\n",
    "    return {'timestamped_phonemes': timestamped_phonemes, 'wav_filename': filename + '.WAV'}\n",
    "\n",
    "# Updated files_to_df to create DataFrame with cleaned-up phonemes\n",
    "def files_to_df(files):\n",
    "    records = []\n",
    "    for filename in files:\n",
    "        parsed = timit_file_to_dict(filename)\n",
    "        parsed['audio'] = zipped_wav_to_array(parsed['wav_filename'])\n",
    "        del parsed['wav_filename']\n",
    "        parsed['ipa'] = \"\".join(phoneme for phoneme, _, _ in parsed['timestamped_phonemes'])\n",
    "        parsed['phoneme_starts'] = [start for _, start, _ in parsed['timestamped_phonemes']]\n",
    "        parsed['phoneme_ends'] = [end for _, _, end in parsed['timestamped_phonemes']]\n",
    "        del parsed['timestamped_phonemes']\n",
    "        records.append(parsed)\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "# Call files_to_df for your test files\n",
    "train_df = files_to_df(training_files)\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Up Audio\n",
    "We will just crop out the start signal so that we do not have this loud sound at the start:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_audio(row):\n",
    "    # Access the phoneme_starts column and get the last value of the list\n",
    "    end = row['phoneme_starts'][-1]\n",
    "    # Access the phoneme_ends column and get the first value of the list\n",
    "    start = row['phoneme_ends'][0]\n",
    "    # Crop the audio from start to end\n",
    "    # note that start and end are in samples, not seconds\n",
    "    cropped_audio = row['audio'][start:end]\n",
    "    \n",
    "    return cropped_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# graph one audio to see start signal that we will remove\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_df['audio'][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio</th>\n",
       "      <th>ipa</th>\n",
       "      <th>phoneme_starts</th>\n",
       "      <th>phoneme_ends</th>\n",
       "      <th>cropped_audio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[25971, 30303, 29285, 26995, 28271, 11552, 131...</td>\n",
       "      <td>톷톝토톷int톔mtt툮툵zt톛w톔tt툮k톔톷tunzni톝ft톷nun</td>\n",
       "      <td>[0, 2346, 2709, 3467, 4646, 5101, 6558, 7394, ...</td>\n",
       "      <td>[2346, 2709, 3467, 4646, 5101, 6558, 7394, 836...</td>\n",
       "      <td>[2, 0, 1, 1, 7, 2, 10, 2, -3, 0, 5, 3, 5, -1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[25971, 30303, 29285, 26995, 28271, 11552, 131...</td>\n",
       "      <td>w톩tt툮tt툮톷tt툮du칧톩sm톩풪sw톷툮ip톩n</td>\n",
       "      <td>[0, 2095, 2892, 3718, 4530, 5760, 6732, 8731, ...</td>\n",
       "      <td>[2095, 2892, 3718, 4530, 5760, 6732, 8731, 107...</td>\n",
       "      <td>[1, 3, 2, 2, 1, 3, 1, -1, 1, 0, 4, 3, 2, 1, 2,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[25971, 30303, 29285, 26995, 28271, 11552, 131...</td>\n",
       "      <td>툮ih칝dd뉄젻톔톷ksu툾n톷isiw톖툮w톖쮈좕덀닯j톩톷</td>\n",
       "      <td>[0, 4760, 6520, 7561, 8280, 10193, 10920, 1156...</td>\n",
       "      <td>[4760, 6520, 7561, 8280, 10193, 10920, 11560, ...</td>\n",
       "      <td>[3, -1, 1, -2, -1, 0, -1, 1, -1, 0, 2, 2, 0, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[25971, 30303, 29285, 26995, 28271, 11552, 131...</td>\n",
       "      <td>톛bl톩si쬴h톝no툵쮈져톩i쬴토o툵h칝ndinh칝nd</td>\n",
       "      <td>[0, 2200, 3091, 3880, 5347, 5848, 6365, 7400, ...</td>\n",
       "      <td>[2200, 3091, 3880, 5347, 5848, 6365, 7400, 960...</td>\n",
       "      <td>[-1, -4, 1, 0, -1, 2, 3, 0, 0, 1, 0, 1, 2, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[25971, 30303, 29285, 26995, 28271, 11552, 131...</td>\n",
       "      <td>hiniv톝lfi콂f톩lmm톝쬴t톔ksikimiklz톷juzd</td>\n",
       "      <td>[0, 2007, 2571, 3020, 4014, 4238, 4687, 5713, ...</td>\n",
       "      <td>[2007, 2571, 3020, 4014, 4238, 4687, 5713, 763...</td>\n",
       "      <td>[-4, 5, 13, 10, 6, 3, -6, -8, -1, 5, 2, -1, 2,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               audio  \\\n",
       "0  [25971, 30303, 29285, 26995, 28271, 11552, 131...   \n",
       "1  [25971, 30303, 29285, 26995, 28271, 11552, 131...   \n",
       "2  [25971, 30303, 29285, 26995, 28271, 11552, 131...   \n",
       "3  [25971, 30303, 29285, 26995, 28271, 11552, 131...   \n",
       "4  [25971, 30303, 29285, 26995, 28271, 11552, 131...   \n",
       "\n",
       "                                     ipa  \\\n",
       "0  톷톝토톷int톔mtt툮툵zt톛w톔tt툮k톔톷tunzni톝ft톷nun   \n",
       "1           w톩tt툮tt툮톷tt툮du칧톩sm톩풪sw톷툮ip톩n   \n",
       "2      툮ih칝dd뉄젻톔톷ksu툾n톷isiw톖툮w톖쮈좕덀닯j톩톷   \n",
       "3      톛bl톩si쬴h톝no툵쮈져톩i쬴토o툵h칝ndinh칝nd   \n",
       "4    hiniv톝lfi콂f톩lmm톝쬴t톔ksikimiklz톷juzd   \n",
       "\n",
       "                                      phoneme_starts  \\\n",
       "0  [0, 2346, 2709, 3467, 4646, 5101, 6558, 7394, ...   \n",
       "1  [0, 2095, 2892, 3718, 4530, 5760, 6732, 8731, ...   \n",
       "2  [0, 4760, 6520, 7561, 8280, 10193, 10920, 1156...   \n",
       "3  [0, 2200, 3091, 3880, 5347, 5848, 6365, 7400, ...   \n",
       "4  [0, 2007, 2571, 3020, 4014, 4238, 4687, 5713, ...   \n",
       "\n",
       "                                        phoneme_ends  \\\n",
       "0  [2346, 2709, 3467, 4646, 5101, 6558, 7394, 836...   \n",
       "1  [2095, 2892, 3718, 4530, 5760, 6732, 8731, 107...   \n",
       "2  [4760, 6520, 7561, 8280, 10193, 10920, 11560, ...   \n",
       "3  [2200, 3091, 3880, 5347, 5848, 6365, 7400, 960...   \n",
       "4  [2007, 2571, 3020, 4014, 4238, 4687, 5713, 763...   \n",
       "\n",
       "                                       cropped_audio  \n",
       "0  [2, 0, 1, 1, 7, 2, 10, 2, -3, 0, 5, 3, 5, -1, ...  \n",
       "1  [1, 3, 2, 2, 1, 3, 1, -1, 1, 0, 4, 3, 2, 1, 2,...  \n",
       "2  [3, -1, 1, -2, -1, 0, -1, 1, -1, 0, 2, 2, 0, -...  \n",
       "3  [-1, -4, 1, 0, -1, 2, 3, 0, 0, 1, 0, 1, 2, 1, ...  \n",
       "4  [-4, 5, 13, 10, 6, 3, -6, -8, -1, 5, 2, -1, 2,...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the process_row function to each row in the DataFrame\n",
    "train_df['cropped_audio'] = train_df.apply(crop_audio, axis=1) \n",
    "train_df.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4a32302040>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize again, much better!\n",
    "plt.plot(train_df['cropped_audio'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ipa</th>\n",
       "      <th>audio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>톷톝토톷int톔mtt툮툵zt톛w톔tt툮k톔톷tunzni톝ft톷nun</td>\n",
       "      <td>[2, 0, 1, 1, 7, 2, 10, 2, -3, 0, 5, 3, 5, -1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>w톩tt툮tt툮톷tt툮du칧톩sm톩풪sw톷툮ip톩n</td>\n",
       "      <td>[1, 3, 2, 2, 1, 3, 1, -1, 1, 0, 4, 3, 2, 1, 2,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>툮ih칝dd뉄젻톔톷ksu툾n톷isiw톖툮w톖쮈좕덀닯j톩톷</td>\n",
       "      <td>[3, -1, 1, -2, -1, 0, -1, 1, -1, 0, 2, 2, 0, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>톛bl톩si쬴h톝no툵쮈져톩i쬴토o툵h칝ndinh칝nd</td>\n",
       "      <td>[-1, -4, 1, 0, -1, 2, 3, 0, 0, 1, 0, 1, 2, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hiniv톝lfi콂f톩lmm톝쬴t톔ksikimiklz톷juzd</td>\n",
       "      <td>[-4, 5, 13, 10, 6, 3, -6, -8, -1, 5, 2, -1, 2,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     ipa  \\\n",
       "0  톷톝토톷int톔mtt툮툵zt톛w톔tt툮k톔톷tunzni톝ft톷nun   \n",
       "1           w톩tt툮tt툮톷tt툮du칧톩sm톩풪sw톷툮ip톩n   \n",
       "2      툮ih칝dd뉄젻톔톷ksu툾n톷isiw톖툮w톖쮈좕덀닯j톩톷   \n",
       "3      톛bl톩si쬴h톝no툵쮈져톩i쬴토o툵h칝ndinh칝nd   \n",
       "4    hiniv톝lfi콂f톩lmm톝쬴t톔ksikimiklz톷juzd   \n",
       "\n",
       "                                               audio  \n",
       "0  [2, 0, 1, 1, 7, 2, 10, 2, -3, 0, 5, 3, 5, -1, ...  \n",
       "1  [1, 3, 2, 2, 1, 3, 1, -1, 1, 0, 4, 3, 2, 1, 2,...  \n",
       "2  [3, -1, 1, -2, -1, 0, -1, 1, -1, 0, 2, 2, 0, -...  \n",
       "3  [-1, -4, 1, 0, -1, 2, 3, 0, 0, 1, 0, 1, 2, 1, ...  \n",
       "4  [-4, 5, 13, 10, 6, 3, -6, -8, -1, 5, 2, -1, 2,...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_df comprised of just cropped_audio and phonemes\n",
    "train_df = train_df.drop(columns=['phoneme_starts', 'phoneme_ends', 'audio'])\n",
    "# rename cropped audio to audio\n",
    "train_df = train_df.rename(columns={'cropped_audio': 'audio'})\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset.from_pandas(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extend Phoneme Vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be some phonemes from TIMIT that are not accounted by the model. So we will make sure the pretrained model's tokenizer is updated for any differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "timit_vocab = set(\"\".join(train_df['ipa']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'u', '토', 'w', '', 'i', 'h', '툵', '톖', 'l', 'd', 'k', '', 'n', '톷', 'o', '칧', 'v', '톝', 'b', '콂', 't', 's', 'm', '톔', '톛', 'f', '칝', '툾', 'e', 'a', '툷', 'j', '툮', '풪', 'z', '톩', 'p'}\n"
     ]
    }
   ],
   "source": [
    "print(timit_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 113, 'C': 20, 'E': 89, 'H': 148, 'I': 124, 'O': 28, 'U': 176, 'X': 224, '[PAD]': 312, '[UNK]': 311, '_': 259, 'a': 156, 'a팪': 188, 'b': 286, 'b퍍': 83, 'b퍍포v': 137, 'b포數': 80, 'c': 186, 'c퉢': 277, 'c포칞': 265, 'd': 229, 'd퍞': 210, 'd포z': 51, 'd포칧': 110, 'd포톭': 284, 'd포툼': 112, 'd포': 214, 'e': 22, 'e팪': 233, 'e': 202, 'e뤫': 187, 'f': 34, 'f퉢': 181, 'h': 253, 'i': 160, 'j': 92, 'k': 135, 'kx퉢': 221, 'k': 25, 'k킈': 140, 'k킉': 115, 'k킊': 97, 'k퉂': 165, 'k퉢': 7, 'k퍀': 118, 'k포p': 102, 'k포x': 287, 'l': 292, 'm': 85, 'm퍈': 101, 'n': 141, 'n퍈': 54, 'n퍞': 61, 'o': 162, 'o팪': 62, 'o': 203, 'o뤫': 60, 'p': 38, 'p퉢': 216, 'p퍀': 11, 'p퍍': 236, 'p퍍포f': 205, 'p포f': 43, 'p포톶': 154, 'q': 237, 'q': 9, 'q킈': 49, 'q킉': 196, 'q킊': 53, 'q퉂': 119, 'q퉢': 99, 'q포퉈': 169, 'q포픦퉢': 44, 'q포乷': 226, 'r': 254, 'r퍈': 174, 's': 201, 's퉢': 117, 't': 39, 't퉢': 2, 't퍀': 59, 't퍍포풪퉢': 50, 't퍞': 307, 't포s': 264, 't포s퉢': 68, 't포톗': 281, 't포톫': 158, 't포톫퉢': 172, 't포툮': 246, 't포툮퉢': 192, 't포풪': 161, 'u': 48, 'u팪': 159, 'v': 82, 'w': 127, 'x': 177, 'x퉢': 66, 'y': 261, 'y팪': 189, 'z': 126, '{': 73, '}': 238, '칚': 209, '칛': 69, '칛팪': 47, '칝': 26, '칝팪': 153, '칞': 10, '칧': 266, '칧': 163, '칧퍞': 204, '칫': 298, '칮': 95, '칮팪': 3, '칮': 121, '칮뤫': 280, '캲': 19, '캴': 42, '콂': 222, '콂': 109, '콂킈': 310, '콂킉': 301, '콂킊': 232, '콂퉂': 58, '콂팱': 146, '콂포m': 302, '콉': 111, '콉팪': 132, '콜': 248, '톓': 197, '톓팪': 234, '톔': 208, '톔팪': 37, '': 18, '뉇': 4, '톕': 303, '톕퍈': 157, '톖': 106, '톖팪': 183, '톗': 308, '톗퉢': 185, '톘': 239, '톘포툻': 215, '톙': 180, '톙퍈': 300, '톚': 91, '톚팪': 41, '톛': 155, '톛팪': 289, '톜': 131, '톝': 282, '톝팪': 65, '톞': 297, '톞팪': 14, '톟': 151, '': 198, '뤫': 120, '': 166, '포퉇': 150, '': 164, '먧': 247, '토': 103, '토': 79, '토킈': 269, '토킉': 98, '토킊': 133, '토퉂': 134, '토팭': 228, '토포b': 70, '토포톢': 190, '톡': 220, '톡': 152, '톡킈': 116, '톡킉': 168, '톡킊': 290, '톡퉂': 268, '톡팭': 267, '톡포투': 63, '톢': 149, '톣': 147, '톣팪': 67, '톣': 244, '톣뤫': 240, '톤': 74, '톤팱': 64, '톦': 87, '톧': 123, '톧팪': 72, '톩': 256, '톩팪': 179, '톫': 108, '톫퉢': 207, '톬': 249, '톬틦': 262, '톬팭': 178, '톬퍈팭': 299, '톭': 242, '톮': 213, '톮팪': 76, '톯': 250, '톰': 219, '': 31, '쒧': 30, '톱': 193, '톱팱': 184, '톲': 257, '톲': 138, '톲킈': 182, '톲킉': 206, '톲킊': 243, '톲퉂': 23, '톳': 212, '톳팪': 94, '톴': 296, '톴팪': 24, '톶': 199, '톶퉢': 305, '톷': 285, '톷먦': 260, '톷먧궮': 12, '톸': 100, '톸퍈': 139, '톹': 273, '톹틦': 55, '톹팱틦': 170, '톻': 211, '톻팱': 270, '': 251, '쮋': 21, '쮋': 27, '': 235, '퍈': 125, '투': 200, '툭': 75, '툭퉢': 96, '툮': 279, '툮퉢': 230, '툯': 291, '툯팱': 88, '툳': 5, '툳퉢': 309, '툳포툭': 258, '툳포툭퉢': 1, '툴': 29, '툴팪': 33, '툵': 128, '툵팪': 263, '툶': 56, '툷': 223, '툷팪': 225, '툸': 173, '툹': 288, '툹팭': 175, '툹퍃': 81, '툹퍃팱': 195, '툺': 105, '툺팪': 86, '툻': 306, '툼': 304, '': 171, '툾': 245, '툾': 78, '툾포h': 276, '툿': 107, '퉃': 104, '퉃퍈': 6, '퉅': 15, '퉅퍈': 294, '퉆': 16, '퉇': 84, '': 52, '팭': 275, '퍃': 8, '퍃팱': 57, '': 40, '퉈': 194, '퉈퉢': 231, '퉈팭': 32, '퉈포퉆': 114, '퉈포퉉': 122, '퉉': 36, '퉗': 45, '': 191, '퉝': 144, '틣': 295, '': 145, '': 217, '티': 218, '틲': 46, '틳': 271, '팪': 283, '퍌': 272, '': 0, '풪': 278, '풪퉢': 71, '풪': 13, '풪퍞': 136, '픦': 129, '픦퉢': 241, '孤': 17, '孤': 274, '尻': 90, '尻놟': 293, '尻': 142, '尻': 130, '尻': 255, '尻': 252, '尻': 93, '故': 35, '': 143, '歐': 167, '歐쏿': 227, '數': 77, '<s>': 313, '</s>': 314}\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(PRE_TRAINED_ID)\n",
    "vocab = tokenizer.get_vocab()\n",
    "# you will see how large the vocab is, we will resize our linear layer later to make it work for our smaller vocab\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "additional_vocab = timit_vocab.difference(set(vocab.keys()) | {' '})\n",
    "tokenizer.add_tokens(list(additional_vocab))\n",
    "print(additional_vocab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = AutoFeatureExtractor.from_pretrained(PRE_TRAINED_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't need to update the feature extractor since it has been pretrained on 16kHz audio which matches the TIMIT dataset.\n",
    "\n",
    "For datasets with different sampling rates, the feature extractor should be updated or the audio resampled (easier).\n",
    "\n",
    "This is also where code to add extra features (such as conditioning on speaker's native language etc.) would be added."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we fine-tune the model, lets listen to an audio clip and see how the pretrained model transcribes it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoProcessor, AutoModelForCTC\n",
    "from IPython.display import Audio\n",
    "import sounddevice as sd\n",
    "\n",
    "def predict_phonemes(audio_data, sample_rate=16000):\n",
    "    \"\"\"\n",
    "    Predicts phoneme sequence from audio using pretrained model\n",
    "    \n",
    "    Parameters:\n",
    "        audio_data: numpy array of audio samples\n",
    "        sample_rate: audio sampling rate (default: 16000 Hz)\n",
    "    \"\"\"\n",
    "    # Load model and processor\n",
    "    model_id = \"ginic/data_seed_4_wav2vec2-large-xlsr-buckeye-ipa\"\n",
    "    processor = AutoProcessor.from_pretrained(model_id)\n",
    "    model = AutoModelForCTC.from_pretrained(model_id)\n",
    "    \n",
    "    # Move model to GPU if available\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Preprocess audio\n",
    "    inputs = processor(\n",
    "        audio_data, \n",
    "        sampling_rate=sample_rate,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True\n",
    "    )\n",
    "    \n",
    "    # Move inputs to same device as model\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    # Run inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs).logits\n",
    "    \n",
    "    # Get predicted IDs and decode to phonemes\n",
    "    predicted_ids = torch.argmax(outputs, dim=-1)\n",
    "    predicted_transcription = processor.batch_decode(predicted_ids)\n",
    "    \n",
    "    # Clean up special tokens\n",
    "    cleaned_transcription = (predicted_transcription[0]\n",
    "                           .replace(\"<pad>\", \"\")\n",
    "                           .replace(\"<s>\", \"\")\n",
    "                           .replace(\"</s>\", \"\")\n",
    "                           .replace(\"<unk>\", \"\")\n",
    "                           .strip())\n",
    "    \n",
    "    return cleaned_transcription\n",
    "\n",
    "# Example usage with your audio data\n",
    "audio_sample = train_df['audio'][0]\n",
    "\n",
    "# Play the audio\n",
    "print(\"游댉 Playing audio sample:\")\n",
    "Audio(audio_sample, rate=16000)\n",
    "\n",
    "# Get prediction\n",
    "print(\"\\n游닇 Predicted phoneme sequence:\")\n",
    "phonemes = predict_phonemes(audio_sample)\n",
    "print(phonemes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINE-TUNE!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GREAT! We have cleaned up the data and have prepared our tokenizer. Now onto finetuning the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tempfile\n",
    "from transformers import (\n",
    "    AutoProcessor, AutoModelForCTC, Trainer, \n",
    "    TrainingArguments, Wav2Vec2CTCTokenizer\n",
    ")\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional, Union\n",
    "import logging\n",
    "from torch.utils.data import DataLoader\n",
    "import wandb\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchaudio\n",
    "import json\n",
    "from transformers.trainer_callback import EarlyStoppingCallback\n",
    "\n",
    "# 游꿢 Where should we save our trained model?\n",
    "NEW_MODEL_ID = \"./notebooks/results-b0\"\n",
    "\n",
    "# 游닇 Let's set up logging so we know what's happening\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# 游꿧 Audio settings\n",
    "SAMPLING_RATE = 16000  # 16kHz - Standard for speech processing\n",
    "MAX_AUDIO_LENGTH = 160000  # 10 seconds of audio (16000 * 10)\n",
    "MAX_LABEL_LENGTH = 100  # Maximum number of phonemes in a transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataCollatorCTCWithPadding:\n",
    "    \"\"\"\n",
    "    游븿꽥뗵勇 The Magic Data Packer! \n",
    "    \n",
    "    This is like a helpful wizard that makes sure all our audio samples are the same length.\n",
    "    Just like how you need all photos to be the same size to make a photo album,\n",
    "    we need all audio clips to be the same length to train our model.\n",
    "    \n",
    "    Example:\n",
    "    If we have:\n",
    "        - Audio 1: [0.1, 0.2, 0.3] (3 seconds)\n",
    "        - Audio 2: [0.1, 0.2] (2 seconds)\n",
    "    \n",
    "    The wizard pads Audio 2 to become:\n",
    "        - Audio 2: [0.1, 0.2, 0.0] (added a 0 to make it 3 seconds)\n",
    "    \"\"\"\n",
    "    processor: AutoProcessor\n",
    "    padding: Union[bool, str] = \"longest\"\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # 游늺 Find the longest audio in this batch (but not longer than our max!)\n",
    "        max_length = min(\n",
    "            max(len(feature[\"input_values\"]) for feature in features),\n",
    "            MAX_AUDIO_LENGTH\n",
    "        )\n",
    "        \n",
    "        # 游꿧 Prepare our audio containers\n",
    "        padded_inputs = []\n",
    "        attention_mask = []\n",
    "        \n",
    "        # 游댃 Process each audio clip\n",
    "        for feature in features:\n",
    "            input_length = len(feature[\"input_values\"])\n",
    "            padding_length = max_length - input_length\n",
    "            \n",
    "            # 游댃 Convert to tensor if it isn't already\n",
    "            if isinstance(feature[\"input_values\"], list):\n",
    "                input_values = torch.tensor(feature[\"input_values\"])\n",
    "            else:\n",
    "                input_values = feature[\"input_values\"]\n",
    "            \n",
    "            # 1勇 Make sure it's a 1D array\n",
    "            input_values = input_values.squeeze()\n",
    "            \n",
    "            # Pad with zeros \n",
    "            if padding_length > 0:\n",
    "                padded_input = torch.nn.functional.pad(input_values, (0, padding_length))\n",
    "                attention_mask.append(torch.cat([torch.ones(input_length), torch.zeros(padding_length)]))\n",
    "            else:\n",
    "                padded_input = input_values\n",
    "                attention_mask.append(torch.ones(input_length))\n",
    "            \n",
    "            padded_inputs.append(padded_input)\n",
    "\n",
    "        # 游닍 Pack everything into a neat batch\n",
    "        batch = {\n",
    "            \"input_values\": torch.stack(padded_inputs),\n",
    "            \"attention_mask\": torch.stack(attention_mask)\n",
    "        }\n",
    "\n",
    "        # 游낑勇 Process the phoneme labels\n",
    "        with self.processor.as_target_processor():\n",
    "            label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "            labels_batch = self.processor.pad(\n",
    "                label_features,\n",
    "                padding=self.padding,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "\n",
    "        # 游꿢 Replace padding with -100 (special number that tells PyTorch to ignore these positions)\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_model_and_processor(timit_vocab):\n",
    "    \"\"\"\n",
    "    \n",
    "    Here we prepare our model and its vocabulary\n",
    "    \n",
    "    Example vocabulary:\n",
    "    {\n",
    "        \"<pad>\": 0,    \n",
    "        \"<s>\": 1,      # start token\n",
    "        \"</s>\": 2,     # end token\n",
    "        \"칝\": 4,        # The \"a\" in \"cat\"\n",
    "        \"t\": 5,        # The \"t\" in \"top\"\n",
    "        ...\n",
    "    }\n",
    "    \"\"\"\n",
    "    logger.info(\"Loading pretrained model and processor...\")\n",
    "    \n",
    "    processor = AutoProcessor.from_pretrained(PRE_TRAINED_ID)\n",
    "    model = AutoModelForCTC.from_pretrained(PRE_TRAINED_ID)\n",
    "    \n",
    "    # Store the old vocabulary before making any changes\n",
    "    old_vocab = processor.tokenizer.get_vocab()\n",
    "    logger.info(f\"Initial vocabulary size: {len(old_vocab)}\")\n",
    "    \n",
    "    # Define fixed special token IDs - pad token first for CTC\n",
    "    special_tokens = {\n",
    "        \"<pad>\": 0,  # Changed to 0 for CTC blank token\n",
    "        \"<s>\": 1,    # Shifted up\n",
    "        \"</s>\": 2,   # Shifted up\n",
    "        \"<unk>\": 3   # Shifted up\n",
    "    }\n",
    "    logger.info(\"Initial special tokens setup:\")\n",
    "    for token, idx in special_tokens.items():\n",
    "        logger.info(f\"{token}: {idx}\")\n",
    "    \n",
    "    # Get regular tokens (excluding special tokens)\n",
    "    regular_tokens = sorted(list(timit_vocab - set(special_tokens.keys())))\n",
    "    \n",
    "    # Create combined vocabulary with fixed IDs\n",
    "    vocab = {**special_tokens}  # Start with special tokens\n",
    "    \n",
    "    # Add regular tokens after special tokens\n",
    "    for idx, token in enumerate(regular_tokens):\n",
    "        vocab[token] = idx + len(special_tokens)\n",
    "    \n",
    "    # Create tokenizer config with consistent token formats\n",
    "    tokenizer_config = {\n",
    "        \"vocab\": vocab,\n",
    "        \"pad_token\": \"<pad>\",\n",
    "        \"bos_token\": \"<s>\",\n",
    "        \"eos_token\": \"</s>\",\n",
    "        \"unk_token\": \"<unk>\",\n",
    "    }\n",
    "    \n",
    "    # Save vocab to temporary file\n",
    "    with tempfile.NamedTemporaryFile(mode='w', delete=False) as f:\n",
    "        json.dump(vocab, f)\n",
    "        vocab_path = f.name\n",
    "    \n",
    "    # Create new tokenizer\n",
    "    new_tokenizer = Wav2Vec2CTCTokenizer(\n",
    "        vocab_path,\n",
    "        **{k: v for k, v in tokenizer_config.items() if k != \"vocab\"}\n",
    "    )\n",
    "    \n",
    "    # Verify tokenizer loaded correctly before proceeding\n",
    "    loaded_vocab = new_tokenizer.get_vocab()\n",
    "    logger.info(\"\\nVerifying special token IDs in new tokenizer:\")\n",
    "    for token, expected_id in special_tokens.items():\n",
    "        actual_id = loaded_vocab.get(token)\n",
    "        logger.info(f\"{token}: expected={expected_id}, actual={actual_id}\")\n",
    "        assert actual_id == expected_id, f\"Token ID mismatch for {token}\"\n",
    "    \n",
    "    # Update processor with new tokenizer\n",
    "    processor.tokenizer = new_tokenizer\n",
    "    os.remove(vocab_path)\n",
    "    \n",
    "    # Verify vocab size\n",
    "    final_vocab_size = len(processor.tokenizer.get_vocab())\n",
    "    logger.info(f\"\\nFinal vocabulary size: {final_vocab_size}\")\n",
    "    assert final_vocab_size == len(vocab), \"Vocabulary size mismatch\"\n",
    "    \n",
    "    # Handle model weights\n",
    "    old_weights = model.lm_head.weight.data\n",
    "    old_bias = model.lm_head.bias.data\n",
    "    \n",
    "    # Create new layer\n",
    "    new_layer = torch.nn.Linear(model.lm_head.in_features, len(processor.tokenizer))\n",
    "    new_layer.weight.data.zero_()\n",
    "    new_layer.bias.data.zero_()\n",
    "    \n",
    "    # Transfer weights and bias using the stored old_vocab\n",
    "    for token, new_idx in loaded_vocab.items():\n",
    "        if token in old_vocab:\n",
    "            old_idx = old_vocab[token]\n",
    "            new_layer.weight.data[new_idx, :] = old_weights[old_idx, :]\n",
    "            new_layer.bias.data[new_idx] = old_bias[old_idx]\n",
    "    \n",
    "    model.lm_head = new_layer\n",
    "    model.config.vocab_size = final_vocab_size\n",
    "    model.config.pad_token_id = 0  # Explicitly set pad token as CTC blank token\n",
    "    \n",
    "    # Final verification\n",
    "    logger.info(\"\\nFinal vocabulary check:\")\n",
    "    final_vocab = processor.tokenizer.get_vocab()\n",
    "    for token, expected_id in special_tokens.items():\n",
    "        actual_id = final_vocab.get(token)\n",
    "        logger.info(f\"{token}: {actual_id}\")\n",
    "        assert actual_id == expected_id, f\"Final token ID mismatch for {token}\"\n",
    "    \n",
    "    return model, processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_audio(audio_input):\n",
    "    \"\"\"\n",
    "    游꿧 Audio Preprocessor\n",
    "    \n",
    "    Standardizes audio input for the model by:\n",
    "    - Converting to correct format (numpy array)\n",
    "    - Normalizing volume\n",
    "    - Ensuring consistent length\n",
    "    \n",
    "    Parameters:\n",
    "        audio_input: Can be:\n",
    "            - File path (str)\n",
    "            - Numpy array\n",
    "            - List of values\n",
    "            - PyTorch tensor\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Processed audio as float32 numpy array\n",
    "    \"\"\"\n",
    "    # Handle different input types\n",
    "    if isinstance(audio_input, str):\n",
    "        waveform, sample_rate = torchaudio.load(audio_input)\n",
    "        audio_numpy = waveform.squeeze().numpy()\n",
    "        \n",
    "    elif isinstance(audio_input, (list, np.ndarray, torch.Tensor)):\n",
    "        audio_numpy = np.asarray(audio_input, dtype=np.float32)\n",
    "    else:\n",
    "        raise ValueError(f\"仇 Unsupported audio type: {type(audio_input)}\")\n",
    "    \n",
    "    # Ensure we have a 1D array\n",
    "    audio_numpy = audio_numpy.squeeze()\n",
    "    \n",
    "    # Normalize volume to range [-1, 1]\n",
    "    if np.abs(audio_numpy).max() > 1:\n",
    "        audio_numpy = audio_numpy / np.abs(audio_numpy).max()\n",
    "    \n",
    "    # Adjust length to match MAX_AUDIO_LENGTH\n",
    "    if len(audio_numpy) > MAX_AUDIO_LENGTH:\n",
    "        audio_numpy = audio_numpy[:MAX_AUDIO_LENGTH]\n",
    "    elif len(audio_numpy) < MAX_AUDIO_LENGTH:\n",
    "        audio_numpy = np.pad(audio_numpy, (0, MAX_AUDIO_LENGTH - len(audio_numpy)))\n",
    "    \n",
    "    return audio_numpy\n",
    "\n",
    "def prepare_datasets(train_df, processor):\n",
    "    \"\"\"\n",
    "    游꿢 Dataset Preparation\n",
    "    \n",
    "    Prepares training and evaluation datasets by:\n",
    "    1. Splitting data into train/eval sets\n",
    "    2. Processing audio files\n",
    "    3. Converting transcriptions to token IDs\n",
    "    \n",
    "    Parameters:\n",
    "        train_df: DataFrame with 'audio' and 'ipa' columns\n",
    "        processor: Hugging Face processor for tokenization\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (training dataset, evaluation dataset)\n",
    "    \"\"\"\n",
    "    logger.info(\"Splitting dataset into train and evaluation...\")\n",
    "    \n",
    "    # Split data 80/20\n",
    "    train_data, eval_data = train_test_split(train_df, test_size=0.2, random_state=42)\n",
    "    \n",
    "    def process_data(batch):\n",
    "        \"\"\"Process a single batch of data\"\"\"\n",
    "        # Convert audio to standard format\n",
    "        audio = preprocess_audio(batch[\"audio\"])\n",
    "        \n",
    "        # Convert audio to model inputs\n",
    "        inputs = processor(\n",
    "            audio, \n",
    "            sampling_rate=SAMPLING_RATE, \n",
    "            return_tensors=None\n",
    "        )\n",
    "        \n",
    "        # Convert IPA transcription to token IDs\n",
    "        with processor.as_target_processor():\n",
    "            labels = processor(batch[\"ipa\"]).input_ids\n",
    "        \n",
    "        return {\n",
    "            \"input_values\": inputs[\"input_values\"],\n",
    "            \"labels\": labels,\n",
    "            \"audio\": audio\n",
    "        }\n",
    "    \n",
    "    # Convert to Hugging Face datasets\n",
    "    train_dataset = Dataset.from_pandas(train_data)\n",
    "    eval_dataset = Dataset.from_pandas(eval_data)\n",
    "    \n",
    "    # Process datasets efficiently\n",
    "    train_dataset = train_dataset.map(\n",
    "        process_data,\n",
    "        batch_size=32,\n",
    "        num_proc=4,\n",
    "        remove_columns=[col for col in train_dataset.column_names if col != \"audio\"]\n",
    "    )\n",
    "    eval_dataset = eval_dataset.map(\n",
    "        process_data,\n",
    "        batch_size=32,\n",
    "        num_proc=4,\n",
    "        remove_columns=[col for col in eval_dataset.column_names if col != \"audio\"]\n",
    "    )\n",
    "    \n",
    "    return train_dataset, eval_dataset\n",
    "\n",
    "def verify_dimensions(batch, logger):\n",
    "    \"\"\"\n",
    "    游늺 Dimension Verifier\n",
    "    \n",
    "    Helps debug tensor shapes in a batch of data.\n",
    "    Prints the shape of each tensor in the batch.\n",
    "    \"\"\"\n",
    "    logger.info(\"Checking batch dimensions:\")\n",
    "    for key, value in batch.items():\n",
    "        if isinstance(value, torch.Tensor):\n",
    "            logger.info(f\"{key}: {value.shape}\")\n",
    "\n",
    "def verify_token_ids(processor, stage=\"\"):\n",
    "    \"\"\"\n",
    "    游댌 Token ID Verifier\n",
    "    \n",
    "    Checks that special tokens and vocabulary are set up correctly.\n",
    "    Useful for debugging tokenization issues.\n",
    "    \n",
    "    Parameters:\n",
    "        processor: Hugging Face processor\n",
    "        stage: Description of when verification is happening\n",
    "    \"\"\"\n",
    "    logger.info(f\"\\n=== Token ID Verification [{stage}] ===\")\n",
    "    vocab = processor.tokenizer.get_vocab()\n",
    "    logger.info(f\"Vocabulary size: {len(vocab)}\")\n",
    "    \n",
    "    # Verify special tokens\n",
    "    special_tokens = [\"<pad>\", \"<s>\", \"</s>\", \"<unk>\"]\n",
    "    for token in special_tokens:\n",
    "        token_id = vocab.get(token)\n",
    "        logger.info(f\"游댐 {token}: ID {token_id}\")\n",
    "    \n",
    "    # Show sample of regular tokens\n",
    "    regular_tokens = [t for t in list(vocab.keys())[:5] if t not in special_tokens]\n",
    "    logger.info(\"Sample regular tokens:\")\n",
    "    for token in regular_tokens:\n",
    "        logger.info(f\"Token {token}: ID {vocab[token]}\")\n",
    "    \n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(train_df, timit_vocab):\n",
    "    \"\"\"\n",
    "    游 Main Training Pipeline\n",
    "    \n",
    "    Coordinates the entire training process:\n",
    "    1. Sets up weights & biases logging\n",
    "    2. Prepares model and processor\n",
    "    3. Configures training parameters\n",
    "    4. Trains the model\n",
    "    5. Saves the results\n",
    "    \"\"\"\n",
    "    # Initialize weights & biases logging\n",
    "    wandb.init(project=\"xlsr-buckeye-phoneme-prediction-overnight\")\n",
    "    \n",
    "    # 游꿢 Set up model and processor\n",
    "    model, processor = prepare_model_and_processor(timit_vocab)\n",
    "    \n",
    "    # 游댌 Verify token setup\n",
    "    vocab = verify_token_ids(processor, \"After Model Preparation\")\n",
    "    logger.info(f\"游닄 Full vocabulary: {vocab}\")\n",
    "    \n",
    "    # 游둰勇 Move model to GPU if available\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # 游댢 Enable memory optimization\n",
    "    model.gradient_checkpointing_enable()\n",
    "    \n",
    "    # 游늵 Prepare datasets\n",
    "    train_dataset, eval_dataset = prepare_datasets(train_df, processor)\n",
    "    \n",
    "    # 游꿑勇 Configure training parameters\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./results-b0\",\n",
    "        # Learning parameters\n",
    "        learning_rate=8e-5,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        gradient_accumulation_steps=4,\n",
    "        max_grad_norm=0.907,\n",
    "        \n",
    "        # Optimizer settings\n",
    "        adam_beta1=0.93287,\n",
    "        adam_beta2=0.96748,\n",
    "        \n",
    "        # Learning rate schedule\n",
    "        warmup_ratio=0.08253,\n",
    "        lr_scheduler_type=\"cosine_with_restarts\",\n",
    "        \n",
    "        # Training duration and evaluation\n",
    "        num_train_epochs=40,\n",
    "        logging_dir='./logs',\n",
    "        logging_steps=10,\n",
    "        save_steps=300,\n",
    "        eval_steps=50,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"eval_loss\",\n",
    "        greater_is_better=False,\n",
    "        \n",
    "        # Model saving settings\n",
    "        save_safetensors=True,\n",
    "        save_strategy=\"steps\",\n",
    "        save_total_limit=3,\n",
    "        \n",
    "        # Performance optimizations\n",
    "        fp16=True,\n",
    "        dataloader_num_workers=4,\n",
    "        dataloader_pin_memory=True,\n",
    "        gradient_checkpointing=True,\n",
    "    )\n",
    "    \n",
    "    # 游닍 Set up data collator\n",
    "    data_collator = DataCollatorCTCWithPadding(\n",
    "        processor=processor,\n",
    "        padding=\"longest\"\n",
    "    )\n",
    "    \n",
    "    # 游띔 Add early stopping\n",
    "    early_stopping = EarlyStoppingCallback(\n",
    "        early_stopping_patience=5,\n",
    "        early_stopping_threshold=0.01\n",
    "    )\n",
    "    \n",
    "    # 游꿉 Initialize trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        data_collator=data_collator,\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "    \n",
    "    # 游 Train the model\n",
    "    trainer.train(\"/home/arunasrivastava/ML/notebooks/results-b0/checkpoint-1800\")\n",
    "    \n",
    "    # 游 Save final model and processor\n",
    "    model.save_pretrained(\"./results-b0\")\n",
    "    processor.save_pretrained(\"./results-b0\")\n",
    "    \n",
    "    # 游댌 Final verification\n",
    "    verify_token_ids(processor, \"After Training\")\n",
    "    \n",
    "    # 九 Test inference\n",
    "    logger.info(\"游꿢 Testing model on a sample...\")\n",
    "    sample_audio = train_dataset[0][\"audio\"]\n",
    "    inputs = processor(sample_audio, return_tensors=\"pt\", padding=True)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "    \n",
    "    predicted_tokens = processor.batch_decode(predicted_ids)\n",
    "    cleaned_prediction = (predicted_tokens[0]\n",
    "                        .replace('<s>', '')\n",
    "                        .replace('</s>', '')\n",
    "                        .replace('<pad>', '')\n",
    "                        .replace('<unk>', '')\n",
    "                        .strip())\n",
    "    \n",
    "    logger.info(f\"游꿧 Raw prediction: {predicted_tokens}\")\n",
    "    logger.info(f\"九 Cleaned prediction: {cleaned_prediction}\")\n",
    "    \n",
    "    wandb.finish()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(train_df, timit_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model on Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 1.26G/1.26G [00:27<00:00, 45.1MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForCTC, Wav2Vec2Processor\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Log in to Hugging Face (if not already logged in)\n",
    "# login(\"your-huggingface-api-token\")\n",
    "\n",
    "# Load the model and processor from your local directory\n",
    "model = AutoModelForCTC.from_pretrained(\"/home/USER/ML/notebooks/results-b0\")\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"/home/USER/ML/notebooks/results-b0\")\n",
    "\n",
    "# Specify the directory where you want to save the model\n",
    "save_directory = \"./xlsr-timit-b0\"\n",
    "\n",
    "# Save and upload to Hugging Face Model Hub under an organization\n",
    "model.save_pretrained(save_directory, push_to_hub=True, repo_id=\"KoelLabs/xlsr-timit-b0\")\n",
    "processor.save_pretrained(save_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions to Upload Model to Hugging Face\n",
    "\n",
    "1. **Login to Hugging Face**  \n",
    "   Run the following command to log in to your Hugging Face account:\n",
    "   ```bash\n",
    "   huggingface-cli login\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Create a Repository**  \n",
    "   Run the following command to log in to your Hugging Face account:\n",
    "   ```bash\n",
    "   huggingface-cli repo create your-model-name --organization your-org-name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Git clone**  \n",
    "   Run the following command to clone your repo:\n",
    "   ```bash \n",
    "   git clone https://huggingface.co/your-org-name/your-model-name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Upload Model**  (if you did not make it on Hugging Face already)\n",
    "   Run the following command to clone your repo:\n",
    "   ```bash \n",
    "   huggingface-cli repo upload --path ./<path here>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **Move Other Files**  \n",
    "   Run the following command to copy each file into the repo:\n",
    "   ```bash\n",
    "   cp -r ./<path here> <your-cloned-repo-folder> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. **Stage & Commit!**\n",
    "    Run the following git commands\n",
    "    ```bash\n",
    "    git add README.md\n",
    "    git commit -m \"Add model card\"\n",
    "    git push\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add your fine-tuned model to the leaderboard!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checkout: https://huggingface.co/spaces/KoelLabs/IPA-Transcription-EN\n",
    "And get your model officially added to the board!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YAAAAY CONGRATULATIONS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Optional) Hyperparam search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install optuna joblib\n",
    "# you can use WADNB sweeps as well, whatever is easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from transformers import TrainingArguments, EarlyStoppingCallback\n",
    "from functools import partial\n",
    "import wandb\n",
    "\n",
    "def objective(trial, train_df, timit_vocab, base_output_dir=\"./results\"):\n",
    "    \"\"\"\n",
    "    Optuna objective function for hyperparameter optimization\n",
    "    \"\"\"\n",
    "    # Generate a unique run name\n",
    "    run_name = f\"trial_{trial.number}\"\n",
    "    output_dir = f\"{base_output_dir}/{run_name}\"\n",
    "    \n",
    "    # Initialize wandb for this trial\n",
    "    wandb.init(\n",
    "        project=\"xlsr-buckeye-phoneme-prediction\",\n",
    "        name=run_name,\n",
    "        config={\"trial_number\": trial.number},\n",
    "        reinit=True\n",
    "    )\n",
    "    \n",
    "    # Sample hyperparameters\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-6, 1e-4, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [4, 8, 16])\n",
    "    grad_accum = trial.suggest_categorical(\"gradient_accumulation_steps\", [2, 4, 8])\n",
    "    warmup_ratio = trial.suggest_float(\"warmup_ratio\", 0.05, 0.15)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 0.001, 0.1, log=True)\n",
    "    max_grad_norm = trial.suggest_float(\"max_grad_norm\", 0.5, 2.0)\n",
    "    adam_beta1 = trial.suggest_float(\"adam_beta1\", 0.85, 0.95)\n",
    "    adam_beta2 = trial.suggest_float(\"adam_beta2\", 0.95, 0.999)\n",
    "    adam_epsilon = trial.suggest_float(\"adam_epsilon\", 1e-9, 1e-7, log=True)\n",
    "    \n",
    "    # Prepare model and data\n",
    "    model, processor = prepare_model_and_processor(timit_vocab)\n",
    "    train_dataset, eval_dataset = prepare_datasets(train_df, processor)\n",
    "    \n",
    "    # Enable gradient checkpointing for memory efficiency\n",
    "    model.gradient_checkpointing_enable()\n",
    "    \n",
    "    # Create training arguments with sampled hyperparameters\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        learning_rate=learning_rate,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        gradient_accumulation_steps=grad_accum,\n",
    "        max_grad_norm=max_grad_norm,\n",
    "        warmup_ratio=warmup_ratio,\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "        weight_decay=weight_decay,\n",
    "        num_train_epochs=5,  # Reduced epochs for faster search\n",
    "        logging_dir=f'{output_dir}/logs',\n",
    "        logging_steps=50,\n",
    "        save_steps=500,\n",
    "        eval_steps=100,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"eval_loss\",\n",
    "        greater_is_better=False,\n",
    "        save_safetensors=True,\n",
    "        save_strategy=\"steps\",\n",
    "        save_total_limit=1,  # Keep only best model\n",
    "        fp16=True,\n",
    "        fp16_full_eval=True,\n",
    "        dataloader_num_workers=4,\n",
    "        dataloader_pin_memory=True,\n",
    "        gradient_checkpointing=True,\n",
    "        adam_beta1=adam_beta1,\n",
    "        adam_beta2=adam_beta2,\n",
    "        adam_epsilon=adam_epsilon,\n",
    "    )\n",
    "    \n",
    "    # Create early stopping callback\n",
    "    early_stopping_callback = EarlyStoppingCallback(\n",
    "        early_stopping_patience=3,\n",
    "        early_stopping_threshold=0.01\n",
    "    )\n",
    "    \n",
    "    # Create trainer with early stopping\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        data_collator=DataCollatorCTCWithPadding(processor=processor, padding=\"longest\"),\n",
    "        callbacks=[early_stopping_callback]  # Add early stopping callback\n",
    "    )\n",
    "    \n",
    "    # Train and get best eval loss\n",
    "    try:\n",
    "        train_result = trainer.train()\n",
    "        eval_result = trainer.evaluate()\n",
    "        \n",
    "        # Report to wandb\n",
    "        wandb.log({\n",
    "            \"best_eval_loss\": eval_result[\"eval_loss\"],\n",
    "            \"final_train_loss\": train_result.training_loss,\n",
    "            **{f\"hp_{k}\": v for k, v in trial.params.items()}\n",
    "        })\n",
    "        \n",
    "        wandb.finish()\n",
    "        \n",
    "        return eval_result[\"eval_loss\"]\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Trial {trial.number} failed with error: {str(e)}\")\n",
    "        wandb.finish()\n",
    "        return float('inf')\n",
    "\n",
    "def run_hyperparameter_search(train_df, timit_vocab, n_trials=20):\n",
    "    \"\"\"\n",
    "    Run the hyperparameter search\n",
    "    \"\"\"\n",
    "    study = optuna.create_study(\n",
    "        direction=\"minimize\",\n",
    "        sampler=optuna.samplers.TPESampler(seed=42),\n",
    "        pruner=optuna.pruners.MedianPruner(\n",
    "            n_startup_trials=5,\n",
    "            n_warmup_steps=5,\n",
    "            interval_steps=1\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    study.optimize(\n",
    "        partial(objective, train_df=train_df, timit_vocab=timit_vocab),\n",
    "        n_trials=n_trials,\n",
    "        timeout=3600 * 12  # 12 hour timeout\n",
    "    )\n",
    "    \n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "    print(f\"  Value: {trial.value}\")\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(f\"    {key}: {value}\")\n",
    "    \n",
    "    return study\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    study = run_hyperparameter_search(train_df, timit_vocab)\n",
    "    \n",
    "    # Save study results\n",
    "    import joblib\n",
    "    joblib.dump(study, \"hyperparam_study.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
